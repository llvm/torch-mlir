//===-------------------------------------------------------*- tablegen -*-===//
//
// This file is licensed under the Apache License v2.0 with LLVM Exceptions.
// See https://llvm.org/LICENSE.txt for license information.
// SPDX-License-Identifier: Apache-2.0 WITH LLVM-exception
// Also available under a BSD-style license. See LICENSE.
//
// Operation summaries and descriptions were systematically derived from public
// API docstrings and are licensed accordingly:
//   https://github.com/pytorch/pytorch/blob/master/LICENSE
//===----------------------------------------------------------------------===//
//
// This file is automatically generated.  Please do not edit.
// Generated via:
//   python -m torch_mlir.dialects.torch.importer.jit_ir.build_tools.torch_ods_gen
//
//===----------------------------------------------------------------------===//

def Torch_AtenTanhOp : Torch_Op<"aten.tanh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tanh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenTanh_Op : Torch_Op<"aten.tanh_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tanh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenReluOp : Torch_Op<"aten.relu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::relu : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRelu_Op : Torch_Op<"aten.relu_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::relu_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLeakyReluOp : Torch_Op<"aten.leaky_relu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::leaky_relu : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$negative_slope
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $negative_slope attr-dict `:` type($self) `,` type($negative_slope) `->` type($result)";
}

def Torch_AtenLeakyRelu_Op : Torch_Op<"aten.leaky_relu_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::leaky_relu_ : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$negative_slope
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $negative_slope attr-dict `:` type($self) `,` type($negative_slope) `->` type($result)";
}

def Torch_AtenLogOp : Torch_Op<"aten.log", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLog_Op : Torch_Op<"aten.log_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSigmoidOp : Torch_Op<"aten.sigmoid", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sigmoid : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSigmoid_Op : Torch_Op<"aten.sigmoid_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sigmoid_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSinOp : Torch_Op<"aten.sin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sin : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSin_Op : Torch_Op<"aten.sin_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sin_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenExpOp : Torch_Op<"aten.exp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::exp : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenExp_Op : Torch_Op<"aten.exp_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::exp_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCosOp : Torch_Op<"aten.cos", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cos : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCos_Op : Torch_Op<"aten.cos_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cos_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNegOp : Torch_Op<"aten.neg", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::neg : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNeg_Op : Torch_Op<"aten.neg_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::neg_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFloorOp : Torch_Op<"aten.floor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::floor : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFloor_Op : Torch_Op<"aten.floor_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::floor_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCeilOp : Torch_Op<"aten.ceil", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ceil : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCeil_Op : Torch_Op<"aten.ceil_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ceil_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenBitwiseNotOp : Torch_Op<"aten.bitwise_not", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_not : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenBitwiseNot_Op : Torch_Op<"aten.bitwise_not_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_not_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAddTensorOp : Torch_Op<"aten.add.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::add.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenAdd_TensorOp : Torch_Op<"aten.add_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::add_.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSubTensorOp : Torch_Op<"aten.sub.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sub.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSub_TensorOp : Torch_Op<"aten.sub_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sub_.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenMulTensorOp : Torch_Op<"aten.mul.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mul.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMul_TensorOp : Torch_Op<"aten.mul_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mul_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDivTensorOp : Torch_Op<"aten.div.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::div.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDiv_TensorOp : Torch_Op<"aten.div_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::div_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLerpTensorOp : Torch_Op<"aten.lerp.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lerp.Tensor : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$end,
    AnyTorchTensorType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $end `,` $weight attr-dict `:` type($self) `,` type($end) `,` type($weight) `->` type($result)";
}

def Torch_AtenLerp_TensorOp : Torch_Op<"aten.lerp_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lerp_.Tensor : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$end,
    AnyTorchTensorType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $end `,` $weight attr-dict `:` type($self) `,` type($end) `,` type($weight) `->` type($result)";
}

def Torch_AtenEqTensorOp : Torch_Op<"aten.eq.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenEq_TensorOp : Torch_Op<"aten.eq_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eq_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGtTensorOp : Torch_Op<"aten.gt.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gt.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGt_TensorOp : Torch_Op<"aten.gt_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gt_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLtTensorOp : Torch_Op<"aten.lt.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lt.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLt_TensorOp : Torch_Op<"aten.lt_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lt_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNeTensorOp : Torch_Op<"aten.ne.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ne.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNe_TensorOp : Torch_Op<"aten.ne_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ne_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenAddScalarOp : Torch_Op<"aten.add.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::add.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenAdd_ScalarOp : Torch_Op<"aten.add_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::add_.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSubScalarOp : Torch_Op<"aten.sub.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sub.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSub_ScalarOp : Torch_Op<"aten.sub_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sub_.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenMulScalarOp : Torch_Op<"aten.mul.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mul.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMul_ScalarOp : Torch_Op<"aten.mul_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mul_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDivScalarOp : Torch_Op<"aten.div.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::div.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDiv_ScalarOp : Torch_Op<"aten.div_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::div_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNeScalarOp : Torch_Op<"aten.ne.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ne.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNe_ScalarOp : Torch_Op<"aten.ne_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ne_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenEqScalarOp : Torch_Op<"aten.eq.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenEq_ScalarOp : Torch_Op<"aten.eq_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eq_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGtScalarOp : Torch_Op<"aten.gt.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gt.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGt_ScalarOp : Torch_Op<"aten.gt_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gt_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGeScalarOp : Torch_Op<"aten.ge.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ge.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGe_ScalarOp : Torch_Op<"aten.ge_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ge_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLtScalarOp : Torch_Op<"aten.lt.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lt.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLt_ScalarOp : Torch_Op<"aten.lt_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lt_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFmodScalarOp : Torch_Op<"aten.fmod.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fmod.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFmod_ScalarOp : Torch_Op<"aten.fmod_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fmod_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMaskedFillScalarOp : Torch_Op<"aten.masked_fill.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::masked_fill.Scalar : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $value attr-dict `:` type($self) `,` type($mask) `,` type($value) `->` type($result)";
}

def Torch_AtenMaskedFill_ScalarOp : Torch_Op<"aten.masked_fill_.Scalar", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::masked_fill_.Scalar : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $value attr-dict `:` type($self) `,` type($mask) `,` type($value) `->` type($result)";
}

def Torch_AtenClampOp : Torch_Op<"aten.clamp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clamp : (Tensor, Scalar?, Scalar?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$min,
    AnyTorchOptionalScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenClamp_Op : Torch_Op<"aten.clamp_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_ : (Tensor, Scalar?, Scalar?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$min,
    AnyTorchOptionalScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenLog2Op : Torch_Op<"aten.log2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log2 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLog2_Op : Torch_Op<"aten.log2_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log2_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRsqrtOp : Torch_Op<"aten.rsqrt", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rsqrt : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRsqrt_Op : Torch_Op<"aten.rsqrt_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rsqrt_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAbsOp : Torch_Op<"aten.abs", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::abs : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAbs_Op : Torch_Op<"aten.abs_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::abs_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenReciprocalOp : Torch_Op<"aten.reciprocal", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reciprocal : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenReciprocal_Op : Torch_Op<"aten.reciprocal_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reciprocal_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenBitwiseAndTensorOp : Torch_Op<"aten.bitwise_and.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_and.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseAnd_TensorOp : Torch_Op<"aten.bitwise_and_.Tensor", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_and_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenThresholdOp : Torch_Op<"aten.threshold", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::threshold : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$threshold,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $threshold `,` $value attr-dict `:` type($self) `,` type($threshold) `,` type($value) `->` type($result)";
}

def Torch_AtenThreshold_Op : Torch_Op<"aten.threshold_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::threshold_ : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$threshold,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $threshold `,` $value attr-dict `:` type($self) `,` type($threshold) `,` type($value) `->` type($result)";
}

def Torch_AtenAddcmulOp : Torch_Op<"aten.addcmul", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::addcmul : (Tensor, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor1,
    AnyTorchTensorType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value) `->` type($result)";
}

def Torch_AtenAddcdivOp : Torch_Op<"aten.addcdiv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::addcdiv : (Tensor, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor1,
    AnyTorchTensorType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value) `->` type($result)";
}

def Torch_AtenMaximumOp : Torch_Op<"aten.maximum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::maximum : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMinimumOp : Torch_Op<"aten.minimum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::minimum : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenRsubScalarOp : Torch_Op<"aten.rsub.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rsub.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenGeluOp : Torch_Op<"aten.gelu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gelu : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenPowTensorScalarOp : Torch_Op<"aten.pow.Tensor_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pow.Tensor_Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenThresholdBackwardOp : Torch_Op<"aten.threshold_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::threshold_backward : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$threshold
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $threshold attr-dict `:` type($grad_output) `,` type($self) `,` type($threshold) `->` type($result)";
}

def Torch_AtenTriuOp : Torch_Op<"aten.triu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::triu : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal attr-dict `:` type($self) `,` type($diagonal) `->` type($result)";
}

def Torch_AtenTriu_Op : Torch_Op<"aten.triu_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::triu_ : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal attr-dict `:` type($self) `,` type($diagonal) `->` type($result)";
}

def Torch_AtenIndexPutOp : Torch_Op<"aten.index_put", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_put : (Tensor, Tensor?[], Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchListOptionalTensorType:$indices,
    AnyTorchTensorType:$values,
    Torch_BoolType:$accumulate
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $values `,` $accumulate attr-dict `:` type($self) `,` type($indices) `,` type($values) `,` type($accumulate) `->` type($result)";
}

def Torch_AtenIndexPut_Op : Torch_Op<"aten.index_put_", [
    IsTrailingUnderscoreInplaceVariant,
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_put_ : (Tensor, Tensor?[], Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchListOptionalTensorType:$indices,
    AnyTorchTensorType:$values,
    Torch_BoolType:$accumulate
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $values `,` $accumulate attr-dict `:` type($self) `,` type($indices) `,` type($values) `,` type($accumulate) `->` type($result)";
}

def Torch_AtenLinearOp : Torch_Op<"aten.linear", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linear : (Tensor, Tensor, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias attr-dict `:` type($input) `,` type($weight) `,` type($bias) `->` type($result)";
}

def Torch_AtenMmOp : Torch_Op<"aten.mm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mm : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat2 attr-dict `:` type($self) `,` type($mat2) `->` type($result)";
}

def Torch_AtenAddmmOp : Torch_Op<"aten.addmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::addmm : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat1 `,` $mat2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($mat1) `,` type($mat2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenMatmulOp : Torch_Op<"aten.matmul", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::matmul : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenConv2dOp : Torch_Op<"aten.conv2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv2d : (Tensor, Tensor, Tensor?, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenBatchNormOp : Torch_Op<"aten.batch_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm : (Tensor, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$training,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps,
    Torch_BoolType:$cudnn_enabled
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $training `,` $momentum `,` $eps `,` $cudnn_enabled attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($training) `,` type($momentum) `,` type($eps) `,` type($cudnn_enabled) `->` type($result)";
}

def Torch_AtenLayerNormOp : Torch_Op<"aten.layer_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::layer_norm : (Tensor, int[], Tensor?, Tensor?, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchIntListType:$normalized_shape,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    Torch_FloatType:$eps,
    Torch_BoolType:$cudnn_enable
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $normalized_shape `,` $weight `,` $bias `,` $eps `,` $cudnn_enable attr-dict `:` type($input) `,` type($normalized_shape) `,` type($weight) `,` type($bias) `,` type($eps) `,` type($cudnn_enable) `->` type($result)";
}

def Torch_AtenNativeLayerNormOp : Torch_Op<"aten.native_layer_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_layer_norm : (Tensor, int[], Tensor?, Tensor?, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchIntListType:$normalized_shape,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    Torch_FloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $normalized_shape `,` $weight `,` $bias `,` $eps attr-dict `:` type($input) `,` type($normalized_shape) `,` type($weight) `,` type($bias) `,` type($eps) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMaxPool2dOp : Torch_Op<"aten.max_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool2d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenSoftmaxIntOp : Torch_Op<"aten.softmax.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::softmax.int : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenLogSoftmaxIntOp : Torch_Op<"aten.log_softmax.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log_softmax.int : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenAdaptiveAvgPool2dOp : Torch_Op<"aten.adaptive_avg_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_avg_pool2d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result)";
}

def Torch_AtenTopkOp : Torch_Op<"aten.topk", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::topk : (Tensor, int, int, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    Torch_IntType:$dim,
    Torch_BoolType:$largest,
    Torch_BoolType:$sorted
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $k `,` $dim `,` $largest `,` $sorted attr-dict `:` type($self) `,` type($k) `,` type($dim) `,` type($largest) `,` type($sorted) `->` type($values) `,` type($indices)";
}

def Torch_AtenTransposeIntOp : Torch_Op<"aten.transpose.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::transpose.int : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim0,
    Torch_IntType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_AtenPermuteOp : Torch_Op<"aten.permute", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::permute : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dims
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dims attr-dict `:` type($self) `,` type($dims) `->` type($result)";
}

def Torch_AtenBmmOp : Torch_Op<"aten.bmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bmm : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat2 attr-dict `:` type($self) `,` type($mat2) `->` type($result)";
}

def Torch_AtenCumsumOp : Torch_Op<"aten.cumsum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumsum : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenFloorDivideScalarOp : Torch_Op<"aten.floor_divide.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::floor_divide.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogsumexpOp : Torch_Op<"aten.logsumexp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logsumexp : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenMeanDimOp : Torch_Op<"aten.mean.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mean.dim : (Tensor, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten__And__TensorOp : Torch_Op<"aten.__and__.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__and__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSqrtOp : Torch_Op<"aten.sqrt", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sqrt : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_SoftmaxOp : Torch_Op<"aten._softmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_softmax : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$half_to_float
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $half_to_float attr-dict `:` type($self) `,` type($dim) `,` type($half_to_float) `->` type($result)";
}

def Torch_AtenMeanOp : Torch_Op<"aten.mean", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mean : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_AtenNllLossForwardOp : Torch_Op<"aten.nll_loss_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss_forward : (Tensor, Tensor, Tensor?, int, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$total_weight
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `->` type($output) `,` type($total_weight)";
}

def Torch_AtenConstantPadNdOp : Torch_Op<"aten.constant_pad_nd", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::constant_pad_nd : (Tensor, int[], Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$pad,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $pad `,` $value attr-dict `:` type($self) `,` type($pad) `,` type($value) `->` type($result)";
}

def Torch_AtenSqueezeDimOp : Torch_Op<"aten.squeeze.dim", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::squeeze.dim : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenUnsqueezeOp : Torch_Op<"aten.unsqueeze", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unsqueeze : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenSqueezeOp : Torch_Op<"aten.squeeze", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::squeeze : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenFlattenUsingIntsOp : Torch_Op<"aten.flatten.using_ints", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::flatten.using_ints : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$start_dim,
    Torch_IntType:$end_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $start_dim `,` $end_dim attr-dict `:` type($self) `,` type($start_dim) `,` type($end_dim) `->` type($result)";
}

def Torch_AtenDimOp : Torch_Op<"aten.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dim : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenSizeOp : Torch_Op<"aten.size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::size : (Tensor) -> (int[])`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    TorchIntListType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
  let hasCanonicalizer = 1;
}

def Torch_AtenFill_ScalarOp : Torch_Op<"aten.fill_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fill_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $value attr-dict `:` type($self) `,` type($value) `->` type($result)";
}

def Torch_AtenBoolTensorOp : Torch_Op<"aten.Bool.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::Bool.Tensor : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$a
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenOnesOp : Torch_Op<"aten.ones", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ones : (int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenZerosOp : Torch_Op<"aten.zeros", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::zeros : (int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenTensorOp : Torch_Op<"aten.tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tensor : (t[], int?, Device?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchListType:$data,
    TorchOptionalIntType:$dtype,
    TorchOptionalDeviceType:$device,
    Torch_BoolType:$requires_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$data `,` $dtype `,` $device `,` $requires_grad attr-dict `:` type($data) `,` type($dtype) `,` type($device) `,` type($requires_grad) `->` type($result)";
}

def Torch_AtenTensorBoolOp : Torch_Op<"aten.tensor.bool", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tensor.bool : (bool, int?, Device?, bool) -> (Tensor)`";
  let arguments = (ins
    Torch_BoolType:$t,
    TorchOptionalIntType:$dtype,
    TorchOptionalDeviceType:$device,
    Torch_BoolType:$requires_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$t `,` $dtype `,` $device `,` $requires_grad attr-dict `:` type($t) `,` type($dtype) `,` type($device) `,` type($requires_grad) `->` type($result)";
}

def Torch_AtenTensorIntOp : Torch_Op<"aten.tensor.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tensor.int : (int, int?, Device?, bool) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$t,
    TorchOptionalIntType:$dtype,
    TorchOptionalDeviceType:$device,
    Torch_BoolType:$requires_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$t `,` $dtype `,` $device `,` $requires_grad attr-dict `:` type($t) `,` type($dtype) `,` type($device) `,` type($requires_grad) `->` type($result)";
}

def Torch_Aten_ShapeAsTensorOp : Torch_Op<"aten._shape_as_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_shape_as_tensor : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAllOp : Torch_Op<"aten.all", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::all : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAnyOp : Torch_Op<"aten.any", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::any : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAnyDimOp : Torch_Op<"aten.any.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::any.dim : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenArangeOp : Torch_Op<"aten.arange", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arange : (Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$end `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($end) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenArangeStartOp : Torch_Op<"aten.arange.start", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arange.start : (Scalar, Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($start) `,` type($end) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenArangeStartStepOp : Torch_Op<"aten.arange.start_step", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arange.start_step : (Scalar, Scalar, Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    AnyTorchScalarType:$step,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $step `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($start) `,` type($end) `,` type($step) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenArgmaxOp : Torch_Op<"aten.argmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::argmax : (Tensor, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenBucketizeTensorOp : Torch_Op<"aten.bucketize.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bucketize.Tensor : (Tensor, Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$boundaries,
    Torch_BoolType:$out_int32,
    Torch_BoolType:$right
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $boundaries `,` $out_int32 `,` $right attr-dict `:` type($self) `,` type($boundaries) `,` type($out_int32) `,` type($right) `->` type($result)";
}

def Torch_AtenContiguousOp : Torch_Op<"aten.contiguous", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::contiguous : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $memory_format attr-dict `:` type($self) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenCopy_Op : Torch_Op<"aten.copy_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::copy_ : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$src,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $src `,` $non_blocking attr-dict `:` type($self) `,` type($src) `,` type($non_blocking) `->` type($result)";
}

def Torch_AtenDetachOp : Torch_Op<"aten.detach", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::detach : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenEmbeddingOp : Torch_Op<"aten.embedding", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::embedding : (Tensor, Tensor, int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$indices,
    Torch_IntType:$padding_idx,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_BoolType:$sparse
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight `,` $indices `,` $padding_idx `,` $scale_grad_by_freq `,` $sparse attr-dict `:` type($weight) `,` type($indices) `,` type($padding_idx) `,` type($scale_grad_by_freq) `,` type($sparse) `->` type($result)";
}

def Torch_AtenEmptyLikeOp : Torch_Op<"aten.empty_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::empty_like : (Tensor, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenZerosLikeOp : Torch_Op<"aten.zeros_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::zeros_like : (Tensor, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenOnesLikeOp : Torch_Op<"aten.ones_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ones_like : (Tensor, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenEmptyMemoryFormatOp : Torch_Op<"aten.empty.memory_format", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::empty.memory_format : (int[], int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenExpandOp : Torch_Op<"aten.expand", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::expand : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    Torch_BoolType:$implicit
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $implicit attr-dict `:` type($self) `,` type($size) `,` type($implicit) `->` type($result)";
}

def Torch_AtenBroadcastToOp : Torch_Op<"aten.broadcast_to", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::broadcast_to : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size attr-dict `:` type($self) `,` type($size) `->` type($result)";
}

def Torch_AtenIndexTensorOp : Torch_Op<"aten.index.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index.Tensor : (Tensor, Tensor?[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchListOptionalTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices attr-dict `:` type($self) `,` type($indices) `->` type($result)";
}

def Torch_AtenIndexSelectOp : Torch_Op<"aten.index_select", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_select : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index attr-dict `:` type($self) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenItemOp : Torch_Op<"aten.item", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::item : (Tensor) -> (Scalar)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchScalarType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMaskedSelectOp : Torch_Op<"aten.masked_select", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::masked_select : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask attr-dict `:` type($self) `,` type($mask) `->` type($result)";
}

def Torch_AtenNumelOp : Torch_Op<"aten.numel", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::numel : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRepeatOp : Torch_Op<"aten.repeat", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::repeat : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$repeats
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $repeats attr-dict `:` type($self) `,` type($repeats) `->` type($result)";
}

def Torch_AtenReshapeOp : Torch_Op<"aten.reshape", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reshape : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$shape
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $shape attr-dict `:` type($self) `,` type($shape) `->` type($result)";
}

def Torch_AtenResize_Op : Torch_Op<"aten.resize_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::resize_ : (Tensor, int[], int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $memory_format attr-dict `:` type($self) `,` type($size) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenSelectIntOp : Torch_Op<"aten.select.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::select.int : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_IntType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index attr-dict `:` type($self) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenSizeIntOp : Torch_Op<"aten.size.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::size.int : (Tensor, int) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenStackOp : Torch_Op<"aten.stack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::stack : (Tensor[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_AtenSumOp : Torch_Op<"aten.sum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sum : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_AtenSumDimIntListOp : Torch_Op<"aten.sum.dim_IntList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sum.dim_IntList : (Tensor, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenToDtypeOp : Torch_Op<"aten.to.dtype", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::to.dtype : (Tensor, int, bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dtype,
    Torch_BoolType:$non_blocking,
    Torch_BoolType:$copy,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $non_blocking `,` $copy `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($non_blocking) `,` type($copy) `,` type($memory_format) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenToOtherOp : Torch_Op<"aten.to.other", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::to.other : (Tensor, Tensor, bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    Torch_BoolType:$non_blocking,
    Torch_BoolType:$copy,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $non_blocking `,` $copy `,` $memory_format attr-dict `:` type($self) `,` type($other) `,` type($non_blocking) `,` type($copy) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenToPrimDeviceOp : Torch_Op<"aten.to.prim_Device", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::to.prim_Device : (Tensor, Device?, int?, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalDeviceType:$device,
    TorchOptionalIntType:$dtype,
    Torch_BoolType:$non_blocking,
    Torch_BoolType:$copy
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $device `,` $dtype `,` $non_blocking `,` $copy attr-dict `:` type($self) `,` type($device) `,` type($dtype) `,` type($non_blocking) `,` type($copy) `->` type($result)";
}

def Torch_AtenTypeAsOp : Torch_Op<"aten.type_as", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::type_as : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenViewOp : Torch_Op<"aten.view", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::view : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size attr-dict `:` type($self) `,` type($size) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenWhereSelfOp : Torch_Op<"aten.where.self", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::where.self : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$condition,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$condition `,` $self `,` $other attr-dict `:` type($condition) `,` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSliceTensorOp : Torch_Op<"aten.slice.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slice.Tensor : (Tensor, int, int?, int?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$start,
    TorchOptionalIntType:$end,
    Torch_IntType:$step
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $start `,` $end `,` $step attr-dict `:` type($self) `,` type($dim) `,` type($start) `,` type($end) `,` type($step) `->` type($result)";
}

def Torch_AtenLenTensorOp : Torch_Op<"aten.len.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::len.Tensor : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$t
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$t attr-dict `:` type($t) `->` type($result)";
}

def Torch_AtenCpuOp : Torch_Op<"aten.cpu", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cpu : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenGatherOp : Torch_Op<"aten.gather", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gather : (Tensor, int, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    Torch_BoolType:$sparse_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $sparse_grad attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($sparse_grad) `->` type($result)";
}

def Torch_AtenIntImplicitOp : Torch_Op<"aten.IntImplicit", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::IntImplicit : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$a
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenTensorFloatOp : Torch_Op<"aten.tensor.float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tensor.float : (float, int?, Device?, bool) -> (Tensor)`";
  let arguments = (ins
    Torch_FloatType:$t,
    TorchOptionalIntType:$dtype,
    TorchOptionalDeviceType:$device,
    Torch_BoolType:$requires_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$t `,` $dtype `,` $device `,` $requires_grad attr-dict `:` type($t) `,` type($dtype) `,` type($device) `,` type($requires_grad) `->` type($result)";
}

def Torch_AtenIntTensorOp : Torch_Op<"aten.Int.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::Int.Tensor : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$a
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenDropoutOp : Torch_Op<"aten.dropout", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dropout : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $p `,` $train attr-dict `:` type($input) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenTOp : Torch_Op<"aten.t", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::t : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten__Contains__StrOp : Torch_Op<"aten.__contains__.str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__contains__.str : (Dict(str, t), str) -> (bool)`";
  let arguments = (ins
    Torch_DictType:$dict,
    Torch_StringType:$key
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$dict `,` $key attr-dict `:` type($dict) `,` type($key) `->` type($result)";
  let hasFolder = 1;
}

def Torch_Aten__Getitem__DictStrOp : Torch_Op<"aten.__getitem__.Dict_str", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__getitem__.Dict_str : (Dict(str, t), str) -> (t)`";
  let arguments = (ins
    Torch_DictType:$self,
    Torch_StringType:$key
  );
  let results = (outs
    AnyTorchType:$result
  );
  let assemblyFormat = "$self `,` $key attr-dict `:` type($self) `,` type($key) `->` type($result)";
  let hasFolder = 1;
}

def Torch_Aten_SetItemStrOp : Torch_Op<"aten._set_item.str", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_set_item.str : (Dict(str, t), str, t) -> ()`";
  let arguments = (ins
    Torch_DictType:$l,
    Torch_StringType:$idx,
    AnyTorchType:$v
  );
  let results = (outs
  );
  let assemblyFormat = "$l `,` $idx `,` $v attr-dict `:` type($l) `,` type($idx) `,` type($v)";
}

def Torch_AtenKeysStrOp : Torch_Op<"aten.keys.str", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::keys.str : (Dict(str, t)) -> (str[])`";
  let arguments = (ins
    Torch_DictType:$self
  );
  let results = (outs
    TorchStringListType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenGetDefaultStrOp : Torch_Op<"aten.get.default_str", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::get.default_str : (Dict(str, t), str, t) -> (t)`";
  let arguments = (ins
    Torch_DictType:$self,
    Torch_StringType:$key,
    AnyTorchType:$default_value
  );
  let results = (outs
    AnyTorchType:$result
  );
  let assemblyFormat = "$self `,` $key `,` $default_value attr-dict `:` type($self) `,` type($key) `,` type($default_value) `->` type($result)";
}

def Torch_AtenDeleteDictStrOp : Torch_Op<"aten.Delete.Dict_str", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::Delete.Dict_str : (Dict(str, t), str) -> ()`";
  let arguments = (ins
    Torch_DictType:$self,
    Torch_StringType:$key
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $key attr-dict `:` type($self) `,` type($key)";
}

def Torch_AtenCatOp : Torch_Op<"aten.cat", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cat : (Tensor[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_AtenAppendTOp : Torch_Op<"aten.append.t", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::append.t : (t[], t) -> (t[])`";
  let arguments = (ins
    AnyTorchListType:$self,
    AnyTorchType:$el
  );
  let results = (outs
    AnyTorchListType:$result
  );
  let assemblyFormat = "$self `,` $el attr-dict `:` type($self) `,` type($el) `->` type($result)";
}

def Torch_AtenAddTOp : Torch_Op<"aten.add.t", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::add.t : (t[], t[]) -> (t[])`";
  let arguments = (ins
    AnyTorchListType:$a,
    AnyTorchListType:$b
  );
  let results = (outs
    AnyTorchListType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenEqIntListOp : Torch_Op<"aten.eq.int_list", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.int_list : (int[], int[]) -> (bool)`";
  let arguments = (ins
    TorchIntListType:$a,
    TorchIntListType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenListTOp : Torch_Op<"aten.list.t", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::list.t : (t[]) -> (t[])`";
  let arguments = (ins
    AnyTorchListType:$l
  );
  let results = (outs
    AnyTorchListType:$result
  );
  let assemblyFormat = "$l attr-dict `:` type($l) `->` type($result)";
}

def Torch_AtenSliceTOp : Torch_Op<"aten.slice.t", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slice.t : (t[], int?, int?, int) -> (t[])`";
  let arguments = (ins
    AnyTorchListType:$l,
    TorchOptionalIntType:$start,
    TorchOptionalIntType:$end,
    Torch_IntType:$step
  );
  let results = (outs
    AnyTorchListType:$result
  );
  let assemblyFormat = "$l `,` $start `,` $end `,` $step attr-dict `:` type($l) `,` type($start) `,` type($end) `,` type($step) `->` type($result)";
}

def Torch_AtenAddStrOp : Torch_Op<"aten.add.str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::add.str : (str, str) -> (str)`";
  let arguments = (ins
    Torch_StringType:$a,
    Torch_StringType:$b
  );
  let results = (outs
    Torch_StringType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenEqStrOp : Torch_Op<"aten.eq.str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.str : (str, str) -> (bool)`";
  let arguments = (ins
    Torch_StringType:$a,
    Torch_StringType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenStrOp : Torch_Op<"aten.str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::str : (t) -> (str)`";
  let arguments = (ins
    AnyTorchType:$elem
  );
  let results = (outs
    Torch_StringType:$result
  );
  let assemblyFormat = "$elem attr-dict `:` type($elem) `->` type($result)";
}

def Torch_AtenFormatOp : Torch_Op<"aten.format", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::format : (...) -> (str)`";
  let arguments = (ins
    Variadic<AnyTorchType>:$operands
  );
  let results = (outs
    Torch_StringType:$result
  );
  let assemblyFormat = "`(` $operands `)` attr-dict `:` type($operands) `->` type($result)";
}

def Torch_AtenJoinOp : Torch_Op<"aten.join", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::join : (str, str[]) -> (str)`";
  let arguments = (ins
    Torch_StringType:$self,
    TorchStringListType:$values
  );
  let results = (outs
    Torch_StringType:$result
  );
  let assemblyFormat = "$self `,` $values attr-dict `:` type($self) `,` type($values) `->` type($result)";
}

def Torch_AtenFloatScalarOp : Torch_Op<"aten.Float.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::Float.Scalar : (Scalar) -> (float)`";
  let arguments = (ins
    AnyTorchScalarType:$a
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenFloatStrOp : Torch_Op<"aten.Float.str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::Float.str : (str) -> (float)`";
  let arguments = (ins
    Torch_StringType:$a
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenIntFloatOp : Torch_Op<"aten.Int.float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::Int.float : (float) -> (int)`";
  let arguments = (ins
    Torch_FloatType:$a
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenGtIntOp : Torch_Op<"aten.gt.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gt.int : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenGeIntOp : Torch_Op<"aten.ge.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ge.int : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenLtIntOp : Torch_Op<"aten.lt.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lt.int : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenLeIntOp : Torch_Op<"aten.le.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::le.int : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenNeIntOp : Torch_Op<"aten.ne.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ne.int : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenEqIntOp : Torch_Op<"aten.eq.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.int : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenFloordivIntOp : Torch_Op<"aten.floordiv.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::floordiv.int : (int, int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenRemainderIntOp : Torch_Op<"aten.remainder.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::remainder.int : (int, int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenAddIntOp : Torch_Op<"aten.add.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::add.int : (int, int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenSubIntOp : Torch_Op<"aten.sub.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sub.int : (int, int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenMulIntOp : Torch_Op<"aten.mul.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mul.int : (int, int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenNegIntOp : Torch_Op<"aten.neg.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::neg.int : (int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$a
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenLogIntOp : Torch_Op<"aten.log.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log.int : (int) -> (float)`";
  let arguments = (ins
    Torch_IntType:$a
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenAddFloatIntOp : Torch_Op<"aten.add.float_int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::add.float_int : (float, int) -> (float)`";
  let arguments = (ins
    Torch_FloatType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenMulFloatOp : Torch_Op<"aten.mul.float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mul.float : (float, float) -> (float)`";
  let arguments = (ins
    Torch_FloatType:$a,
    Torch_FloatType:$b
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenNegFloatOp : Torch_Op<"aten.neg.float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::neg.float : (float) -> (float)`";
  let arguments = (ins
    Torch_FloatType:$a
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
}

def Torch_AtenLtFloatIntOp : Torch_Op<"aten.lt.float_int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lt.float_int : (float, int) -> (bool)`";
  let arguments = (ins
    Torch_FloatType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenEqFloatOp : Torch_Op<"aten.eq.float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.float : (float, float) -> (bool)`";
  let arguments = (ins
    Torch_FloatType:$a,
    Torch_FloatType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_Aten__And__BoolOp : Torch_Op<"aten.__and__.bool", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__and__.bool : (bool, bool) -> (bool)`";
  let arguments = (ins
    Torch_BoolType:$a,
    Torch_BoolType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenNeBoolOp : Torch_Op<"aten.ne.bool", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ne.bool : (bool, bool) -> (bool)`";
  let arguments = (ins
    Torch_BoolType:$a,
    Torch_BoolType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
  let hasFolder = 1;
}

def Torch_Aten__Is__Op : Torch_Op<"aten.__is__", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__is__ : (t1, t2) -> (bool)`";
  let arguments = (ins
    AnyTorchType:$self,
    AnyTorchType:$obj
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $obj attr-dict `:` type($self) `,` type($obj) `->` type($result)";
  let hasFolder = 1;
}

def Torch_Aten__Isnot__Op : Torch_Op<"aten.__isnot__", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__isnot__ : (t1, t2) -> (bool)`";
  let arguments = (ins
    AnyTorchType:$self,
    AnyTorchType:$obj
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $obj attr-dict `:` type($self) `,` type($obj) `->` type($result)";
  let hasFolder = 1;
}

def Torch_Aten__Not__Op : Torch_Op<"aten.__not__", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__not__ : (bool) -> (bool)`";
  let arguments = (ins
    Torch_BoolType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
  let hasFolder = 1;
}

def Torch_AtenLenTOp : Torch_Op<"aten.len.t", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::len.t : (t[]) -> (int)`";
  let arguments = (ins
    AnyTorchListType:$a
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$a attr-dict `:` type($a) `->` type($result)";
  let hasFolder = 1;
  let hasCanonicalizer = 1;
}

def Torch_Aten__Getitem__TOp : Torch_Op<"aten.__getitem__.t", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__getitem__.t : (t[], int) -> (t)`";
  let arguments = (ins
    AnyTorchListType:$list,
    Torch_IntType:$idx
  );
  let results = (outs
    AnyTorchType:$result
  );
  let assemblyFormat = "$list `,` $idx attr-dict `:` type($list) `,` type($idx) `->` type($result)";
  let hasCanonicalizer = 1;
}

def Torch_Aten_SetItemTOp : Torch_Op<"aten._set_item.t", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_set_item.t : (t[], int, t) -> (t[])`";
  let arguments = (ins
    AnyTorchListType:$l,
    Torch_IntType:$idx,
    AnyTorchType:$el
  );
  let results = (outs
    AnyTorchListType:$result
  );
  let assemblyFormat = "$l `,` $idx `,` $el attr-dict `:` type($l) `,` type($idx) `,` type($el) `->` type($result)";
}

def Torch_AtenDivOp : Torch_Op<"aten.div", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::div : (Scalar, Scalar) -> (float)`";
  let arguments = (ins
    AnyTorchScalarType:$a,
    AnyTorchScalarType:$b
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_AtenEqDeviceOp : Torch_Op<"aten.eq.device", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eq.device : (Device, Device) -> (bool)`";
  let arguments = (ins
    Torch_DeviceType:$a,
    Torch_DeviceType:$b
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$a `,` $b attr-dict `:` type($a) `,` type($b) `->` type($result)";
}

def Torch_Aten_SoftmaxBackwardDataOp : Torch_Op<"aten._softmax_backward_data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_softmax_backward_data : (Tensor, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    Torch_IntType:$dim,
    Torch_IntType:$input_dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $dim `,` $input_dtype attr-dict `:` type($grad_output) `,` type($output) `,` type($dim) `,` type($input_dtype) `->` type($result)";
}

def Torch_AtenTanhBackwardOp : Torch_Op<"aten.tanh_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tanh_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output attr-dict `:` type($grad_output) `,` type($output) `->` type($result)";
}

def Torch_AtenGeluBackwardOp : Torch_Op<"aten.gelu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gelu_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self attr-dict `:` type($grad) `,` type($self) `->` type($result)";
}

def Torch_Aten_LogSoftmaxBackwardDataOp : Torch_Op<"aten._log_softmax_backward_data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_log_softmax_backward_data : (Tensor, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    Torch_IntType:$dim,
    Torch_IntType:$input_dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $dim `,` $input_dtype attr-dict `:` type($grad_output) `,` type($output) `,` type($dim) `,` type($input_dtype) `->` type($result)";
}

def Torch_AtenSparseMaskOp : Torch_Op<"aten.sparse_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_mask : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask attr-dict `:` type($self) `,` type($mask) `->` type($result)";
}

def Torch_AtenIntReprOp : Torch_Op<"aten.int_repr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::int_repr : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenQPerChannelZeroPointsOp : Torch_Op<"aten.q_per_channel_zero_points", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::q_per_channel_zero_points : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenQPerChannelScalesOp : Torch_Op<"aten.q_per_channel_scales", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::q_per_channel_scales : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenToDenseOp : Torch_Op<"aten.to_dense", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::to_dense : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_AtenHspmmOp : Torch_Op<"aten.hspmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hspmm : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$mat1 `,` $mat2 attr-dict `:` type($mat1) `,` type($mat2) `->` type($result)";
}

def Torch_AtenColIndicesOp : Torch_Op<"aten.col_indices", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::col_indices : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCrowIndicesOp : Torch_Op<"aten.crow_indices", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::crow_indices : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIndicesOp : Torch_Op<"aten.indices", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::indices : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenValuesOp : Torch_Op<"aten.values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::values : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenUnflattenDenseTensorsOp : Torch_Op<"aten.unflatten_dense_tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unflatten_dense_tensors : (Tensor, Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$flat,
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$flat `,` $tensors attr-dict `:` type($flat) `,` type($tensors) `->` type($result)";
}

def Torch_AtenFlattenDenseTensorsOp : Torch_Op<"aten.flatten_dense_tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::flatten_dense_tensors : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenPadSequenceOp : Torch_Op<"aten.pad_sequence", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pad_sequence : (Tensor[], bool, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$sequences,
    Torch_BoolType:$batch_first,
    Torch_FloatType:$padding_value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sequences `,` $batch_first `,` $padding_value attr-dict `:` type($sequences) `,` type($batch_first) `,` type($padding_value) `->` type($result)";
}

def Torch_AtenLinalgMatrixPowerOp : Torch_Op<"aten.linalg_matrix_power", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_power : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n attr-dict `:` type($self) `,` type($n) `->` type($result)";
}

def Torch_AtenLinalgNormOp : Torch_Op<"aten.linalg_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_norm : (Tensor, Scalar?, int[]?, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$ord,
    TorchOptionalIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenLinalgNormOrdStrOp : Torch_Op<"aten.linalg_norm.ord_str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_norm.ord_str : (Tensor, str, int[]?, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$ord,
    TorchOptionalIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenGerOp : Torch_Op<"aten.ger", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ger : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec2 attr-dict `:` type($self) `,` type($vec2) `->` type($result)";
}

def Torch_AtenOuterOp : Torch_Op<"aten.outer", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::outer : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec2 attr-dict `:` type($self) `,` type($vec2) `->` type($result)";
}

def Torch_AtenInnerOp : Torch_Op<"aten.inner", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::inner : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLinalgMatmulOp : Torch_Op<"aten.linalg_matmul", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matmul : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDetOp : Torch_Op<"aten.det", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::det : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgDetOp : Torch_Op<"aten.linalg_det", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_det : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFftIfftshiftOp : Torch_Op<"aten.fft_ifftshift", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ifftshift : (Tensor, int[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenFftFftshiftOp : Torch_Op<"aten.fft_fftshift", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_fftshift : (Tensor, int[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenFftIhfftnOp : Torch_Op<"aten.fft_ihfftn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ihfftn : (Tensor, int[]?, int[]?, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenFftHfftnOp : Torch_Op<"aten.fft_hfftn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_hfftn : (Tensor, int[]?, int[]?, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenFftIhfft2Op : Torch_Op<"aten.fft_ihfft2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ihfft2 : (Tensor, int[]?, int[], str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenFftHfft2Op : Torch_Op<"aten.fft_hfft2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_hfft2 : (Tensor, int[]?, int[], str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenSpecialSoftmaxOp : Torch_Op<"aten.special_softmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_softmax : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenSpecialMultigammalnOp : Torch_Op<"aten.special_multigammaln", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_multigammaln : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenSpecialGammainccOp : Torch_Op<"aten.special_gammaincc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_gammaincc : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialGammaincOp : Torch_Op<"aten.special_gammainc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_gammainc : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialLogSoftmaxOp : Torch_Op<"aten.special_log_softmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_log_softmax : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenSpecialLog1pOp : Torch_Op<"aten.special_log1p", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_log1p : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialRoundOp : Torch_Op<"aten.special_round", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_round : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialSincOp : Torch_Op<"aten.special_sinc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_sinc : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialExpitOp : Torch_Op<"aten.special_expit", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_expit : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialLogsumexpOp : Torch_Op<"aten.special_logsumexp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_logsumexp : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenSpecialPolygammaOp : Torch_Op<"aten.special_polygamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_polygamma : (int, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $self attr-dict `:` type($n) `,` type($self) `->` type($result)";
}

def Torch_AtenSpecialLogitOp : Torch_Op<"aten.special_logit", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_logit : (Tensor, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $eps attr-dict `:` type($self) `,` type($eps) `->` type($result)";
}

def Torch_AtenSpecialI0Op : Torch_Op<"aten.special_i0", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_i0 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialXlogyOp : Torch_Op<"aten.special_xlogy", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_xlogy : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialXlogySelfScalarOp : Torch_Op<"aten.special_xlogy.self_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_xlogy.self_scalar : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialXlogyOtherScalarOp : Torch_Op<"aten.special_xlogy.other_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_xlogy.other_scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialNdtrOp : Torch_Op<"aten.special_ndtr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_ndtr : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialErfinvOp : Torch_Op<"aten.special_erfinv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_erfinv : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialErfcOp : Torch_Op<"aten.special_erfc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_erfc : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialErfOp : Torch_Op<"aten.special_erf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_erf : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialGammalnOp : Torch_Op<"aten.special_gammaln", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_gammaln : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialDigammaOp : Torch_Op<"aten.special_digamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_digamma : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialPsiOp : Torch_Op<"aten.special_psi", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_psi : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialExp2Op : Torch_Op<"aten.special_exp2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_exp2 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialExpm1Op : Torch_Op<"aten.special_expm1", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_expm1 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenColumnStackOp : Torch_Op<"aten.column_stack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::column_stack : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenNllLossNdOp : Torch_Op<"aten.nll_loss_nd", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss_nd : (Tensor, Tensor, Tensor?, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `->` type($result)";
}

def Torch_AtenFloatPowerTensorTensorOp : Torch_Op<"aten.float_power.Tensor_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::float_power.Tensor_Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenFloatPowerScalarOp : Torch_Op<"aten.float_power.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::float_power.Scalar : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenFloatPowerTensorScalarOp : Torch_Op<"aten.float_power.Tensor_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::float_power.Tensor_Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenArgsortOp : Torch_Op<"aten.argsort", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::argsort : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$descending
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $descending attr-dict `:` type($self) `,` type($dim) `,` type($descending) `->` type($result)";
}

def Torch_AtenArgsortDimnameOp : Torch_Op<"aten.argsort.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::argsort.dimname : (Tensor, str, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$descending
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $descending attr-dict `:` type($self) `,` type($dim) `,` type($descending) `->` type($result)";
}

def Torch_AtenMsortOp : Torch_Op<"aten.msort", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::msort : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCrossEntropyLossOp : Torch_Op<"aten.cross_entropy_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cross_entropy_loss : (Tensor, Tensor, Tensor?, int, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    Torch_FloatType:$label_smoothing
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $label_smoothing attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($label_smoothing) `->` type($result)";
}

def Torch_AtenArgwhereOp : Torch_Op<"aten.argwhere", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::argwhere : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNonzeroNumpyOp : Torch_Op<"aten.nonzero_numpy", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nonzero_numpy : (Tensor) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenTakeAlongDimOp : Torch_Op<"aten.take_along_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::take_along_dim : (Tensor, Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchOptionalIntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $dim attr-dict `:` type($self) `,` type($indices) `,` type($dim) `->` type($result)";
}

def Torch_AtenLessScalarOp : Torch_Op<"aten.less.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::less.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLessTensorOp : Torch_Op<"aten.less.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::less.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterScalarOp : Torch_Op<"aten.greater.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::greater.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterTensorOp : Torch_Op<"aten.greater.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::greater.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLessEqualScalarOp : Torch_Op<"aten.less_equal.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::less_equal.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLessEqualTensorOp : Torch_Op<"aten.less_equal.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::less_equal.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterEqualScalarOp : Torch_Op<"aten.greater_equal.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::greater_equal.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterEqualTensorOp : Torch_Op<"aten.greater_equal.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::greater_equal.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNotEqualScalarOp : Torch_Op<"aten.not_equal.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::not_equal.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNotEqualTensorOp : Torch_Op<"aten.not_equal.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::not_equal.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIndexAddOp : Torch_Op<"aten.index_add", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_add : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenIndexAddAlphaOp : Torch_Op<"aten.index_add.alpha", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_add.alpha : (Tensor, int, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source `,` $alpha attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `,` type($alpha) `->` type($result)";
}

def Torch_AtenIndexAddDimnameOp : Torch_Op<"aten.index_add.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_add.dimname : (Tensor, str, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source `,` $alpha attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `,` type($alpha) `->` type($result)";
}

def Torch_AtenPutOp : Torch_Op<"aten.put", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::put : (Tensor, Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source,
    Torch_BoolType:$accumulate
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $index `,` $source `,` $accumulate attr-dict `:` type($self) `,` type($index) `,` type($source) `,` type($accumulate) `->` type($result)";
}

def Torch_AtenMaskedScatterOp : Torch_Op<"aten.masked_scatter", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::masked_scatter : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $source attr-dict `:` type($self) `,` type($mask) `,` type($source) `->` type($result)";
}

def Torch_AtenQuantizedRnnTanhCellOp : Torch_Op<"aten.quantized_rnn_tanh_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_rnn_tanh_cell : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Scalar, Scalar, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchTensorType:$b_ih,
    AnyTorchTensorType:$b_hh,
    AnyTorchTensorType:$packed_ih,
    AnyTorchTensorType:$packed_hh,
    AnyTorchTensorType:$col_offsets_ih,
    AnyTorchTensorType:$col_offsets_hh,
    AnyTorchScalarType:$scale_ih,
    AnyTorchScalarType:$scale_hh,
    AnyTorchScalarType:$zero_point_ih,
    AnyTorchScalarType:$zero_point_hh
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh `,` $packed_ih `,` $packed_hh `,` $col_offsets_ih `,` $col_offsets_hh `,` $scale_ih `,` $scale_hh `,` $zero_point_ih `,` $zero_point_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `,` type($packed_ih) `,` type($packed_hh) `,` type($col_offsets_ih) `,` type($col_offsets_hh) `,` type($scale_ih) `,` type($scale_hh) `,` type($zero_point_ih) `,` type($zero_point_hh) `->` type($result)";
}

def Torch_AtenQuantizedRnnReluCellOp : Torch_Op<"aten.quantized_rnn_relu_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_rnn_relu_cell : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Scalar, Scalar, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchTensorType:$b_ih,
    AnyTorchTensorType:$b_hh,
    AnyTorchTensorType:$packed_ih,
    AnyTorchTensorType:$packed_hh,
    AnyTorchTensorType:$col_offsets_ih,
    AnyTorchTensorType:$col_offsets_hh,
    AnyTorchScalarType:$scale_ih,
    AnyTorchScalarType:$scale_hh,
    AnyTorchScalarType:$zero_point_ih,
    AnyTorchScalarType:$zero_point_hh
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh `,` $packed_ih `,` $packed_hh `,` $col_offsets_ih `,` $col_offsets_hh `,` $scale_ih `,` $scale_hh `,` $zero_point_ih `,` $zero_point_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `,` type($packed_ih) `,` type($packed_hh) `,` type($col_offsets_ih) `,` type($col_offsets_hh) `,` type($scale_ih) `,` type($scale_hh) `,` type($zero_point_ih) `,` type($zero_point_hh) `->` type($result)";
}

def Torch_AtenQuantizedGruCellOp : Torch_Op<"aten.quantized_gru_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_gru_cell : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Scalar, Scalar, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchTensorType:$b_ih,
    AnyTorchTensorType:$b_hh,
    AnyTorchTensorType:$packed_ih,
    AnyTorchTensorType:$packed_hh,
    AnyTorchTensorType:$col_offsets_ih,
    AnyTorchTensorType:$col_offsets_hh,
    AnyTorchScalarType:$scale_ih,
    AnyTorchScalarType:$scale_hh,
    AnyTorchScalarType:$zero_point_ih,
    AnyTorchScalarType:$zero_point_hh
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh `,` $packed_ih `,` $packed_hh `,` $col_offsets_ih `,` $col_offsets_hh `,` $scale_ih `,` $scale_hh `,` $zero_point_ih `,` $zero_point_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `,` type($packed_ih) `,` type($packed_hh) `,` type($col_offsets_ih) `,` type($col_offsets_hh) `,` type($scale_ih) `,` type($scale_hh) `,` type($zero_point_ih) `,` type($zero_point_hh) `->` type($result)";
}

def Torch_AtenQuantizedLstmCellOp : Torch_Op<"aten.quantized_lstm_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_lstm_cell : (Tensor, Tensor[], Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Scalar, Scalar, Scalar, Scalar) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchTensorType:$b_ih,
    AnyTorchTensorType:$b_hh,
    AnyTorchTensorType:$packed_ih,
    AnyTorchTensorType:$packed_hh,
    AnyTorchTensorType:$col_offsets_ih,
    AnyTorchTensorType:$col_offsets_hh,
    AnyTorchScalarType:$scale_ih,
    AnyTorchScalarType:$scale_hh,
    AnyTorchScalarType:$zero_point_ih,
    AnyTorchScalarType:$zero_point_hh
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh `,` $packed_ih `,` $packed_hh `,` $col_offsets_ih `,` $col_offsets_hh `,` $scale_ih `,` $scale_hh `,` $zero_point_ih `,` $zero_point_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `,` type($packed_ih) `,` type($packed_hh) `,` type($col_offsets_ih) `,` type($col_offsets_hh) `,` type($scale_ih) `,` type($scale_hh) `,` type($zero_point_ih) `,` type($zero_point_hh) `->` type($result0) `,` type($result1)";
}

def Torch_AtenRnnReluInputOp : Torch_Op<"aten.rnn_relu.input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rnn_relu.input : (Tensor, Tensor, Tensor[], bool, int, float, bool, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    Torch_BoolType:$batch_first
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional `,` $batch_first attr-dict `:` type($input) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_first) `->` type($result0) `,` type($result1)";
}

def Torch_AtenRnnReluDataOp : Torch_Op<"aten.rnn_relu.data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rnn_relu.data : (Tensor, Tensor, Tensor, Tensor[], bool, int, float, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$data,
    AnyTorchTensorType:$batch_sizes,
    AnyTorchTensorType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$data `,` $batch_sizes `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional attr-dict `:` type($data) `,` type($batch_sizes) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `->` type($result0) `,` type($result1)";
}

def Torch_AtenRnnTanhInputOp : Torch_Op<"aten.rnn_tanh.input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rnn_tanh.input : (Tensor, Tensor, Tensor[], bool, int, float, bool, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    Torch_BoolType:$batch_first
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional `,` $batch_first attr-dict `:` type($input) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_first) `->` type($result0) `,` type($result1)";
}

def Torch_AtenRnnTanhDataOp : Torch_Op<"aten.rnn_tanh.data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rnn_tanh.data : (Tensor, Tensor, Tensor, Tensor[], bool, int, float, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$data,
    AnyTorchTensorType:$batch_sizes,
    AnyTorchTensorType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$data `,` $batch_sizes `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional attr-dict `:` type($data) `,` type($batch_sizes) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `->` type($result0) `,` type($result1)";
}

def Torch_AtenGruInputOp : Torch_Op<"aten.gru.input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gru.input : (Tensor, Tensor, Tensor[], bool, int, float, bool, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    Torch_BoolType:$batch_first
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional `,` $batch_first attr-dict `:` type($input) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_first) `->` type($result0) `,` type($result1)";
}

def Torch_AtenGruDataOp : Torch_Op<"aten.gru.data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gru.data : (Tensor, Tensor, Tensor, Tensor[], bool, int, float, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$data,
    AnyTorchTensorType:$batch_sizes,
    AnyTorchTensorType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$data `,` $batch_sizes `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional attr-dict `:` type($data) `,` type($batch_sizes) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `->` type($result0) `,` type($result1)";
}

def Torch_AtenLstmInputOp : Torch_Op<"aten.lstm.input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lstm.input : (Tensor, Tensor[], Tensor[], bool, int, float, bool, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    Torch_BoolType:$batch_first
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional `,` $batch_first attr-dict `:` type($input) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_first) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenLstmDataOp : Torch_Op<"aten.lstm.data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lstm.data : (Tensor, Tensor, Tensor[], Tensor[], bool, int, float, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$data,
    AnyTorchTensorType:$batch_sizes,
    AnyTorchTensorListType:$hx,
    AnyTorchTensorListType:$params,
    Torch_BoolType:$has_biases,
    Torch_IntType:$num_layers,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$data `,` $batch_sizes `,` $hx `,` $params `,` $has_biases `,` $num_layers `,` $dropout `,` $train `,` $bidirectional attr-dict `:` type($data) `,` type($batch_sizes) `,` type($hx) `,` type($params) `,` type($has_biases) `,` type($num_layers) `,` type($dropout) `,` type($train) `,` type($bidirectional) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenCombinationsOp : Torch_Op<"aten.combinations", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::combinations : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$r,
    Torch_BoolType:$with_replacement
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $r `,` $with_replacement attr-dict `:` type($self) `,` type($r) `,` type($with_replacement) `->` type($result)";
}

def Torch_AtenCartesianProdOp : Torch_Op<"aten.cartesian_prod", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cartesian_prod : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenMeshgridOp : Torch_Op<"aten.meshgrid", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::meshgrid : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenMeshgridIndexingOp : Torch_Op<"aten.meshgrid.indexing", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::meshgrid.indexing : (Tensor[], str) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_StringType:$indexing
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $indexing attr-dict `:` type($tensors) `,` type($indexing) `->` type($result)";
}

def Torch_AtenChooseQparamsOptimizedOp : Torch_Op<"aten.choose_qparams_optimized", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::choose_qparams_optimized : (Tensor, int, int, float, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_IntType:$numel,
    Torch_IntType:$n_bins,
    Torch_FloatType:$ratio,
    Torch_IntType:$bit_width
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $numel `,` $n_bins `,` $ratio `,` $bit_width attr-dict `:` type($input) `,` type($numel) `,` type($n_bins) `,` type($ratio) `,` type($bit_width) `->` type($result0) `,` type($result1)";
}

def Torch_AtenFakeQuantizePerChannelAffineOp : Torch_Op<"aten.fake_quantize_per_channel_affine", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_channel_affine : (Tensor, Tensor, Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$axis,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $axis `,` $quant_min `,` $quant_max attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($axis) `,` type($quant_min) `,` type($quant_max) `->` type($result)";
}

def Torch_AtenCoalesceOp : Torch_Op<"aten.coalesce", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::coalesce : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSubtractTensorOp : Torch_Op<"aten.subtract.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::subtract.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSubtractScalarOp : Torch_Op<"aten.subtract.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::subtract.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenPositiveOp : Torch_Op<"aten.positive", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::positive : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNormExceptDimOp : Torch_Op<"aten.norm_except_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm_except_dim : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$v,
    Torch_IntType:$pow,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$v `,` $pow `,` $dim attr-dict `:` type($v) `,` type($pow) `,` type($dim) `->` type($result)";
}

def Torch_AtenWhereScalarSelfOp : Torch_Op<"aten.where.ScalarSelf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::where.ScalarSelf : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$condition,
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$condition `,` $self `,` $other attr-dict `:` type($condition) `,` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenWhereScalarOtherOp : Torch_Op<"aten.where.ScalarOther", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::where.ScalarOther : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$condition,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$condition `,` $self `,` $other attr-dict `:` type($condition) `,` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenWhereScalarOp : Torch_Op<"aten.where.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::where.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$condition,
    AnyTorchScalarType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$condition `,` $self `,` $other attr-dict `:` type($condition) `,` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenWhereOp : Torch_Op<"aten.where", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::where : (Tensor) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$condition
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$condition attr-dict `:` type($condition) `->` type($result)";
}

def Torch_AtenFixOp : Torch_Op<"aten.fix", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fix : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenTrapzXOp : Torch_Op<"aten.trapz.x", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trapz.x : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$y,
    AnyTorchTensorType:$x,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$y `,` $x `,` $dim attr-dict `:` type($y) `,` type($x) `,` type($dim) `->` type($result)";
}

def Torch_AtenTrapzDxOp : Torch_Op<"aten.trapz.dx", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trapz.dx : (Tensor, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$y,
    Torch_FloatType:$dx,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$y `,` $dx `,` $dim attr-dict `:` type($y) `,` type($dx) `,` type($dim) `->` type($result)";
}

def Torch_AtenTrapezoidXOp : Torch_Op<"aten.trapezoid.x", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trapezoid.x : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$y,
    AnyTorchTensorType:$x,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$y `,` $x `,` $dim attr-dict `:` type($y) `,` type($x) `,` type($dim) `->` type($result)";
}

def Torch_AtenTrapezoidDxOp : Torch_Op<"aten.trapezoid.dx", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trapezoid.dx : (Tensor, Scalar, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$y,
    AnyTorchScalarType:$dx,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$y `,` $dx `,` $dim attr-dict `:` type($y) `,` type($dx) `,` type($dim) `->` type($result)";
}

def Torch_AtenFlipudOp : Torch_Op<"aten.flipud", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::flipud : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFliplrOp : Torch_Op<"aten.fliplr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fliplr : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenOneHotOp : Torch_Op<"aten.one_hot", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::one_hot : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$num_classes
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $num_classes attr-dict `:` type($self) `,` type($num_classes) `->` type($result)";
}

def Torch_AtenTileOp : Torch_Op<"aten.tile", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tile : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dims
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dims attr-dict `:` type($self) `,` type($dims) `->` type($result)";
}

def Torch_AtenSumToSizeOp : Torch_Op<"aten.sum_to_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sum_to_size : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size attr-dict `:` type($self) `,` type($size) `->` type($result)";
}

def Torch_AtenIstftOp : Torch_Op<"aten.istft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::istft : (Tensor, int, int?, int?, Tensor?, bool, bool, bool?, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n_fft,
    TorchOptionalIntType:$hop_length,
    TorchOptionalIntType:$win_length,
    AnyTorchOptionalTensorType:$window,
    Torch_BoolType:$center,
    Torch_BoolType:$normalized,
    TorchOptionalBoolType:$onesided,
    TorchOptionalIntType:$length,
    Torch_BoolType:$return_complex
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n_fft `,` $hop_length `,` $win_length `,` $window `,` $center `,` $normalized `,` $onesided `,` $length `,` $return_complex attr-dict `:` type($self) `,` type($n_fft) `,` type($hop_length) `,` type($win_length) `,` type($window) `,` type($center) `,` type($normalized) `,` type($onesided) `,` type($length) `,` type($return_complex) `->` type($result)";
}

def Torch_AtenDstackOp : Torch_Op<"aten.dstack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dstack : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenVstackOp : Torch_Op<"aten.vstack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::vstack : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenHstackOp : Torch_Op<"aten.hstack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hstack : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenSmmOp : Torch_Op<"aten.smm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::smm : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat2 attr-dict `:` type($self) `,` type($mat2) `->` type($result)";
}

def Torch_AtenRelu6Op : Torch_Op<"aten.relu6", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::relu6 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNegativeOp : Torch_Op<"aten.negative", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::negative : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRavelOp : Torch_Op<"aten.ravel", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ravel : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenPinMemoryOp : Torch_Op<"aten.pin_memory", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::pin_memory : (Tensor, Device?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalDeviceType:$device
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $device attr-dict `:` type($self) `,` type($device) `->` type($result)";
}

def Torch_AtenPixelUnshuffleOp : Torch_Op<"aten.pixel_unshuffle", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pixel_unshuffle : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$downscale_factor
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $downscale_factor attr-dict `:` type($self) `,` type($downscale_factor) `->` type($result)";
}

def Torch_AtenPixelShuffleOp : Torch_Op<"aten.pixel_shuffle", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pixel_shuffle : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$upscale_factor
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upscale_factor attr-dict `:` type($self) `,` type($upscale_factor) `->` type($result)";
}

def Torch_AtenAdjointOp : Torch_Op<"aten.adjoint", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adjoint : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMoveaxisIntlistOp : Torch_Op<"aten.moveaxis.intlist", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::moveaxis.intlist : (Tensor, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$source,
    TorchIntListType:$destination
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $source `,` $destination attr-dict `:` type($self) `,` type($source) `,` type($destination) `->` type($result)";
}

def Torch_AtenMoveaxisIntOp : Torch_Op<"aten.moveaxis.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::moveaxis.int : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$source,
    Torch_IntType:$destination
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $source `,` $destination attr-dict `:` type($self) `,` type($source) `,` type($destination) `->` type($result)";
}

def Torch_AtenPairwiseDistanceOp : Torch_Op<"aten.pairwise_distance", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pairwise_distance : (Tensor, Tensor, float, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x1,
    AnyTorchTensorType:$x2,
    Torch_FloatType:$p,
    Torch_FloatType:$eps,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x1 `,` $x2 `,` $p `,` $eps `,` $keepdim attr-dict `:` type($x1) `,` type($x2) `,` type($p) `,` type($eps) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenMultiplyTensorOp : Torch_Op<"aten.multiply.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multiply.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMultiplyScalarOp : Torch_Op<"aten.multiply.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multiply.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNanmeanOp : Torch_Op<"aten.nanmean", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanmean : (Tensor, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenMatrixExpOp : Torch_Op<"aten.matrix_exp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::matrix_exp : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMatrixPowerOp : Torch_Op<"aten.matrix_power", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::matrix_power : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n attr-dict `:` type($self) `,` type($n) `->` type($result)";
}

def Torch_AtenLdexpTensorOp : Torch_Op<"aten.ldexp.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ldexp.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFbgemmPackQuantizedMatrixOp : Torch_Op<"aten.fbgemm_pack_quantized_matrix", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_pack_quantized_matrix : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input attr-dict `:` type($input) `->` type($result)";
}

def Torch_AtenFbgemmPackQuantizedMatrixKNOp : Torch_Op<"aten.fbgemm_pack_quantized_matrix.KN", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_pack_quantized_matrix.KN : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_IntType:$K,
    Torch_IntType:$N
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $K `,` $N attr-dict `:` type($input) `,` type($K) `,` type($N) `->` type($result)";
}

def Torch_AtenFbgemmLinearFp16WeightOp : Torch_Op<"aten.fbgemm_linear_fp16_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_linear_fp16_weight : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$packed_weight,
    AnyTorchTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $packed_weight `,` $bias attr-dict `:` type($input) `,` type($packed_weight) `,` type($bias) `->` type($result)";
}

def Torch_AtenFbgemmLinearFp16WeightFp32ActivationOp : Torch_Op<"aten.fbgemm_linear_fp16_weight_fp32_activation", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_linear_fp16_weight_fp32_activation : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$packed_weight,
    AnyTorchTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $packed_weight `,` $bias attr-dict `:` type($input) `,` type($packed_weight) `,` type($bias) `->` type($result)";
}

def Torch_AtenFbgemmPackGemmMatrixFp16Op : Torch_Op<"aten.fbgemm_pack_gemm_matrix_fp16", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_pack_gemm_matrix_fp16 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input attr-dict `:` type($input) `->` type($result)";
}

def Torch_AtenFbgemmLinearQuantizeWeightOp : Torch_Op<"aten.fbgemm_linear_quantize_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_linear_quantize_weight : (Tensor) -> (Tensor, Tensor, float, int)`";
  let arguments = (ins
    AnyTorchTensorType:$input
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    Torch_FloatType:$result2,
    Torch_IntType:$result3
  );
  let assemblyFormat = "$input attr-dict `:` type($input) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_AtenFbgemmLinearInt8WeightOp : Torch_Op<"aten.fbgemm_linear_int8_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_linear_int8_weight : (Tensor, Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$packed,
    AnyTorchTensorType:$col_offsets,
    AnyTorchScalarType:$weight_scale,
    AnyTorchScalarType:$weight_zero_point,
    AnyTorchTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $packed `,` $col_offsets `,` $weight_scale `,` $weight_zero_point `,` $bias attr-dict `:` type($input) `,` type($weight) `,` type($packed) `,` type($col_offsets) `,` type($weight_scale) `,` type($weight_zero_point) `,` type($bias) `->` type($result)";
}

def Torch_AtenFbgemmLinearInt8WeightFp32ActivationOp : Torch_Op<"aten.fbgemm_linear_int8_weight_fp32_activation", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fbgemm_linear_int8_weight_fp32_activation : (Tensor, Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$packed,
    AnyTorchTensorType:$col_offsets,
    AnyTorchScalarType:$weight_scale,
    AnyTorchScalarType:$weight_zero_point,
    AnyTorchTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $packed `,` $col_offsets `,` $weight_scale `,` $weight_zero_point `,` $bias attr-dict `:` type($input) `,` type($weight) `,` type($packed) `,` type($col_offsets) `,` type($weight_scale) `,` type($weight_zero_point) `,` type($bias) `->` type($result)";
}

def Torch_AtenKronOp : Torch_Op<"aten.kron", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kron : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIsrealOp : Torch_Op<"aten.isreal", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isreal : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIscloseOp : Torch_Op<"aten.isclose", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isclose : (Tensor, Tensor, float, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    Torch_FloatType:$rtol,
    Torch_FloatType:$atol,
    Torch_BoolType:$equal_nan
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rtol `,` $atol `,` $equal_nan attr-dict `:` type($self) `,` type($other) `,` type($rtol) `,` type($atol) `,` type($equal_nan) `->` type($result)";
}

def Torch_AtenNewOnesOp : Torch_Op<"aten.new_ones", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::new_ones : (Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($self) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenNewFullOp : Torch_Op<"aten.new_full", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::new_full : (Tensor, int[], Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    AnyTorchScalarType:$fill_value,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $fill_value `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($self) `,` type($size) `,` type($fill_value) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenEmbeddingBagOp : Torch_Op<"aten.embedding_bag", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::embedding_bag : (Tensor, Tensor, Tensor, bool, int, bool, Tensor?, bool) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    Torch_BoolType:$sparse,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_BoolType:$include_last_offset
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3
  );
  let assemblyFormat = "$weight `,` $indices `,` $offsets `,` $scale_grad_by_freq `,` $mode `,` $sparse `,` $per_sample_weights `,` $include_last_offset attr-dict `:` type($weight) `,` type($indices) `,` type($offsets) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($sparse) `,` type($per_sample_weights) `,` type($include_last_offset) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_AtenEmbeddingBagPaddingIdxOp : Torch_Op<"aten.embedding_bag.padding_idx", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::embedding_bag.padding_idx : (Tensor, Tensor, Tensor, bool, int, bool, Tensor?, bool, int?) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    Torch_BoolType:$sparse,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_BoolType:$include_last_offset,
    TorchOptionalIntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3
  );
  let assemblyFormat = "$weight `,` $indices `,` $offsets `,` $scale_grad_by_freq `,` $mode `,` $sparse `,` $per_sample_weights `,` $include_last_offset `,` $padding_idx attr-dict `:` type($weight) `,` type($indices) `,` type($offsets) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($sparse) `,` type($per_sample_weights) `,` type($include_last_offset) `,` type($padding_idx) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_AtenRowStackOp : Torch_Op<"aten.row_stack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::row_stack : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenEinsumOp : Torch_Op<"aten.einsum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::einsum : (str, Tensor[]) -> (Tensor)`";
  let arguments = (ins
    Torch_StringType:$equation,
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$equation `,` $tensors attr-dict `:` type($equation) `,` type($tensors) `->` type($result)";
}

def Torch_AtenDivideTensorOp : Torch_Op<"aten.divide.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::divide.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDivideScalarOp : Torch_Op<"aten.divide.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::divide.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDivideTensorModeOp : Torch_Op<"aten.divide.Tensor_mode", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::divide.Tensor_mode : (Tensor, Tensor, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenDivideScalarModeOp : Torch_Op<"aten.divide.Scalar_mode", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::divide.Scalar_mode : (Tensor, Scalar, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenGradientScalarintOp : Torch_Op<"aten.gradient.scalarint", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.scalarint : (Tensor, Scalar?, int?, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$spacing,
    TorchOptionalIntType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $spacing `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($spacing) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenGradientScalararrayOp : Torch_Op<"aten.gradient.scalararray", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.scalararray : (Tensor, Scalar, int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$spacing,
    TorchIntListType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $spacing `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($spacing) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenGradientArrayOp : Torch_Op<"aten.gradient.array", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.array : (Tensor, int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenGradientScalarrayintOp : Torch_Op<"aten.gradient.scalarrayint", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.scalarrayint : (Tensor, Scalar[], int?, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarListType:$spacing,
    TorchOptionalIntType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $spacing `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($spacing) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenGradientScalarrayarrayOp : Torch_Op<"aten.gradient.scalarrayarray", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.scalarrayarray : (Tensor, Scalar[], int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarListType:$spacing,
    TorchIntListType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $spacing `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($spacing) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenGradientTensorarrayintOp : Torch_Op<"aten.gradient.tensorarrayint", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.tensorarrayint : (Tensor, Tensor[], int?, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorListType:$spacing,
    TorchOptionalIntType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $spacing `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($spacing) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenGradientTensorarrayOp : Torch_Op<"aten.gradient.tensorarray", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gradient.tensorarray : (Tensor, Tensor[], int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorListType:$spacing,
    TorchIntListType:$dim,
    Torch_IntType:$edge_order
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $spacing `,` $dim `,` $edge_order attr-dict `:` type($self) `,` type($spacing) `,` type($dim) `,` type($edge_order) `->` type($result)";
}

def Torch_AtenDiffOp : Torch_Op<"aten.diff", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diff : (Tensor, int, int, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n,
    Torch_IntType:$dim,
    AnyTorchOptionalTensorType:$prepend,
    AnyTorchOptionalTensorType:$append
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $prepend `,` $append attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($prepend) `,` type($append) `->` type($result)";
}

def Torch_AtenDiagEmbedOp : Torch_Op<"aten.diag_embed", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diag_embed : (Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$offset,
    Torch_IntType:$dim1,
    Torch_IntType:$dim2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $offset `,` $dim1 `,` $dim2 attr-dict `:` type($self) `,` type($offset) `,` type($dim1) `,` type($dim2) `->` type($result)";
}

def Torch_AtenCumulativeTrapezoidXOp : Torch_Op<"aten.cumulative_trapezoid.x", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumulative_trapezoid.x : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$y,
    AnyTorchTensorType:$x,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$y `,` $x `,` $dim attr-dict `:` type($y) `,` type($x) `,` type($dim) `->` type($result)";
}

def Torch_AtenCumulativeTrapezoidDxOp : Torch_Op<"aten.cumulative_trapezoid.dx", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumulative_trapezoid.dx : (Tensor, Scalar, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$y,
    AnyTorchScalarType:$dx,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$y `,` $dx `,` $dim attr-dict `:` type($y) `,` type($dx) `,` type($dim) `->` type($result)";
}

def Torch_AtenCorrcoefOp : Torch_Op<"aten.corrcoef", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::corrcoef : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCovOp : Torch_Op<"aten.cov", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cov : (Tensor, int, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$correction,
    AnyTorchOptionalTensorType:$fweights,
    AnyTorchOptionalTensorType:$aweights
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $correction `,` $fweights `,` $aweights attr-dict `:` type($self) `,` type($correction) `,` type($fweights) `,` type($aweights) `->` type($result)";
}

def Torch_AtenClipOp : Torch_Op<"aten.clip", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clip : (Tensor, Scalar?, Scalar?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$min,
    AnyTorchOptionalScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenClipTensorOp : Torch_Op<"aten.clip.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clip.Tensor : (Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$min,
    AnyTorchOptionalTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenBlockDiagOp : Torch_Op<"aten.block_diag", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::block_diag : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenConcatOp : Torch_Op<"aten.concat", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::concat : (Tensor[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_AtenConcatNamesOp : Torch_Op<"aten.concat.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::concat.names : (Tensor[], str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_AtenBroadcastTensorsOp : Torch_Op<"aten.broadcast_tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::broadcast_tensors : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenAtleast3dOp : Torch_Op<"aten.atleast_3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atleast_3d : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAtleast3dSequenceOp : Torch_Op<"aten.atleast_3d.Sequence", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atleast_3d.Sequence : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenAtleast2dOp : Torch_Op<"aten.atleast_2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atleast_2d : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAtleast2dSequenceOp : Torch_Op<"aten.atleast_2d.Sequence", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atleast_2d.Sequence : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenAtleast1dOp : Torch_Op<"aten.atleast_1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atleast_1d : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAtleast1dSequenceOp : Torch_Op<"aten.atleast_1d.Sequence", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atleast_1d.Sequence : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenArctanOp : Torch_Op<"aten.arctan", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arctan : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArcsinOp : Torch_Op<"aten.arcsin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arcsin : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArctanhOp : Torch_Op<"aten.arctanh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arctanh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArcsinhOp : Torch_Op<"aten.arcsinh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arcsinh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArccosOp : Torch_Op<"aten.arccos", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arccos : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFeatureAlphaDropoutOp : Torch_Op<"aten.feature_alpha_dropout", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::feature_alpha_dropout : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $p `,` $train attr-dict `:` type($input) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenCoshOp : Torch_Op<"aten.cosh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cosh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDataOp : Torch_Op<"aten.data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::data : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenPolarOp : Torch_Op<"aten.polar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::polar : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$abs,
    AnyTorchTensorType:$angle
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$abs `,` $angle attr-dict `:` type($abs) `,` type($angle) `->` type($result)";
}

def Torch_AtenComplexOp : Torch_Op<"aten.complex", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::complex : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$real,
    AnyTorchTensorType:$imag
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$real `,` $imag attr-dict `:` type($real) `,` type($imag) `->` type($result)";
}

def Torch_AtenTrueDivideScalarOp : Torch_Op<"aten.true_divide.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::true_divide.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenTrueDivideTensorOp : Torch_Op<"aten.true_divide.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::true_divide.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenResolveNegOp : Torch_Op<"aten.resolve_neg", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::resolve_neg : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenResolveConjOp : Torch_Op<"aten.resolve_conj", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::resolve_conj : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenVarMeanOp : Torch_Op<"aten.var_mean", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var_mean : (Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$unbiased
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $unbiased attr-dict `:` type($self) `,` type($unbiased) `->` type($result0) `,` type($result1)";
}

def Torch_AtenVarMeanDimOp : Torch_Op<"aten.var_mean.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var_mean.dim : (Tensor, int[], bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenVarMeanNamesDimOp : Torch_Op<"aten.var_mean.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var_mean.names_dim : (Tensor, str[], bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenVarMeanCorrectionOp : Torch_Op<"aten.var_mean.correction", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var_mean.correction : (Tensor, int[]?, int?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenVarMeanCorrectionNamesOp : Torch_Op<"aten.var_mean.correction_names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var_mean.correction_names : (Tensor, str[], int?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenConjOp : Torch_Op<"aten.conj", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::conj : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenStdMeanOp : Torch_Op<"aten.std_mean", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std_mean : (Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$unbiased
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $unbiased attr-dict `:` type($self) `,` type($unbiased) `->` type($result0) `,` type($result1)";
}

def Torch_AtenStdMeanDimOp : Torch_Op<"aten.std_mean.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std_mean.dim : (Tensor, int[], bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenStdMeanNamesDimOp : Torch_Op<"aten.std_mean.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std_mean.names_dim : (Tensor, str[], bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenStdMeanCorrectionOp : Torch_Op<"aten.std_mean.correction", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std_mean.correction : (Tensor, int[]?, int?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenStdMeanCorrectionNamesOp : Torch_Op<"aten.std_mean.correction_names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std_mean.correction_names : (Tensor, str[], int?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenSignbitOp : Torch_Op<"aten.signbit", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::signbit : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCloneOp : Torch_Op<"aten.clone", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clone : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $memory_format attr-dict `:` type($self) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenCholeskyInverseOp : Torch_Op<"aten.cholesky_inverse", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cholesky_inverse : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upper attr-dict `:` type($self) `,` type($upper) `->` type($result)";
}

def Torch_AtenRad2degOp : Torch_Op<"aten.rad2deg", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rad2deg : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCholeskyOp : Torch_Op<"aten.cholesky", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cholesky : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upper attr-dict `:` type($self) `,` type($upper) `->` type($result)";
}

def Torch_AtenPolygammaOp : Torch_Op<"aten.polygamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::polygamma : (int, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $self attr-dict `:` type($n) `,` type($self) `->` type($result)";
}

def Torch_AtenNextafterOp : Torch_Op<"aten.nextafter", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nextafter : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMinOp : Torch_Op<"aten.min", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::min : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMinDimOp : Torch_Op<"aten.min.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::min.dim : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMinNamesDimOp : Torch_Op<"aten.min.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::min.names_dim : (Tensor, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMinOtherOp : Torch_Op<"aten.min.other", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::min.other : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNanmedianOp : Torch_Op<"aten.nanmedian", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanmedian : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNanmedianDimOp : Torch_Op<"aten.nanmedian.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanmedian.dim : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenNanmedianNamesDimOp : Torch_Op<"aten.nanmedian.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanmedian.names_dim : (Tensor, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMedianOp : Torch_Op<"aten.median", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::median : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMedianDimOp : Torch_Op<"aten.median.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::median.dim : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMedianNamesDimOp : Torch_Op<"aten.median.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::median.names_dim : (Tensor, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMeanNamesDimOp : Torch_Op<"aten.mean.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mean.names_dim : (Tensor, str[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenQuantizePerChannelOp : Torch_Op<"aten.quantize_per_channel", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantize_per_channel : (Tensor, Tensor, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scales,
    AnyTorchTensorType:$zero_points,
    Torch_IntType:$axis,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scales `,` $zero_points `,` $axis `,` $dtype attr-dict `:` type($self) `,` type($scales) `,` type($zero_points) `,` type($axis) `,` type($dtype) `->` type($result)";
}

def Torch_AtenUniqueDimConsecutiveOp : Torch_Op<"aten.unique_dim_consecutive", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unique_dim_consecutive : (Tensor, int, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$return_inverse,
    Torch_BoolType:$return_counts
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $dim `,` $return_inverse `,` $return_counts attr-dict `:` type($self) `,` type($dim) `,` type($return_inverse) `,` type($return_counts) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMaxOp : Torch_Op<"aten.max", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMaxDimOp : Torch_Op<"aten.max.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max.dim : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMaxNamesDimOp : Torch_Op<"aten.max.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max.names_dim : (Tensor, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenMaxOtherOp : Torch_Op<"aten.max.other", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max.other : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenUniqueDimOp : Torch_Op<"aten.unique_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unique_dim : (Tensor, int, bool, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$sorted,
    Torch_BoolType:$return_inverse,
    Torch_BoolType:$return_counts
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $dim `,` $sorted `,` $return_inverse `,` $return_counts attr-dict `:` type($self) `,` type($dim) `,` type($sorted) `,` type($return_inverse) `,` type($return_counts) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMaskedFillTensorOp : Torch_Op<"aten.masked_fill.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::masked_fill.Tensor : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $value attr-dict `:` type($self) `,` type($mask) `,` type($value) `->` type($result)";
}

def Torch_AtenLogsumexpNamesOp : Torch_Op<"aten.logsumexp.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logsumexp.names : (Tensor, str[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenLogicalNotOp : Torch_Op<"aten.logical_not", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logical_not : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLogaddexpOp : Torch_Op<"aten.logaddexp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logaddexp : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBlackmanWindowOp : Torch_Op<"aten.blackman_window", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::blackman_window : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenBlackmanWindowPeriodicOp : Torch_Op<"aten.blackman_window.periodic", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::blackman_window.periodic : (int, bool, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenKthvalueOp : Torch_Op<"aten.kthvalue", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kthvalue : (Tensor, int, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $k `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($k) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenKthvalueDimnameOp : Torch_Op<"aten.kthvalue.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kthvalue.dimname : (Tensor, int, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $k `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($k) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenIsnanOp : Torch_Op<"aten.isnan", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isnan : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenEmptyQuantizedOp : Torch_Op<"aten.empty_quantized", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::empty_quantized : (int[], Tensor, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchTensorType:$qtensor,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $qtensor `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($size) `,` type($qtensor) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenLogicalXorOp : Torch_Op<"aten.logical_xor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logical_xor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogicalOrOp : Torch_Op<"aten.logical_or", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logical_or : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIgammacOp : Torch_Op<"aten.igammac", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::igammac : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogicalAndOp : Torch_Op<"aten.logical_and", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logical_and : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIgammaOp : Torch_Op<"aten.igamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::igamma : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenHypotOp : Torch_Op<"aten.hypot", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hypot : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFlattenDimnameListOp : Torch_Op<"aten.flatten.DimnameList", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::flatten.DimnameList : (Tensor, str[], str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dims,
    Torch_StringType:$out_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dims `,` $out_dim attr-dict `:` type($self) `,` type($dims) `,` type($out_dim) `->` type($result)";
}

def Torch_AtenFlattenNamedOutDimOp : Torch_Op<"aten.flatten.named_out_dim", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::flatten.named_out_dim : (Tensor, int, int, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$start_dim,
    Torch_IntType:$end_dim,
    Torch_StringType:$out_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $start_dim `,` $end_dim `,` $out_dim attr-dict `:` type($self) `,` type($start_dim) `,` type($end_dim) `,` type($out_dim) `->` type($result)";
}

def Torch_AtenFlattenUsingNamesOp : Torch_Op<"aten.flatten.using_names", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::flatten.using_names : (Tensor, str, str, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$start_dim,
    Torch_StringType:$end_dim,
    Torch_StringType:$out_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $start_dim `,` $end_dim `,` $out_dim attr-dict `:` type($self) `,` type($start_dim) `,` type($end_dim) `,` type($out_dim) `->` type($result)";
}

def Torch_AtenModeOp : Torch_Op<"aten.mode", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mode : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenModeDimnameOp : Torch_Op<"aten.mode.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mode.dimname : (Tensor, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($values) `,` type($indices)";
}

def Torch_AtenErfcOp : Torch_Op<"aten.erfc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::erfc : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenErfOp : Torch_Op<"aten.erf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::erf : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDeg2radOp : Torch_Op<"aten.deg2rad", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::deg2rad : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAtanhOp : Torch_Op<"aten.atanh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atanh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAsinhOp : Torch_Op<"aten.asinh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::asinh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenVarOp : Torch_Op<"aten.var", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$unbiased
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $unbiased attr-dict `:` type($self) `,` type($unbiased) `->` type($result)";
}

def Torch_AtenVarDimOp : Torch_Op<"aten.var.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var.dim : (Tensor, int[], bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenVarNamesDimOp : Torch_Op<"aten.var.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var.names_dim : (Tensor, str[], bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenVarCorrectionOp : Torch_Op<"aten.var.correction", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var.correction : (Tensor, int[]?, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenVarCorrectionNamesOp : Torch_Op<"aten.var.correction_names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::var.correction_names : (Tensor, str[], int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenAlignToOp : Torch_Op<"aten.align_to", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::align_to : (Tensor, str[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$names
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $names attr-dict `:` type($self) `,` type($names) `->` type($result)";
}

def Torch_AtenAlignToEllipsisIdxOp : Torch_Op<"aten.align_to.ellipsis_idx", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::align_to.ellipsis_idx : (Tensor, str[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$order,
    Torch_IntType:$ellipsis_idx
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $order `,` $ellipsis_idx attr-dict `:` type($self) `,` type($order) `,` type($ellipsis_idx) `->` type($result)";
}

def Torch_AtenAsStridedOp : Torch_Op<"aten.as_strided", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::as_strided : (Tensor, int[], int[], int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchIntListType:$stride,
    TorchOptionalIntType:$storage_offset
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $stride `,` $storage_offset attr-dict `:` type($self) `,` type($size) `,` type($stride) `,` type($storage_offset) `->` type($result)";
}

def Torch_AtenIndexFillDimnameScalarOp : Torch_Op<"aten.index_fill.Dimname_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_fill.Dimname_Scalar : (Tensor, str, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenIndexFillDimnameTensorOp : Torch_Op<"aten.index_fill.Dimname_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_fill.Dimname_Tensor : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenIndexFillIntScalarOp : Torch_Op<"aten.index_fill.int_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_fill.int_Scalar : (Tensor, int, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenIndexFillIntTensorOp : Torch_Op<"aten.index_fill.int_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_fill.int_Tensor : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenAmaxOp : Torch_Op<"aten.amax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::amax : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenArgminOp : Torch_Op<"aten.argmin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::argmin : (Tensor, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenAcoshOp : Torch_Op<"aten.acosh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::acosh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAbsoluteOp : Torch_Op<"aten.absolute", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::absolute : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIndexCopyOp : Torch_Op<"aten.index_copy", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_copy : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenIndexCopyDimnameOp : Torch_Op<"aten.index_copy.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_copy.dimname : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenLinalgInvExOp : Torch_Op<"aten.linalg_inv_ex", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_inv_ex : (Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$check_errors
  );
  let results = (outs
    AnyTorchTensorType:$inverse,
    AnyTorchTensorType:$info
  );
  let assemblyFormat = "$self `,` $check_errors attr-dict `:` type($self) `,` type($check_errors) `->` type($inverse) `,` type($info)";
}

def Torch_AtenLinalgSvdOp : Torch_Op<"aten.linalg_svd", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_svd : (Tensor, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$full_matrices
  );
  let results = (outs
    AnyTorchTensorType:$U,
    AnyTorchTensorType:$S,
    AnyTorchTensorType:$Vh
  );
  let assemblyFormat = "$self `,` $full_matrices attr-dict `:` type($self) `,` type($full_matrices) `->` type($U) `,` type($S) `,` type($Vh)";
}

def Torch_AtenAffineGridGeneratorOp : Torch_Op<"aten.affine_grid_generator", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::affine_grid_generator : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$theta,
    TorchIntListType:$size,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$theta `,` $size `,` $align_corners attr-dict `:` type($theta) `,` type($size) `,` type($align_corners) `->` type($result)";
}

def Torch_AtenMultilabelMarginLossForwardOp : Torch_Op<"aten.multilabel_margin_loss_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multilabel_margin_loss_forward : (Tensor, Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$is_target
  );
  let assemblyFormat = "$self `,` $target `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($reduction) `->` type($output) `,` type($is_target)";
}

def Torch_AtenSolveOp : Torch_Op<"aten.solve", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::solve : (Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A
  );
  let results = (outs
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$LU
  );
  let assemblyFormat = "$self `,` $A attr-dict `:` type($self) `,` type($A) `->` type($solution) `,` type($LU)";
}

def Torch_AtenQrOp : Torch_Op<"aten.qr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::qr : (Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$some
  );
  let results = (outs
    AnyTorchTensorType:$Q,
    AnyTorchTensorType:$R
  );
  let assemblyFormat = "$self `,` $some attr-dict `:` type($self) `,` type($some) `->` type($Q) `,` type($R)";
}

def Torch_AtenLstsqOp : Torch_Op<"aten.lstsq", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lstsq : (Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A
  );
  let results = (outs
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$QR
  );
  let assemblyFormat = "$self `,` $A attr-dict `:` type($self) `,` type($A) `->` type($solution) `,` type($QR)";
}

def Torch_AtenGeqrfOp : Torch_Op<"aten.geqrf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::geqrf : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$a,
    AnyTorchTensorType:$tau
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($a) `,` type($tau)";
}

def Torch_AtenEigOp : Torch_Op<"aten.eig", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eig : (Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$eigenvectors
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$res_eigenvectors
  );
  let assemblyFormat = "$self `,` $eigenvectors attr-dict `:` type($self) `,` type($eigenvectors) `->` type($eigenvalues) `,` type($res_eigenvectors)";
}

def Torch_AtenCosineSimilarityOp : Torch_Op<"aten.cosine_similarity", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cosine_similarity : (Tensor, Tensor, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x1,
    AnyTorchTensorType:$x2,
    Torch_IntType:$dim,
    Torch_FloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x1 `,` $x2 `,` $dim `,` $eps attr-dict `:` type($x1) `,` type($x2) `,` type($dim) `,` type($eps) `->` type($result)";
}

def Torch_AtenCumminOp : Torch_Op<"aten.cummin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cummin : (Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($values) `,` type($indices)";
}

def Torch_AtenCumminDimnameOp : Torch_Op<"aten.cummin.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cummin.dimname : (Tensor, str) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($values) `,` type($indices)";
}

def Torch_AtenCummaxOp : Torch_Op<"aten.cummax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cummax : (Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($values) `,` type($indices)";
}

def Torch_AtenCummaxDimnameOp : Torch_Op<"aten.cummax.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cummax.dimname : (Tensor, str) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($values) `,` type($indices)";
}

def Torch_AtenLinalgHouseholderProductOp : Torch_Op<"aten.linalg_householder_product", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_householder_product : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$tau
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $tau attr-dict `:` type($input) `,` type($tau) `->` type($result)";
}

def Torch_AtenLinalgInvOp : Torch_Op<"aten.linalg_inv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_inv : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenUnsafeSplitTensorOp : Torch_Op<"aten.unsafe_split.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unsafe_split.Tensor : (Tensor, int, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$split_size,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $split_size `,` $dim attr-dict `:` type($self) `,` type($split_size) `,` type($dim) `->` type($result)";
}

def Torch_AtenLinalgSolveOp : Torch_Op<"aten.linalg_solve", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_solve : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $other attr-dict `:` type($input) `,` type($other) `->` type($result)";
}

def Torch_AtenTriangularSolveOp : Torch_Op<"aten.triangular_solve", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::triangular_solve : (Tensor, Tensor, bool, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A,
    Torch_BoolType:$upper,
    Torch_BoolType:$transpose,
    Torch_BoolType:$unitriangular
  );
  let results = (outs
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$cloned_coefficient
  );
  let assemblyFormat = "$self `,` $A `,` $upper `,` $transpose `,` $unitriangular attr-dict `:` type($self) `,` type($A) `,` type($upper) `,` type($transpose) `,` type($unitriangular) `->` type($solution) `,` type($cloned_coefficient)";
}

def Torch_AtenFftIrfftOp : Torch_Op<"aten.fft_irfft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_irfft : (Tensor, int?, int, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenAllDimOp : Torch_Op<"aten.all.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::all.dim : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenAllDimnameOp : Torch_Op<"aten.all.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::all.dimname : (Tensor, str, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenLinalgLstsqOp : Torch_Op<"aten.linalg_lstsq", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_lstsq : (Tensor, Tensor, float?, str?) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$b,
    TorchOptionalFloatType:$rcond,
    TorchOptionalStringType:$driver
  );
  let results = (outs
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$residuals,
    AnyTorchTensorType:$rank,
    AnyTorchTensorType:$singular_values
  );
  let assemblyFormat = "$self `,` $b `,` $rcond `,` $driver attr-dict `:` type($self) `,` type($b) `,` type($rcond) `,` type($driver) `->` type($solution) `,` type($residuals) `,` type($rank) `,` type($singular_values)";
}

def Torch_AtenFftIfftnOp : Torch_Op<"aten.fft_ifftn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ifftn : (Tensor, int[]?, int[]?, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenFftIfft2Op : Torch_Op<"aten.fft_ifft2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ifft2 : (Tensor, int[]?, int[], str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenConjPhysicalOp : Torch_Op<"aten.conj_physical", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conj_physical : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCtcLossIntListOp : Torch_Op<"aten.ctc_loss.IntList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ctc_loss.IntList : (Tensor, Tensor, int[], int[], int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$log_probs,
    AnyTorchTensorType:$targets,
    TorchIntListType:$input_lengths,
    TorchIntListType:$target_lengths,
    Torch_IntType:$blank,
    Torch_IntType:$reduction,
    Torch_BoolType:$zero_infinity
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$log_probs `,` $targets `,` $input_lengths `,` $target_lengths `,` $blank `,` $reduction `,` $zero_infinity attr-dict `:` type($log_probs) `,` type($targets) `,` type($input_lengths) `,` type($target_lengths) `,` type($blank) `,` type($reduction) `,` type($zero_infinity) `->` type($result)";
}

def Torch_AtenCtcLossTensorOp : Torch_Op<"aten.ctc_loss.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ctc_loss.Tensor : (Tensor, Tensor, Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$log_probs,
    AnyTorchTensorType:$targets,
    AnyTorchTensorType:$input_lengths,
    AnyTorchTensorType:$target_lengths,
    Torch_IntType:$blank,
    Torch_IntType:$reduction,
    Torch_BoolType:$zero_infinity
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$log_probs `,` $targets `,` $input_lengths `,` $target_lengths `,` $blank `,` $reduction `,` $zero_infinity attr-dict `:` type($log_probs) `,` type($targets) `,` type($input_lengths) `,` type($target_lengths) `,` type($blank) `,` type($reduction) `,` type($zero_infinity) `->` type($result)";
}

def Torch_AtenSoftshrinkOp : Torch_Op<"aten.softshrink", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::softshrink : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $lambd attr-dict `:` type($self) `,` type($lambd) `->` type($result)";
}

def Torch_AtenSeluOp : Torch_Op<"aten.selu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::selu : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenHardsigmoidOp : Torch_Op<"aten.hardsigmoid", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardsigmoid : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgMatrixNormOp : Torch_Op<"aten.linalg_matrix_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_norm : (Tensor, Scalar, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$ord,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenLinalgMatrixNormStrOrdOp : Torch_Op<"aten.linalg_matrix_norm.str_ord", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_norm.str_ord : (Tensor, str, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$ord,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenHardshrinkOp : Torch_Op<"aten.hardshrink", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardshrink : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $lambd attr-dict `:` type($self) `,` type($lambd) `->` type($result)";
}

def Torch_AtenEluOp : Torch_Op<"aten.elu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::elu : (Tensor, Scalar, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$alpha,
    AnyTorchScalarType:$scale,
    AnyTorchScalarType:$input_scale
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $alpha `,` $scale `,` $input_scale attr-dict `:` type($self) `,` type($alpha) `,` type($scale) `,` type($input_scale) `->` type($result)";
}

def Torch_AtenReplicationPad3dOp : Torch_Op<"aten.replication_pad3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::replication_pad3d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding attr-dict `:` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReplicationPad2dOp : Torch_Op<"aten.replication_pad2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::replication_pad2d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding attr-dict `:` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReplicationPad1dOp : Torch_Op<"aten.replication_pad1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::replication_pad1d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding attr-dict `:` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenDiagonalScatterOp : Torch_Op<"aten.diagonal_scatter", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diagonal_scatter : (Tensor, Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$src,
    Torch_IntType:$offset,
    Torch_IntType:$dim1,
    Torch_IntType:$dim2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $src `,` $offset `,` $dim1 `,` $dim2 attr-dict `:` type($self) `,` type($src) `,` type($offset) `,` type($dim1) `,` type($dim2) `->` type($result)";
}

def Torch_AtenReflectionPad2dOp : Torch_Op<"aten.reflection_pad2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reflection_pad2d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding attr-dict `:` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReflectionPad1dOp : Torch_Op<"aten.reflection_pad1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reflection_pad1d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding attr-dict `:` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenFakeQuantizePerChannelAffineCachemaskOp : Torch_Op<"aten.fake_quantize_per_channel_affine_cachemask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_channel_affine_cachemask : (Tensor, Tensor, Tensor, int, int, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$axis,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$mask
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $axis `,` $quant_min `,` $quant_max attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($axis) `,` type($quant_min) `,` type($quant_max) `->` type($output) `,` type($mask)";
}

def Torch_AtenFakeQuantizePerTensorAffineCachemaskOp : Torch_Op<"aten.fake_quantize_per_tensor_affine_cachemask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_tensor_affine_cachemask : (Tensor, float, int, int, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$scale,
    Torch_IntType:$zero_point,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$mask
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $quant_min `,` $quant_max attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($quant_min) `,` type($quant_max) `->` type($output) `,` type($mask)";
}

def Torch_AtenPinverseOp : Torch_Op<"aten.pinverse", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pinverse : (Tensor, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$rcond
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $rcond attr-dict `:` type($self) `,` type($rcond) `->` type($result)";
}

def Torch_AtenOrmqrOp : Torch_Op<"aten.ormqr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ormqr : (Tensor, Tensor, Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input2,
    AnyTorchTensorType:$input3,
    Torch_BoolType:$left,
    Torch_BoolType:$transpose
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $input2 `,` $input3 `,` $left `,` $transpose attr-dict `:` type($self) `,` type($input2) `,` type($input3) `,` type($left) `,` type($transpose) `->` type($result)";
}

def Torch_AtenOrgqrOp : Torch_Op<"aten.orgqr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::orgqr : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $input2 attr-dict `:` type($self) `,` type($input2) `->` type($result)";
}

def Torch_AtenMatrixRankOp : Torch_Op<"aten.matrix_rank", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::matrix_rank : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$symmetric
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $symmetric attr-dict `:` type($self) `,` type($symmetric) `->` type($result)";
}

def Torch_AtenMatrixRankTolOp : Torch_Op<"aten.matrix_rank.tol", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::matrix_rank.tol : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$tol,
    Torch_BoolType:$symmetric
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tol `,` $symmetric attr-dict `:` type($self) `,` type($tol) `,` type($symmetric) `->` type($result)";
}

def Torch_AtenLuSolveOp : Torch_Op<"aten.lu_solve", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lu_solve : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$LU_data,
    AnyTorchTensorType:$LU_pivots
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $LU_data `,` $LU_pivots attr-dict `:` type($self) `,` type($LU_data) `,` type($LU_pivots) `->` type($result)";
}

def Torch_AtenInverseOp : Torch_Op<"aten.inverse", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::inverse : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCholeskySolveOp : Torch_Op<"aten.cholesky_solve", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cholesky_solve : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input2,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $input2 `,` $upper attr-dict `:` type($self) `,` type($input2) `,` type($upper) `->` type($result)";
}

def Torch_AtenAlignTensorsOp : Torch_Op<"aten.align_tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::align_tensors : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenAminmaxOp : Torch_Op<"aten.aminmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::aminmax : (Tensor, int?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$min,
    AnyTorchTensorType:$max
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($min) `,` type($max)";
}

def Torch_AtenVanderOp : Torch_Op<"aten.vander", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::vander : (Tensor, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x,
    TorchOptionalIntType:$N,
    Torch_BoolType:$increasing
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x `,` $N `,` $increasing attr-dict `:` type($x) `,` type($N) `,` type($increasing) `->` type($result)";
}

def Torch_AtenFftRfftnOp : Torch_Op<"aten.fft_rfftn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_rfftn : (Tensor, int[]?, int[]?, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenLogcumsumexpOp : Torch_Op<"aten.logcumsumexp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logcumsumexp : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenLogcumsumexpDimnameOp : Torch_Op<"aten.logcumsumexp.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logcumsumexp.dimname : (Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenHistcOp : Torch_Op<"aten.histc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::histc : (Tensor, int, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$bins,
    AnyTorchScalarType:$min,
    AnyTorchScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $bins `,` $min `,` $max attr-dict `:` type($self) `,` type($bins) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenDiagOp : Torch_Op<"aten.diag", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diag : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal attr-dict `:` type($self) `,` type($diagonal) `->` type($result)";
}

def Torch_AtenNanquantileOp : Torch_Op<"aten.nanquantile", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanquantile : (Tensor, Tensor, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenNanquantileScalarOp : Torch_Op<"aten.nanquantile.scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanquantile.scalar : (Tensor, float, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenNanquantileNewOp : Torch_Op<"aten.nanquantile.new", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanquantile.new : (Tensor, Tensor, int?, bool, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `->` type($result)";
}

def Torch_AtenNanquantileNewScalarOp : Torch_Op<"aten.nanquantile.new_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nanquantile.new_scalar : (Tensor, float, int?, bool, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `->` type($result)";
}

def Torch_AtenQuantileOp : Torch_Op<"aten.quantile", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantile : (Tensor, Tensor, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenQuantileScalarOp : Torch_Op<"aten.quantile.scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantile.scalar : (Tensor, float, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenQuantileNewOp : Torch_Op<"aten.quantile.new", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantile.new : (Tensor, Tensor, int?, bool, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `->` type($result)";
}

def Torch_AtenQuantileNewScalarOp : Torch_Op<"aten.quantile.new_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantile.new_scalar : (Tensor, float, int?, bool, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `->` type($result)";
}

def Torch_AtenArccoshOp : Torch_Op<"aten.arccosh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::arccosh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFmodTensorOp : Torch_Op<"aten.fmod.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fmod.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBincountOp : Torch_Op<"aten.bincount", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bincount : (Tensor, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$weights,
    Torch_IntType:$minlength
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weights `,` $minlength attr-dict `:` type($self) `,` type($weights) `,` type($minlength) `->` type($result)";
}

def Torch_AtenAlphaDropoutOp : Torch_Op<"aten.alpha_dropout", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::alpha_dropout : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $p `,` $train attr-dict `:` type($input) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenUpsampleNearest3dOp : Torch_Op<"aten.upsample_nearest3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest3d : (Tensor, int[], float?, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $scales_d `,` $scales_h `,` $scales_w attr-dict `:` type($self) `,` type($output_size) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleNearest3dVecOp : Torch_Op<"aten.upsample_nearest3d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest3d.vec : (Tensor, int[]?, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenLinalgEighOp : Torch_Op<"aten.linalg_eigh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_eigh : (Tensor, str) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$UPLO
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$eigenvectors
  );
  let assemblyFormat = "$self `,` $UPLO attr-dict `:` type($self) `,` type($UPLO) `->` type($eigenvalues) `,` type($eigenvectors)";
}

def Torch_AtenAliasOp : Torch_Op<"aten.alias", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::alias : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenUpsampleNearest2dOp : Torch_Op<"aten.upsample_nearest2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest2d : (Tensor, int[], float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $scales_h `,` $scales_w attr-dict `:` type($self) `,` type($output_size) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleNearest2dVecOp : Torch_Op<"aten.upsample_nearest2d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest2d.vec : (Tensor, int[]?, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenLinalgCholeskyExOp : Torch_Op<"aten.linalg_cholesky_ex", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_cholesky_ex : (Tensor, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper,
    Torch_BoolType:$check_errors
  );
  let results = (outs
    AnyTorchTensorType:$L,
    AnyTorchTensorType:$info
  );
  let assemblyFormat = "$self `,` $upper `,` $check_errors attr-dict `:` type($self) `,` type($upper) `,` type($check_errors) `->` type($L) `,` type($info)";
}

def Torch_AtenAddrOp : Torch_Op<"aten.addr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::addr : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec1,
    AnyTorchTensorType:$vec2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec1 `,` $vec2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($vec1) `,` type($vec2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenUpsampleNearest1dOp : Torch_Op<"aten.upsample_nearest1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest1d : (Tensor, int[], float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchOptionalFloatType:$scales
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $scales attr-dict `:` type($self) `,` type($output_size) `,` type($scales) `->` type($result)";
}

def Torch_AtenUpsampleNearest1dVecOp : Torch_Op<"aten.upsample_nearest1d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest1d.vec : (Tensor, int[]?, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenLinalgQrOp : Torch_Op<"aten.linalg_qr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_qr : (Tensor, str) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$mode
  );
  let results = (outs
    AnyTorchTensorType:$Q,
    AnyTorchTensorType:$R
  );
  let assemblyFormat = "$self `,` $mode attr-dict `:` type($self) `,` type($mode) `->` type($Q) `,` type($R)";
}

def Torch_AtenAddmvOp : Torch_Op<"aten.addmv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::addmv : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat,
    AnyTorchTensorType:$vec,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat `,` $vec `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($mat) `,` type($vec) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenFloorDivideOp : Torch_Op<"aten.floor_divide", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::floor_divide : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenUpsampleTrilinear3dOp : Torch_Op<"aten.upsample_trilinear3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_trilinear3d : (Tensor, int[], bool, float?, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales_d `,` $scales_h `,` $scales_w attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleTrilinear3dVecOp : Torch_Op<"aten.upsample_trilinear3d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_trilinear3d.vec : (Tensor, int[]?, bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $align_corners `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenBinaryCrossEntropyOp : Torch_Op<"aten.binary_cross_entropy", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::binary_cross_entropy : (Tensor, Tensor, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `->` type($result)";
}

def Torch_AtenIsfiniteOp : Torch_Op<"aten.isfinite", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isfinite : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenScatterAddOp : Torch_Op<"aten.scatter_add", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter_add : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `->` type($result)";
}

def Torch_AtenScatterAddDimnameOp : Torch_Op<"aten.scatter_add.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter_add.dimname : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `->` type($result)";
}

def Torch_AtenCatNamesOp : Torch_Op<"aten.cat.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cat.names : (Tensor[], str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_AtenStftOp : Torch_Op<"aten.stft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::stft : (Tensor, int, int?, int?, Tensor?, bool, bool?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n_fft,
    TorchOptionalIntType:$hop_length,
    TorchOptionalIntType:$win_length,
    AnyTorchOptionalTensorType:$window,
    Torch_BoolType:$normalized,
    TorchOptionalBoolType:$onesided,
    TorchOptionalBoolType:$return_complex
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n_fft `,` $hop_length `,` $win_length `,` $window `,` $normalized `,` $onesided `,` $return_complex attr-dict `:` type($self) `,` type($n_fft) `,` type($hop_length) `,` type($win_length) `,` type($window) `,` type($normalized) `,` type($onesided) `,` type($return_complex) `->` type($result)";
}

def Torch_AtenAngleOp : Torch_Op<"aten.angle", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::angle : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenViewDtypeOp : Torch_Op<"aten.view.dtype", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::view.dtype : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_AtenBinaryCrossEntropyWithLogitsOp : Torch_Op<"aten.binary_cross_entropy_with_logits", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::binary_cross_entropy_with_logits : (Tensor, Tensor, Tensor?, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$pos_weight,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $pos_weight `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($pos_weight) `,` type($reduction) `->` type($result)";
}

def Torch_AtenBilinearOp : Torch_Op<"aten.bilinear", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bilinear : (Tensor, Tensor, Tensor, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input1,
    AnyTorchTensorType:$input2,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input1 `,` $input2 `,` $weight `,` $bias attr-dict `:` type($input1) `,` type($input2) `,` type($weight) `,` type($bias) `->` type($result)";
}

def Torch_AtenCeluOp : Torch_Op<"aten.celu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::celu : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $alpha attr-dict `:` type($self) `,` type($alpha) `->` type($result)";
}

def Torch_AtenViewAsRealOp : Torch_Op<"aten.view_as_real", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::view_as_real : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMultilabelMarginLossOp : Torch_Op<"aten.multilabel_margin_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multilabel_margin_loss : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenReshapeAsOp : Torch_Op<"aten.reshape_as", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reshape_as : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFftFft2Op : Torch_Op<"aten.fft_fft2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_fft2 : (Tensor, int[]?, int[], str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenToDeviceOp : Torch_Op<"aten.to.device", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::to.device : (Tensor, Device, int, bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_DeviceType:$device,
    Torch_IntType:$dtype,
    Torch_BoolType:$non_blocking,
    Torch_BoolType:$copy,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $device `,` $dtype `,` $non_blocking `,` $copy `,` $memory_format attr-dict `:` type($self) `,` type($device) `,` type($dtype) `,` type($non_blocking) `,` type($copy) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenToDtypeLayoutOp : Torch_Op<"aten.to.dtype_layout", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::to.dtype_layout : (Tensor, int?, int?, Device?, bool?, bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    Torch_BoolType:$non_blocking,
    Torch_BoolType:$copy,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $non_blocking `,` $copy `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($non_blocking) `,` type($copy) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenSwapdimsOp : Torch_Op<"aten.swapdims", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::swapdims : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim0,
    Torch_IntType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_AtenFakeQuantizePerTensorAffineOp : Torch_Op<"aten.fake_quantize_per_tensor_affine", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_tensor_affine : (Tensor, float, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$scale,
    Torch_IntType:$zero_point,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $quant_min `,` $quant_max attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($quant_min) `,` type($quant_max) `->` type($result)";
}

def Torch_AtenFakeQuantizePerTensorAffineTensorQparamsOp : Torch_Op<"aten.fake_quantize_per_tensor_affine.tensor_qparams", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_tensor_affine.tensor_qparams : (Tensor, Tensor, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $quant_min `,` $quant_max attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($quant_min) `,` type($quant_max) `->` type($result)";
}

def Torch_AtenImagOp : Torch_Op<"aten.imag", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::imag : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenUniqueConsecutiveOp : Torch_Op<"aten.unique_consecutive", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unique_consecutive : (Tensor, bool, bool, int?) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$return_inverse,
    Torch_BoolType:$return_counts,
    TorchOptionalIntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $return_inverse `,` $return_counts `,` $dim attr-dict `:` type($self) `,` type($return_inverse) `,` type($return_counts) `,` type($dim) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenTruncOp : Torch_Op<"aten.trunc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trunc : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSearchsortedTensorOp : Torch_Op<"aten.searchsorted.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::searchsorted.Tensor : (Tensor, Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$sorted_sequence,
    AnyTorchTensorType:$self,
    Torch_BoolType:$out_int32,
    Torch_BoolType:$right
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sorted_sequence `,` $self `,` $out_int32 `,` $right attr-dict `:` type($sorted_sequence) `,` type($self) `,` type($out_int32) `,` type($right) `->` type($result)";
}

def Torch_AtenSearchsortedScalarOp : Torch_Op<"aten.searchsorted.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::searchsorted.Scalar : (Tensor, Scalar, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$sorted_sequence,
    AnyTorchScalarType:$self,
    Torch_BoolType:$out_int32,
    Torch_BoolType:$right
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sorted_sequence `,` $self `,` $out_int32 `,` $right attr-dict `:` type($sorted_sequence) `,` type($self) `,` type($out_int32) `,` type($right) `->` type($result)";
}

def Torch_AtenSignOp : Torch_Op<"aten.sign", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sign : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenHingeEmbeddingLossOp : Torch_Op<"aten.hinge_embedding_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hinge_embedding_loss : (Tensor, Tensor, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_FloatType:$margin,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $margin `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($margin) `,` type($reduction) `->` type($result)";
}

def Torch_AtenFracOp : Torch_Op<"aten.frac", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::frac : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLog1pOp : Torch_Op<"aten.log1p", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log1p : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenBaddbmmOp : Torch_Op<"aten.baddbmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::baddbmm : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$batch1,
    AnyTorchTensorType:$batch2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch1 `,` $batch2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($batch1) `,` type($batch2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenClampMaxOp : Torch_Op<"aten.clamp_max", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clamp_max : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $max attr-dict `:` type($self) `,` type($max) `->` type($result)";
}

def Torch_AtenClampMaxTensorOp : Torch_Op<"aten.clamp_max.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clamp_max.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $max attr-dict `:` type($self) `,` type($max) `->` type($result)";
}

def Torch_AtenRenameOp : Torch_Op<"aten.rename", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rename : (Tensor, str[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalStringListType:$names
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $names attr-dict `:` type($self) `,` type($names) `->` type($result)";
}

def Torch_AtenLog10Op : Torch_Op<"aten.log10", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log10 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNewEmptyStridedOp : Torch_Op<"aten.new_empty_strided", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::new_empty_strided : (Tensor, int[], int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchIntListType:$stride,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $stride `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($self) `,` type($size) `,` type($stride) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenTensorSplitSectionsOp : Torch_Op<"aten.tensor_split.sections", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tensor_split.sections : (Tensor, int, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$sections,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $sections `,` $dim attr-dict `:` type($self) `,` type($sections) `,` type($dim) `->` type($result)";
}

def Torch_AtenTensorSplitIndicesOp : Torch_Op<"aten.tensor_split.indices", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tensor_split.indices : (Tensor, int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$indices,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $dim attr-dict `:` type($self) `,` type($indices) `,` type($dim) `->` type($result)";
}

def Torch_AtenTensorSplitTensorIndicesOrSectionsOp : Torch_Op<"aten.tensor_split.tensor_indices_or_sections", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tensor_split.tensor_indices_or_sections : (Tensor, Tensor, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor_indices_or_sections,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $tensor_indices_or_sections `,` $dim attr-dict `:` type($self) `,` type($tensor_indices_or_sections) `,` type($dim) `->` type($result)";
}

def Torch_AtenTensordotOp : Torch_Op<"aten.tensordot", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tensordot : (Tensor, Tensor, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchIntListType:$dims_self,
    TorchIntListType:$dims_other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $dims_self `,` $dims_other attr-dict `:` type($self) `,` type($other) `,` type($dims_self) `,` type($dims_other) `->` type($result)";
}

def Torch_AtenNewEmptyOp : Torch_Op<"aten.new_empty", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::new_empty : (Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($self) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenMHOp : Torch_Op<"aten.mH", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mH : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenExpm1Op : Torch_Op<"aten.expm1", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::expm1 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenTanOp : Torch_Op<"aten.tan", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tan : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDigammaOp : Torch_Op<"aten.digamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::digamma : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRealOp : Torch_Op<"aten.real", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::real : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSinhOp : Torch_Op<"aten.sinh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sinh : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDivTensorModeOp : Torch_Op<"aten.div.Tensor_mode", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::div.Tensor_mode : (Tensor, Tensor, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenDivScalarModeOp : Torch_Op<"aten.div.Scalar_mode", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::div.Scalar_mode : (Tensor, Scalar, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenHsplitIntOp : Torch_Op<"aten.hsplit.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hsplit.int : (Tensor, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$sections
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $sections attr-dict `:` type($self) `,` type($sections) `->` type($result)";
}

def Torch_AtenHsplitArrayOp : Torch_Op<"aten.hsplit.array", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hsplit.array : (Tensor, int[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$indices
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $indices attr-dict `:` type($self) `,` type($indices) `->` type($result)";
}

def Torch_AtenRefineNamesOp : Torch_Op<"aten.refine_names", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::refine_names : (Tensor, str[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$names
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $names attr-dict `:` type($self) `,` type($names) `->` type($result)";
}

def Torch_AtenChunkOp : Torch_Op<"aten.chunk", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::chunk : (Tensor, int, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$chunks,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $chunks `,` $dim attr-dict `:` type($self) `,` type($chunks) `,` type($dim) `->` type($result)";
}

def Torch_AtenMvOp : Torch_Op<"aten.mv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mv : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec attr-dict `:` type($self) `,` type($vec) `->` type($result)";
}

def Torch_AtenSoftmaxDimnameOp : Torch_Op<"aten.softmax.Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::softmax.Dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenPowTensorTensorOp : Torch_Op<"aten.pow.Tensor_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pow.Tensor_Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenPowScalarOp : Torch_Op<"aten.pow.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pow.Scalar : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenLuUnpackOp : Torch_Op<"aten.lu_unpack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lu_unpack : (Tensor, Tensor, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$LU_data,
    AnyTorchTensorType:$LU_pivots,
    Torch_BoolType:$unpack_data,
    Torch_BoolType:$unpack_pivots
  );
  let results = (outs
    AnyTorchTensorType:$P,
    AnyTorchTensorType:$L,
    AnyTorchTensorType:$U
  );
  let assemblyFormat = "$LU_data `,` $LU_pivots `,` $unpack_data `,` $unpack_pivots attr-dict `:` type($LU_data) `,` type($LU_pivots) `,` type($unpack_data) `,` type($unpack_pivots) `->` type($P) `,` type($L) `,` type($U)";
}

def Torch_AtenUpsampleLinear1dOp : Torch_Op<"aten.upsample_linear1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_linear1d : (Tensor, int[], bool, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales) `->` type($result)";
}

def Torch_AtenUpsampleLinear1dVecOp : Torch_Op<"aten.upsample_linear1d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_linear1d.vec : (Tensor, int[]?, bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $align_corners `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenIm2colOp : Torch_Op<"aten.im2col", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::im2col : (Tensor, int[], int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $dilation `,` $padding `,` $stride attr-dict `:` type($self) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `->` type($result)";
}

def Torch_AtenFftIfftOp : Torch_Op<"aten.fft_ifft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ifft : (Tensor, int?, int, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenAsinOp : Torch_Op<"aten.asin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::asin : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAcosOp : Torch_Op<"aten.acos", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::acos : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenPdistOp : Torch_Op<"aten.pdist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::pdist : (Tensor, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenBartlettWindowOp : Torch_Op<"aten.bartlett_window", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bartlett_window : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenBartlettWindowPeriodicOp : Torch_Op<"aten.bartlett_window.periodic", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bartlett_window.periodic : (int, bool, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenClampMinOp : Torch_Op<"aten.clamp_min", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clamp_min : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min attr-dict `:` type($self) `,` type($min) `->` type($result)";
}

def Torch_AtenClampMinTensorOp : Torch_Op<"aten.clamp_min.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clamp_min.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$min
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min attr-dict `:` type($self) `,` type($min) `->` type($result)";
}

def Torch_AtenAtan2Op : Torch_Op<"aten.atan2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atan2 : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenViewAsOp : Torch_Op<"aten.view_as", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::view_as : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogSoftmaxDimnameOp : Torch_Op<"aten.log_softmax.Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log_softmax.Dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenLinalgSvdvalsOp : Torch_Op<"aten.linalg_svdvals", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_svdvals : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input attr-dict `:` type($input) `->` type($result)";
}

def Torch_AtenAlignAsOp : Torch_Op<"aten.align_as", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::align_as : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenAminOp : Torch_Op<"aten.amin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::amin : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenTransposeDimnameOp : Torch_Op<"aten.transpose.Dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::transpose.Dimname : (Tensor, str, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim0,
    Torch_StringType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_AtenFftRfftOp : Torch_Op<"aten.fft_rfft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_rfft : (Tensor, int?, int, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenTraceOp : Torch_Op<"aten.trace", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trace : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgTensorinvOp : Torch_Op<"aten.linalg_tensorinv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_tensorinv : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$ind
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ind attr-dict `:` type($self) `,` type($ind) `->` type($result)";
}

def Torch_AtenLinalgEigvalsOp : Torch_Op<"aten.linalg_eigvals", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_eigvals : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenUpsampleBilinear2dOp : Torch_Op<"aten.upsample_bilinear2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bilinear2d : (Tensor, int[], bool, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales_h `,` $scales_w attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleBilinear2dVecOp : Torch_Op<"aten.upsample_bilinear2d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bilinear2d.vec : (Tensor, int[]?, bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $align_corners `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenUnsafeChunkOp : Torch_Op<"aten.unsafe_chunk", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unsafe_chunk : (Tensor, int, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$chunks,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $chunks `,` $dim attr-dict `:` type($self) `,` type($chunks) `,` type($dim) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankOp : Torch_Op<"aten.linalg_matrix_rank", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$tol,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tol `,` $hermitian attr-dict `:` type($self) `,` type($tol) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankTolTensorOp : Torch_Op<"aten.linalg_matrix_rank.tol_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.tol_tensor : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$tol,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $tol `,` $hermitian attr-dict `:` type($input) `,` type($tol) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankAtolRtolTensorOp : Torch_Op<"aten.linalg_matrix_rank.atol_rtol_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.atol_rtol_tensor : (Tensor, Tensor?, Tensor?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$atol,
    AnyTorchOptionalTensorType:$rtol,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $atol `,` $rtol `,` $hermitian attr-dict `:` type($input) `,` type($atol) `,` type($rtol) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankAtolRtolFloatOp : Torch_Op<"aten.linalg_matrix_rank.atol_rtol_float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.atol_rtol_float : (Tensor, float?, float?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$atol,
    TorchOptionalFloatType:$rtol,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $atol `,` $rtol `,` $hermitian attr-dict `:` type($self) `,` type($atol) `,` type($rtol) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgTensorsolveOp : Torch_Op<"aten.linalg_tensorsolve", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_tensorsolve : (Tensor, Tensor, int[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalIntListType:$dims
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $dims attr-dict `:` type($self) `,` type($other) `,` type($dims) `->` type($result)";
}

def Torch_AtenAddbmmOp : Torch_Op<"aten.addbmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::addbmm : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$batch1,
    AnyTorchTensorType:$batch2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch1 `,` $batch2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($batch1) `,` type($batch2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenFftFftnOp : Torch_Op<"aten.fft_fftn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_fftn : (Tensor, int[]?, int[]?, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenFftIhfftOp : Torch_Op<"aten.fft_ihfft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_ihfft : (Tensor, int?, int, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenUnfoldOp : Torch_Op<"aten.unfold", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unfold : (Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dimension,
    Torch_IntType:$size,
    Torch_IntType:$step
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dimension `,` $size `,` $step attr-dict `:` type($self) `,` type($dimension) `,` type($size) `,` type($step) `->` type($result)";
}

def Torch_AtenDiagonalOp : Torch_Op<"aten.diagonal", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::diagonal : (Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$offset,
    Torch_IntType:$dim1,
    Torch_IntType:$dim2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $offset `,` $dim1 `,` $dim2 attr-dict `:` type($self) `,` type($offset) `,` type($dim1) `,` type($dim2) `->` type($result)";
}

def Torch_AtenDiagonalDimnameOp : Torch_Op<"aten.diagonal.Dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::diagonal.Dimname : (Tensor, str, str, str, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$outdim,
    Torch_StringType:$dim1,
    Torch_StringType:$dim2,
    Torch_IntType:$offset
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $outdim `,` $dim1 `,` $dim2 `,` $offset attr-dict `:` type($self) `,` type($outdim) `,` type($dim1) `,` type($dim2) `,` type($offset) `->` type($result)";
}

def Torch_AtenNuclearNormOp : Torch_Op<"aten.nuclear_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nuclear_norm : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $keepdim attr-dict `:` type($self) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenNuclearNormDimOp : Torch_Op<"aten.nuclear_norm.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nuclear_norm.dim : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenDotOp : Torch_Op<"aten.dot", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dot : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor attr-dict `:` type($self) `,` type($tensor) `->` type($result)";
}

def Torch_AtenQuantizePerTensorOp : Torch_Op<"aten.quantize_per_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantize_per_tensor : (Tensor, float, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$scale,
    Torch_IntType:$zero_point,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $dtype attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($dtype) `->` type($result)";
}

def Torch_AtenQuantizePerTensorTensorQparamsOp : Torch_Op<"aten.quantize_per_tensor.tensor_qparams", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantize_per_tensor.tensor_qparams : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $dtype attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($dtype) `->` type($result)";
}

def Torch_AtenQuantizePerTensorTensorsOp : Torch_Op<"aten.quantize_per_tensor.tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantize_per_tensor.tensors : (Tensor[], Tensor, Tensor, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$scales,
    AnyTorchTensorType:$zero_points,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scales `,` $zero_points `,` $dtype attr-dict `:` type($tensors) `,` type($scales) `,` type($zero_points) `,` type($dtype) `->` type($result)";
}

def Torch_AtenLinalgCondOp : Torch_Op<"aten.linalg_cond", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_cond : (Tensor, Scalar?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenLinalgCondPStrOp : Torch_Op<"aten.linalg_cond.p_str", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_cond.p_str : (Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenLstmCellOp : Torch_Op<"aten.lstm_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lstm_cell : (Tensor, Tensor[], Tensor, Tensor, Tensor?, Tensor?) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchOptionalTensorType:$b_ih,
    AnyTorchOptionalTensorType:$b_hh
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `->` type($result0) `,` type($result1)";
}

def Torch_AtenRepeatInterleaveTensorOp : Torch_Op<"aten.repeat_interleave.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::repeat_interleave.Tensor : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$repeats,
    TorchOptionalIntType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$repeats `,` $output_size attr-dict `:` type($repeats) `,` type($output_size) `->` type($result)";
}

def Torch_AtenRepeatInterleaveSelfTensorOp : Torch_Op<"aten.repeat_interleave.self_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::repeat_interleave.self_Tensor : (Tensor, Tensor, int?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$repeats,
    TorchOptionalIntType:$dim,
    TorchOptionalIntType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $repeats `,` $dim `,` $output_size attr-dict `:` type($self) `,` type($repeats) `,` type($dim) `,` type($output_size) `->` type($result)";
}

def Torch_AtenRepeatInterleaveSelfIntOp : Torch_Op<"aten.repeat_interleave.self_int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::repeat_interleave.self_int : (Tensor, int, int?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$repeats,
    TorchOptionalIntType:$dim,
    TorchOptionalIntType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $repeats `,` $dim `,` $output_size attr-dict `:` type($self) `,` type($repeats) `,` type($dim) `,` type($output_size) `->` type($result)";
}

def Torch_AtenKlDivOp : Torch_Op<"aten.kl_div", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kl_div : (Tensor, Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_BoolType:$log_target
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $log_target attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($log_target) `->` type($result)";
}

def Torch_AtenSquareOp : Torch_Op<"aten.square", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::square : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenL1LossOp : Torch_Op<"aten.l1_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::l1_loss : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenStdOp : Torch_Op<"aten.std", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$unbiased
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $unbiased attr-dict `:` type($self) `,` type($unbiased) `->` type($result)";
}

def Torch_AtenStdDimOp : Torch_Op<"aten.std.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std.dim : (Tensor, int[], bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenStdNamesDimOp : Torch_Op<"aten.std.names_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std.names_dim : (Tensor, str[], bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenStdCorrectionOp : Torch_Op<"aten.std.correction", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std.correction : (Tensor, int[]?, int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenStdCorrectionNamesOp : Torch_Op<"aten.std.correction_names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::std.correction_names : (Tensor, str[], int?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenExpandAsOp : Torch_Op<"aten.expand_as", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::expand_as : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMultiMarginLossOp : Torch_Op<"aten.multi_margin_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multi_margin_loss : (Tensor, Tensor, Scalar, Scalar, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchScalarType:$p,
    AnyTorchScalarType:$margin,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $p `,` $margin `,` $weight `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($p) `,` type($margin) `,` type($weight) `,` type($reduction) `->` type($result)";
}

def Torch_AtenRandintOp : Torch_Op<"aten.randint", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randint : (int, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$high,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$high `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($high) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenRandintLowOp : Torch_Op<"aten.randint.low", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randint.low : (int, int, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$low,
    Torch_IntType:$high,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$low `,` $high `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($low) `,` type($high) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenDiagflatOp : Torch_Op<"aten.diagflat", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diagflat : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$offset
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $offset attr-dict `:` type($self) `,` type($offset) `->` type($result)";
}

def Torch_AtenAnyDimnameOp : Torch_Op<"aten.any.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::any.dimname : (Tensor, str, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenFftRfft2Op : Torch_Op<"aten.fft_rfft2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_rfft2 : (Tensor, int[]?, int[], str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenTrilOp : Torch_Op<"aten.tril", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tril : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal attr-dict `:` type($self) `,` type($diagonal) `->` type($result)";
}

def Torch_AtenRandintLikeOp : Torch_Op<"aten.randint_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randint_like : (Tensor, int, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$high,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $high `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($high) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenRandintLikeLowDtypeOp : Torch_Op<"aten.randint_like.low_dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randint_like.low_dtype : (Tensor, int, int, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$low,
    Torch_IntType:$high,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $low `,` $high `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($low) `,` type($high) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenGluOp : Torch_Op<"aten.glu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::glu : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenClampTensorOp : Torch_Op<"aten.clamp.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::clamp.Tensor : (Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$min,
    AnyTorchOptionalTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenRandpermOp : Torch_Op<"aten.randperm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randperm : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($n) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSqueezeDimnameOp : Torch_Op<"aten.squeeze.dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::squeeze.dimname : (Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenFftIrfftnOp : Torch_Op<"aten.fft_irfftn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_irfftn : (Tensor, int[]?, int[]?, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenMovedimIntlistOp : Torch_Op<"aten.movedim.intlist", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::movedim.intlist : (Tensor, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$source,
    TorchIntListType:$destination
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $source `,` $destination attr-dict `:` type($self) `,` type($source) `,` type($destination) `->` type($result)";
}

def Torch_AtenMovedimIntOp : Torch_Op<"aten.movedim.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::movedim.int : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$source,
    Torch_IntType:$destination
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $source `,` $destination attr-dict `:` type($self) `,` type($source) `,` type($destination) `->` type($result)";
}

def Torch_AtenRsubTensorOp : Torch_Op<"aten.rsub.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rsub.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSumDimDimnameListOp : Torch_Op<"aten.sum.dim_DimnameList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sum.dim_DimnameList : (Tensor, str[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenMarginRankingLossOp : Torch_Op<"aten.margin_ranking_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::margin_ranking_loss : (Tensor, Tensor, Tensor, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input1,
    AnyTorchTensorType:$input2,
    AnyTorchTensorType:$target,
    Torch_FloatType:$margin,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input1 `,` $input2 `,` $target `,` $margin `,` $reduction attr-dict `:` type($input1) `,` type($input2) `,` type($target) `,` type($margin) `,` type($reduction) `->` type($result)";
}

def Torch_AtenUnsafeSplitWithSizesOp : Torch_Op<"aten.unsafe_split_with_sizes", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unsafe_split_with_sizes : (Tensor, int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$split_sizes,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $split_sizes `,` $dim attr-dict `:` type($self) `,` type($split_sizes) `,` type($dim) `->` type($result)";
}

def Torch_AtenLinalgCholeskyOp : Torch_Op<"aten.linalg_cholesky", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_cholesky : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upper attr-dict `:` type($self) `,` type($upper) `->` type($result)";
}

def Torch_AtenSelectDimnameOp : Torch_Op<"aten.select.Dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::select.Dimname : (Tensor, str, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_IntType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index attr-dict `:` type($self) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenSvdOp : Torch_Op<"aten.svd", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::svd : (Tensor, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$some,
    Torch_BoolType:$compute_uv
  );
  let results = (outs
    AnyTorchTensorType:$U,
    AnyTorchTensorType:$S,
    AnyTorchTensorType:$V
  );
  let assemblyFormat = "$self `,` $some `,` $compute_uv attr-dict `:` type($self) `,` type($some) `,` type($compute_uv) `->` type($U) `,` type($S) `,` type($V)";
}

def Torch_AtenFftHfftOp : Torch_Op<"aten.fft_hfft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_hfft : (Tensor, int?, int, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenUnbindIntOp : Torch_Op<"aten.unbind.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unbind.int : (Tensor, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenUnbindDimnameOp : Torch_Op<"aten.unbind.Dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unbind.Dimname : (Tensor, str) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenMatrixHOp : Torch_Op<"aten.matrix_H", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::matrix_H : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMTOp : Torch_Op<"aten.mT", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mT : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRoundOp : Torch_Op<"aten.round", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::round : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNarrowOp : Torch_Op<"aten.narrow", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::narrow : (Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_IntType:$start,
    Torch_IntType:$length
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $start `,` $length attr-dict `:` type($self) `,` type($dim) `,` type($start) `,` type($length) `->` type($result)";
}

def Torch_AtenNarrowTensorOp : Torch_Op<"aten.narrow.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::narrow.Tensor : (Tensor, int, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$start,
    Torch_IntType:$length
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $start `,` $length attr-dict `:` type($self) `,` type($dim) `,` type($start) `,` type($length) `->` type($result)";
}

def Torch_AtenLgammaOp : Torch_Op<"aten.lgamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lgamma : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgEigvalshOp : Torch_Op<"aten.linalg_eigvalsh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_eigvalsh : (Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$UPLO
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $UPLO attr-dict `:` type($self) `,` type($UPLO) `->` type($result)";
}

def Torch_AtenViewAsComplexOp : Torch_Op<"aten.view_as_complex", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::view_as_complex : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSplitTensorOp : Torch_Op<"aten.split.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::split.Tensor : (Tensor, int, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$split_size,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $split_size `,` $dim attr-dict `:` type($self) `,` type($split_size) `,` type($dim) `->` type($result)";
}

def Torch_AtenSplitWithSizesOp : Torch_Op<"aten.split_with_sizes", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::split_with_sizes : (Tensor, int[], int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$split_sizes,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $split_sizes `,` $dim attr-dict `:` type($self) `,` type($split_sizes) `,` type($dim) `->` type($result)";
}

def Torch_AtenLogSigmoidOp : Torch_Op<"aten.log_sigmoid", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log_sigmoid : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSwapaxesOp : Torch_Op<"aten.swapaxes", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::swapaxes : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$axis0,
    Torch_IntType:$axis1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $axis0 `,` $axis1 attr-dict `:` type($self) `,` type($axis0) `,` type($axis1) `->` type($result)";
}

def Torch_AtenNewZerosOp : Torch_Op<"aten.new_zeros", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::new_zeros : (Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($self) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenLinalgEigOp : Torch_Op<"aten.linalg_eig", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_eig : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$eigenvectors
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($eigenvalues) `,` type($eigenvectors)";
}

def Torch_AtenLogaddexp2Op : Torch_Op<"aten.logaddexp2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logaddexp2 : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenVsplitIntOp : Torch_Op<"aten.vsplit.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::vsplit.int : (Tensor, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$sections
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $sections attr-dict `:` type($self) `,` type($sections) `->` type($result)";
}

def Torch_AtenVsplitArrayOp : Torch_Op<"aten.vsplit.array", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::vsplit.array : (Tensor, int[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$indices
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $indices attr-dict `:` type($self) `,` type($indices) `->` type($result)";
}

def Torch_AtenMseLossOp : Torch_Op<"aten.mse_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mse_loss : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenInstanceNormOp : Torch_Op<"aten.instance_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::instance_norm : (Tensor, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$use_input_stats,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps,
    Torch_BoolType:$cudnn_enabled
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $use_input_stats `,` $momentum `,` $eps `,` $cudnn_enabled attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($use_input_stats) `,` type($momentum) `,` type($eps) `,` type($cudnn_enabled) `->` type($result)";
}

def Torch_AtenGeTensorOp : Torch_Op<"aten.ge.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ge.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLeTensorOp : Torch_Op<"aten.le.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::le.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLeScalarOp : Torch_Op<"aten.le.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::le.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIsinfOp : Torch_Op<"aten.isinf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isinf : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenVdotOp : Torch_Op<"aten.vdot", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::vdot : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenCol2imOp : Torch_Op<"aten.col2im", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::col2im : (Tensor, int[], int[], int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $kernel_size `,` $dilation `,` $padding `,` $stride attr-dict `:` type($self) `,` type($output_size) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `->` type($result)";
}

def Torch_AtenFftIrfft2Op : Torch_Op<"aten.fft_irfft2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_irfft2 : (Tensor, int[]?, int[], str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenTripletMarginLossOp : Torch_Op<"aten.triplet_margin_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::triplet_margin_loss : (Tensor, Tensor, Tensor, float, float, float, bool, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$anchor,
    AnyTorchTensorType:$positive,
    AnyTorchTensorType:$negative,
    Torch_FloatType:$margin,
    Torch_FloatType:$p,
    Torch_FloatType:$eps,
    Torch_BoolType:$swap,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$anchor `,` $positive `,` $negative `,` $margin `,` $p `,` $eps `,` $swap `,` $reduction attr-dict `:` type($anchor) `,` type($positive) `,` type($negative) `,` type($margin) `,` type($p) `,` type($eps) `,` type($swap) `,` type($reduction) `->` type($result)";
}

def Torch_AtenUnflattenIntOp : Torch_Op<"aten.unflatten.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unflatten.int : (Tensor, int, int[], str[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchIntListType:$sizes,
    TorchOptionalStringListType:$names
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $sizes `,` $names attr-dict `:` type($self) `,` type($dim) `,` type($sizes) `,` type($names) `->` type($result)";
}

def Torch_AtenUnflattenDimnameOp : Torch_Op<"aten.unflatten.Dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unflatten.Dimname : (Tensor, str, int[], str[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchIntListType:$sizes,
    TorchStringListType:$names
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $sizes `,` $names attr-dict `:` type($self) `,` type($dim) `,` type($sizes) `,` type($names) `->` type($result)";
}

def Torch_AtenDsplitIntOp : Torch_Op<"aten.dsplit.int", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::dsplit.int : (Tensor, int) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$sections
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $sections attr-dict `:` type($self) `,` type($sections) `->` type($result)";
}

def Torch_AtenDsplitArrayOp : Torch_Op<"aten.dsplit.array", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::dsplit.array : (Tensor, int[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$indices
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $indices attr-dict `:` type($self) `,` type($indices) `->` type($result)";
}

def Torch_AtenCdistOp : Torch_Op<"aten.cdist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cdist : (Tensor, Tensor, float, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x1,
    AnyTorchTensorType:$x2,
    Torch_FloatType:$p,
    TorchOptionalIntType:$compute_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x1 `,` $x2 `,` $p `,` $compute_mode attr-dict `:` type($x1) `,` type($x2) `,` type($p) `,` type($compute_mode) `->` type($result)";
}

def Torch_AtenEmptyNamesOp : Torch_Op<"aten.empty.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::empty.names : (int[], str[]?, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalStringListType:$names,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $names `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($size) `,` type($names) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenEmptyStridedOp : Torch_Op<"aten.empty_strided", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::empty_strided : (int[], int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchIntListType:$stride,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $stride `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($stride) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenAtanOp : Torch_Op<"aten.atan", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::atan : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFullLikeOp : Torch_Op<"aten.full_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::full_like : (Tensor, Scalar, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$fill_value,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $fill_value `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($fill_value) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenRandLikeOp : Torch_Op<"aten.rand_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rand_like : (Tensor, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenRandnLikeOp : Torch_Op<"aten.randn_like", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randn_like : (Tensor, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenRandOp : Torch_Op<"aten.rand", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rand : (int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenRandNamesOp : Torch_Op<"aten.rand.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rand.names : (int[], str[]?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalStringListType:$names,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $names `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($names) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenRandnOp : Torch_Op<"aten.randn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randn : (int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenRandnNamesOp : Torch_Op<"aten.randn.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::randn.names : (int[], str[]?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalStringListType:$names,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $names `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($names) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenErfinvOp : Torch_Op<"aten.erfinv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::erfinv : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCopysignTensorOp : Torch_Op<"aten.copysign.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::copysign.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenCopysignScalarOp : Torch_Op<"aten.copysign.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::copysign.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenPreluOp : Torch_Op<"aten.prelu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::prelu : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight attr-dict `:` type($self) `,` type($weight) `->` type($result)";
}

def Torch_AtenFftFftOp : Torch_Op<"aten.fft_fft", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_fft : (Tensor, int?, int, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `->` type($result)";
}

def Torch_AtenRenormOp : Torch_Op<"aten.renorm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::renorm : (Tensor, Scalar, int, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$p,
    Torch_IntType:$dim,
    AnyTorchScalarType:$maxnorm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $maxnorm attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($maxnorm) `->` type($result)";
}

def Torch_AtenSliceScatterOp : Torch_Op<"aten.slice_scatter", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slice_scatter : (Tensor, Tensor, int, int?, int?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$src,
    Torch_IntType:$dim,
    TorchOptionalIntType:$start,
    TorchOptionalIntType:$end,
    Torch_IntType:$step
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $src `,` $dim `,` $start `,` $end `,` $step attr-dict `:` type($self) `,` type($src) `,` type($dim) `,` type($start) `,` type($end) `,` type($step) `->` type($result)";
}

def Torch_AtenChainMatmulOp : Torch_Op<"aten.chain_matmul", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::chain_matmul : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$matrices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$matrices attr-dict `:` type($matrices) `->` type($result)";
}

def Torch_AtenSymeigOp : Torch_Op<"aten.symeig", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::symeig : (Tensor, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$eigenvectors,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$res_eigenvectors
  );
  let assemblyFormat = "$self `,` $eigenvectors `,` $upper attr-dict `:` type($self) `,` type($eigenvectors) `,` type($upper) `->` type($eigenvalues) `,` type($res_eigenvectors)";
}

def Torch_AtenNumpyTOp : Torch_Op<"aten.numpy_T", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::numpy_T : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSoftplusOp : Torch_Op<"aten.softplus", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::softplus : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$threshold
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $beta `,` $threshold attr-dict `:` type($self) `,` type($beta) `,` type($threshold) `->` type($result)";
}

def Torch_AtenLinalgMultiDotOp : Torch_Op<"aten.linalg_multi_dot", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_multi_dot : (Tensor[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenGruCellOp : Torch_Op<"aten.gru_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gru_cell : (Tensor, Tensor, Tensor, Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchOptionalTensorType:$b_ih,
    AnyTorchOptionalTensorType:$b_hh
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `->` type($result)";
}

def Torch_AtenRnnTanhCellOp : Torch_Op<"aten.rnn_tanh_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rnn_tanh_cell : (Tensor, Tensor, Tensor, Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchOptionalTensorType:$b_ih,
    AnyTorchOptionalTensorType:$b_hh
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `->` type($result)";
}

def Torch_AtenGroupNormOp : Torch_Op<"aten.group_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::group_norm : (Tensor, int, Tensor?, Tensor?, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_IntType:$num_groups,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    Torch_FloatType:$eps,
    Torch_BoolType:$cudnn_enabled
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $num_groups `,` $weight `,` $bias `,` $eps `,` $cudnn_enabled attr-dict `:` type($input) `,` type($num_groups) `,` type($weight) `,` type($bias) `,` type($eps) `,` type($cudnn_enabled) `->` type($result)";
}

def Torch_AtenRnnReluCellOp : Torch_Op<"aten.rnn_relu_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rnn_relu_cell : (Tensor, Tensor, Tensor, Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$hx,
    AnyTorchTensorType:$w_ih,
    AnyTorchTensorType:$w_hh,
    AnyTorchOptionalTensorType:$b_ih,
    AnyTorchOptionalTensorType:$b_hh
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $hx `,` $w_ih `,` $w_hh `,` $b_ih `,` $b_hh attr-dict `:` type($input) `,` type($hx) `,` type($w_ih) `,` type($w_hh) `,` type($b_ih) `,` type($b_hh) `->` type($result)";
}

def Torch_AtenI0Op : Torch_Op<"aten.i0", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::i0 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFrobeniusNormOp : Torch_Op<"aten.frobenius_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::frobenius_norm : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFrobeniusNormDimOp : Torch_Op<"aten.frobenius_norm.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::frobenius_norm.dim : (Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenPoissonNllLossOp : Torch_Op<"aten.poisson_nll_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::poisson_nll_loss : (Tensor, Tensor, bool, bool, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$target,
    Torch_BoolType:$log_input,
    Torch_BoolType:$full,
    Torch_FloatType:$eps,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $target `,` $log_input `,` $full `,` $eps `,` $reduction attr-dict `:` type($input) `,` type($target) `,` type($log_input) `,` type($full) `,` type($eps) `,` type($reduction) `->` type($result)";
}

def Torch_AtenCosineEmbeddingLossOp : Torch_Op<"aten.cosine_embedding_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cosine_embedding_loss : (Tensor, Tensor, Tensor, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input1,
    AnyTorchTensorType:$input2,
    AnyTorchTensorType:$target,
    Torch_FloatType:$margin,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input1 `,` $input2 `,` $target `,` $margin `,` $reduction attr-dict `:` type($input1) `,` type($input2) `,` type($target) `,` type($margin) `,` type($reduction) `->` type($result)";
}

def Torch_AtenNllLossOp : Torch_Op<"aten.nll_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss : (Tensor, Tensor, Tensor?, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `->` type($result)";
}

def Torch_AtenHardswishOp : Torch_Op<"aten.hardswish", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardswish : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNllLoss2dOp : Torch_Op<"aten.nll_loss2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss2d : (Tensor, Tensor, Tensor?, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `->` type($result)";
}

def Torch_AtenSmoothL1LossOp : Torch_Op<"aten.smooth_l1_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::smooth_l1_loss : (Tensor, Tensor, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$beta
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $beta attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($beta) `->` type($result)";
}

def Torch_AtenHuberLossOp : Torch_Op<"aten.huber_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::huber_loss : (Tensor, Tensor, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$delta
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $delta attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($delta) `->` type($result)";
}

def Torch_AtenSoftMarginLossOp : Torch_Op<"aten.soft_margin_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::soft_margin_loss : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction attr-dict `:` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenDistOp : Torch_Op<"aten.dist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dist : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $p attr-dict `:` type($self) `,` type($other) `,` type($p) `->` type($result)";
}

def Torch_AtenProdOp : Torch_Op<"aten.prod", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::prod : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_AtenProdDimIntOp : Torch_Op<"aten.prod.dim_int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::prod.dim_int : (Tensor, int, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenProdDimDimnameOp : Torch_Op<"aten.prod.dim_Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::prod.dim_Dimname : (Tensor, str, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenCountNonzeroDimIntListOp : Torch_Op<"aten.count_nonzero.dim_IntList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::count_nonzero.dim_IntList : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenCountNonzeroOp : Torch_Op<"aten.count_nonzero", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::count_nonzero : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenCumprodOp : Torch_Op<"aten.cumprod", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumprod : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenCumprodDimnameOp : Torch_Op<"aten.cumprod.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumprod.dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenCrossOp : Torch_Op<"aten.cross", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cross : (Tensor, Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalIntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $dim attr-dict `:` type($self) `,` type($other) `,` type($dim) `->` type($result)";
}

def Torch_AtenCumsumDimnameOp : Torch_Op<"aten.cumsum.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumsum.dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenNormScalarOp : Torch_Op<"aten.norm.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenNormScalarOptDimOp : Torch_Op<"aten.norm.ScalarOpt_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm.ScalarOpt_dim : (Tensor, Scalar?, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenNormNamesScalarOptDimOp : Torch_Op<"aten.norm.names_ScalarOpt_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm.names_ScalarOpt_dim : (Tensor, Scalar?, str[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenNormScalarOptDimDtypeOp : Torch_Op<"aten.norm.ScalarOpt_dim_dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm.ScalarOpt_dim_dtype : (Tensor, Scalar?, int[], bool, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenNormScalarOptDtypeOp : Torch_Op<"aten.norm.ScalarOpt_dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm.ScalarOpt_dtype : (Tensor, Scalar?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dtype attr-dict `:` type($self) `,` type($p) `,` type($dtype) `->` type($result)";
}

def Torch_AtenNormNamesScalarOptDimDtypeOp : Torch_Op<"aten.norm.names_ScalarOpt_dim_dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::norm.names_ScalarOpt_dim_dtype : (Tensor, Scalar?, str[], bool, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenGridSamplerOp : Torch_Op<"aten.grid_sampler", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::grid_sampler : (Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners attr-dict `:` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `->` type($result)";
}

def Torch_AtenFrexpTensorOp : Torch_Op<"aten.frexp.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::frexp.Tensor : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$mantissa,
    AnyTorchTensorType:$exponent
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($mantissa) `,` type($exponent)";
}

def Torch_AtenSpecialEntrOp : Torch_Op<"aten.special_entr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_entr : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenEyeOp : Torch_Op<"aten.eye", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eye : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($n) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenEyeMOp : Torch_Op<"aten.eye.m", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::eye.m : (int, int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    Torch_IntType:$m,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $m `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($n) `,` type($m) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenFeatureDropoutOp : Torch_Op<"aten.feature_dropout", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::feature_dropout : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $p `,` $train attr-dict `:` type($input) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenFlipOp : Torch_Op<"aten.flip", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::flip : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dims
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dims attr-dict `:` type($self) `,` type($dims) `->` type($result)";
}

def Torch_AtenFmaxOp : Torch_Op<"aten.fmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fmax : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFminOp : Torch_Op<"aten.fmin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fmin : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFullNamesOp : Torch_Op<"aten.full.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::full.names : (int[], Scalar, str[]?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchScalarType:$fill_value,
    TorchOptionalStringListType:$names,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $fill_value `,` $names `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($fill_value) `,` type($names) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenFullOp : Torch_Op<"aten.full", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::full : (int[], Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchScalarType:$fill_value,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $fill_value `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($fill_value) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenGatherDimnameOp : Torch_Op<"aten.gather.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gather.dimname : (Tensor, str, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    Torch_BoolType:$sparse_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $sparse_grad attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($sparse_grad) `->` type($result)";
}

def Torch_AtenGcdOp : Torch_Op<"aten.gcd", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gcd : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGridSampler2dOp : Torch_Op<"aten.grid_sampler_2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::grid_sampler_2d : (Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners attr-dict `:` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `->` type($result)";
}

def Torch_AtenGridSampler3dOp : Torch_Op<"aten.grid_sampler_3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::grid_sampler_3d : (Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners attr-dict `:` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `->` type($result)";
}

def Torch_AtenHammingWindowOp : Torch_Op<"aten.hamming_window", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hamming_window : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenHammingWindowPeriodicOp : Torch_Op<"aten.hamming_window.periodic", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hamming_window.periodic : (int, bool, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenHammingWindowPeriodicAlphaOp : Torch_Op<"aten.hamming_window.periodic_alpha", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hamming_window.periodic_alpha : (int, bool, float, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    Torch_FloatType:$alpha,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $alpha `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($alpha) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenHammingWindowPeriodicAlphaBetaOp : Torch_Op<"aten.hamming_window.periodic_alpha_beta", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hamming_window.periodic_alpha_beta : (int, bool, float, float, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    Torch_FloatType:$alpha,
    Torch_FloatType:$beta,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $alpha `,` $beta `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($alpha) `,` type($beta) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenHannWindowOp : Torch_Op<"aten.hann_window", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hann_window : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenHannWindowPeriodicOp : Torch_Op<"aten.hann_window.periodic", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hann_window.periodic : (int, bool, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenHardtanhOp : Torch_Op<"aten.hardtanh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardtanh : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min_val,
    AnyTorchScalarType:$max_val
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min_val `,` $max_val attr-dict `:` type($self) `,` type($min_val) `,` type($max_val) `->` type($result)";
}

def Torch_AtenHeavisideOp : Torch_Op<"aten.heaviside", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::heaviside : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$values
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $values attr-dict `:` type($self) `,` type($values) `->` type($result)";
}

def Torch_AtenHistogramBinsTensorOp : Torch_Op<"aten.histogram.bins_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::histogram.bins_tensor : (Tensor, Tensor, Tensor?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$bins,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density
  );
  let results = (outs
    AnyTorchTensorType:$hist,
    AnyTorchTensorType:$bin_edges
  );
  let assemblyFormat = "$self `,` $bins `,` $weight `,` $density attr-dict `:` type($self) `,` type($bins) `,` type($weight) `,` type($density) `->` type($hist) `,` type($bin_edges)";
}

def Torch_AtenHistogramBinCtOp : Torch_Op<"aten.histogram.bin_ct", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::histogram.bin_ct : (Tensor, int, float[]?, Tensor?, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$bins,
    TorchOptionalFloatListType:$range,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density
  );
  let results = (outs
    AnyTorchTensorType:$hist,
    AnyTorchTensorType:$bin_edges
  );
  let assemblyFormat = "$self `,` $bins `,` $range `,` $weight `,` $density attr-dict `:` type($self) `,` type($bins) `,` type($range) `,` type($weight) `,` type($density) `->` type($hist) `,` type($bin_edges)";
}

def Torch_AtenIndexSelectDimnameOp : Torch_Op<"aten.index_select.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_select.dimname : (Tensor, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index attr-dict `:` type($self) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenFromFileOp : Torch_Op<"aten.from_file", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::from_file : (str, bool?, int?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_StringType:$filename,
    TorchOptionalBoolType:$shared,
    TorchOptionalIntType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$filename `,` $shared `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($filename) `,` type($shared) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenKaiserWindowOp : Torch_Op<"aten.kaiser_window", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kaiser_window : (int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenKaiserWindowPeriodicOp : Torch_Op<"aten.kaiser_window.periodic", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kaiser_window.periodic : (int, bool, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenKaiserWindowBetaOp : Torch_Op<"aten.kaiser_window.beta", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kaiser_window.beta : (int, bool, float, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$window_length,
    Torch_BoolType:$periodic,
    Torch_FloatType:$beta,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$window_length `,` $periodic `,` $beta `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($window_length) `,` type($periodic) `,` type($beta) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenLinspaceOp : Torch_Op<"aten.linspace", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linspace : (Scalar, Scalar, int?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$steps,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $steps `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($start) `,` type($end) `,` type($steps) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenLogspaceOp : Torch_Op<"aten.logspace", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logspace : (Scalar, Scalar, int?, float, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$steps,
    Torch_FloatType:$base,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $steps `,` $base `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($start) `,` type($end) `,` type($steps) `,` type($base) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenOnesNamesOp : Torch_Op<"aten.ones.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::ones.names : (int[], str[]?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalStringListType:$names,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $names `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($names) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenScalarTensorOp : Torch_Op<"aten.scalar_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scalar_tensor : (Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$s,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$s `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($s) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenRangeStepOp : Torch_Op<"aten.range.step", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::range.step : (Scalar, Scalar, Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    AnyTorchScalarType:$step,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $step `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($start) `,` type($end) `,` type($step) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenRangeOp : Torch_Op<"aten.range", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::range : (Scalar, Scalar, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($start) `,` type($end) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenZerosNamesOp : Torch_Op<"aten.zeros.names", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::zeros.names : (int[], str[]?, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalStringListType:$names,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $names `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($names) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSparseCsrTensorCrowColValueSizeOp : Torch_Op<"aten.sparse_csr_tensor.crow_col_value_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_csr_tensor.crow_col_value_size : (Tensor, Tensor, Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$crow_indices,
    AnyTorchTensorType:$col_indices,
    AnyTorchTensorType:$values,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$crow_indices `,` $col_indices `,` $values `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($crow_indices) `,` type($col_indices) `,` type($values) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSparseCsrTensorCrowColValueOp : Torch_Op<"aten.sparse_csr_tensor.crow_col_value", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_csr_tensor.crow_col_value : (Tensor, Tensor, Tensor, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$crow_indices,
    AnyTorchTensorType:$col_indices,
    AnyTorchTensorType:$values,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$crow_indices `,` $col_indices `,` $values `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($crow_indices) `,` type($col_indices) `,` type($values) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSparseCooTensorSizeOp : Torch_Op<"aten.sparse_coo_tensor.size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_coo_tensor.size : (int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSparseCooTensorIndicesOp : Torch_Op<"aten.sparse_coo_tensor.indices", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_coo_tensor.indices : (Tensor, Tensor, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$values,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$indices `,` $values `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($indices) `,` type($values) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSparseCooTensorIndicesSizeOp : Torch_Op<"aten.sparse_coo_tensor.indices_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_coo_tensor.indices_size : (Tensor, Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$values,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$indices `,` $values `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($indices) `,` type($values) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenTrilIndicesOp : Torch_Op<"aten.tril_indices", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::tril_indices : (int, int, int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$row,
    Torch_IntType:$col,
    Torch_IntType:$offset,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$row `,` $col `,` $offset `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($row) `,` type($col) `,` type($offset) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenTriuIndicesOp : Torch_Op<"aten.triu_indices", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::triu_indices : (int, int, int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$row,
    Torch_IntType:$col,
    Torch_IntType:$offset,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$row `,` $col `,` $offset `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($row) `,` type($col) `,` type($offset) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenFftFftfreqOp : Torch_Op<"aten.fft_fftfreq", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_fftfreq : (int, float, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    Torch_FloatType:$d,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $d `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($n) `,` type($d) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenFftRfftfreqOp : Torch_Op<"aten.fft_rfftfreq", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fft_rfftfreq : (int, float, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    Torch_FloatType:$d,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $d `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($n) `,` type($d) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenIsposinfOp : Torch_Op<"aten.isposinf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isposinf : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsneginfOp : Torch_Op<"aten.isneginf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isneginf : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSgnOp : Torch_Op<"aten.sgn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sgn : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLcmOp : Torch_Op<"aten.lcm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lcm : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenExp2Op : Torch_Op<"aten.exp2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::exp2 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLerpScalarOp : Torch_Op<"aten.lerp.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::lerp.Scalar : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$end,
    AnyTorchScalarType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $end `,` $weight attr-dict `:` type($self) `,` type($end) `,` type($weight) `->` type($result)";
}

def Torch_AtenIsinTensorTensorOp : Torch_Op<"aten.isin.Tensor_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isin.Tensor_Tensor : (Tensor, Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$elements,
    AnyTorchTensorType:$test_elements,
    Torch_BoolType:$assume_unique,
    Torch_BoolType:$invert
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$elements `,` $test_elements `,` $assume_unique `,` $invert attr-dict `:` type($elements) `,` type($test_elements) `,` type($assume_unique) `,` type($invert) `->` type($result)";
}

def Torch_AtenIsinTensorScalarOp : Torch_Op<"aten.isin.Tensor_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isin.Tensor_Scalar : (Tensor, Scalar, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$elements,
    AnyTorchScalarType:$test_element,
    Torch_BoolType:$assume_unique,
    Torch_BoolType:$invert
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$elements `,` $test_element `,` $assume_unique `,` $invert attr-dict `:` type($elements) `,` type($test_element) `,` type($assume_unique) `,` type($invert) `->` type($result)";
}

def Torch_AtenIsinScalarTensorOp : Torch_Op<"aten.isin.Scalar_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::isin.Scalar_Tensor : (Scalar, Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$element,
    AnyTorchTensorType:$test_elements,
    Torch_BoolType:$assume_unique,
    Torch_BoolType:$invert
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$element `,` $test_elements `,` $assume_unique `,` $invert attr-dict `:` type($element) `,` type($test_elements) `,` type($assume_unique) `,` type($invert) `->` type($result)";
}

def Torch_AtenNanToNumOp : Torch_Op<"aten.nan_to_num", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nan_to_num : (Tensor, float?, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$nan,
    TorchOptionalFloatType:$posinf,
    TorchOptionalFloatType:$neginf
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $nan `,` $posinf `,` $neginf attr-dict `:` type($self) `,` type($nan) `,` type($posinf) `,` type($neginf) `->` type($result)";
}

def Torch_AtenXlogyTensorOp : Torch_Op<"aten.xlogy.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::xlogy.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenXlogyScalarSelfOp : Torch_Op<"aten.xlogy.Scalar_Self", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::xlogy.Scalar_Self : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenXlogyScalarOtherOp : Torch_Op<"aten.xlogy.Scalar_Other", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::xlogy.Scalar_Other : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogSigmoidForwardOp : Torch_Op<"aten.log_sigmoid_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log_sigmoid_forward : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$buffer
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($output) `,` type($buffer)";
}

def Torch_AtenMvlgammaOp : Torch_Op<"aten.mvlgamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mvlgamma : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenNarrowCopyOp : Torch_Op<"aten.narrow_copy", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::narrow_copy : (Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_IntType:$start,
    Torch_IntType:$length
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $start `,` $length attr-dict `:` type($self) `,` type($dim) `,` type($start) `,` type($length) `->` type($result)";
}

def Torch_AtenLogdetOp : Torch_Op<"aten.logdet", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logdet : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenChannelShuffleOp : Torch_Op<"aten.channel_shuffle", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::channel_shuffle : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $groups attr-dict `:` type($self) `,` type($groups) `->` type($result)";
}

def Torch_AtenBucketizeScalarOp : Torch_Op<"aten.bucketize.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bucketize.Scalar : (Scalar, Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$boundaries,
    Torch_BoolType:$out_int32,
    Torch_BoolType:$right
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $boundaries `,` $out_int32 `,` $right attr-dict `:` type($self) `,` type($boundaries) `,` type($out_int32) `,` type($right) `->` type($result)";
}

def Torch_AtenSiluOp : Torch_Op<"aten.silu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::silu : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMishOp : Torch_Op<"aten.mish", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mish : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLogitOp : Torch_Op<"aten.logit", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logit : (Tensor, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $eps attr-dict `:` type($self) `,` type($eps) `->` type($result)";
}

def Torch_AtenSincOp : Torch_Op<"aten.sinc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sinc : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSspaddmmOp : Torch_Op<"aten.sspaddmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sspaddmm : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat1 `,` $mat2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($mat1) `,` type($mat2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenNansumOp : Torch_Op<"aten.nansum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nansum : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_AtenNansumDimIntListOp : Torch_Op<"aten.nansum.dim_IntList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nansum.dim_IntList : (Tensor, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenRollOp : Torch_Op<"aten.roll", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::roll : (Tensor, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$shifts,
    TorchIntListType:$dims
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $shifts `,` $dims attr-dict `:` type($self) `,` type($shifts) `,` type($dims) `->` type($result)";
}

def Torch_AtenToSparseSparseDimOp : Torch_Op<"aten.to_sparse.sparse_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::to_sparse.sparse_dim : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$sparse_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $sparse_dim attr-dict `:` type($self) `,` type($sparse_dim) `->` type($result)";
}

def Torch_AtenToSparseOp : Torch_Op<"aten.to_sparse", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::to_sparse : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDequantizeSelfOp : Torch_Op<"aten.dequantize.self", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dequantize.self : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDequantizeTensorsOp : Torch_Op<"aten.dequantize.tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dequantize.tensors : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenScatterSrcOp : Torch_Op<"aten.scatter.src", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter.src : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `->` type($result)";
}

def Torch_AtenScatterValueOp : Torch_Op<"aten.scatter.value", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter.value : (Tensor, int, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenScatterReduceOp : Torch_Op<"aten.scatter.reduce", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter.reduce : (Tensor, int, Tensor, Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src,
    Torch_StringType:$reduce
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src `,` $reduce attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `,` type($reduce) `->` type($result)";
}

def Torch_AtenScatterValueReduceOp : Torch_Op<"aten.scatter.value_reduce", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter.value_reduce : (Tensor, int, Tensor, Scalar, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value,
    Torch_StringType:$reduce
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value `,` $reduce attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `,` type($reduce) `->` type($result)";
}

def Torch_AtenScatterDimnameSrcOp : Torch_Op<"aten.scatter.dimname_src", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter.dimname_src : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `->` type($result)";
}

def Torch_AtenScatterDimnameValueOp : Torch_Op<"aten.scatter.dimname_value", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::scatter.dimname_value : (Tensor, str, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenBitwiseAndScalarOp : Torch_Op<"aten.bitwise_and.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_and.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseOrTensorOp : Torch_Op<"aten.bitwise_or.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_or.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseOrScalarOp : Torch_Op<"aten.bitwise_or.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_or.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseXorTensorOp : Torch_Op<"aten.bitwise_xor.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_xor.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseXorScalarOp : Torch_Op<"aten.bitwise_xor.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_xor.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseLeftShiftTensorOp : Torch_Op<"aten.bitwise_left_shift.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseLeftShiftTensorScalarOp : Torch_Op<"aten.bitwise_left_shift.Tensor_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift.Tensor_Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseLeftShiftScalarTensorOp : Torch_Op<"aten.bitwise_left_shift.Scalar_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift.Scalar_Tensor : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseRightShiftTensorOp : Torch_Op<"aten.bitwise_right_shift.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseRightShiftTensorScalarOp : Torch_Op<"aten.bitwise_right_shift.Tensor_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift.Tensor_Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseRightShiftScalarTensorOp : Torch_Op<"aten.bitwise_right_shift.Scalar_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift.Scalar_Tensor : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenTakeOp : Torch_Op<"aten.take", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::take : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $index attr-dict `:` type($self) `,` type($index) `->` type($result)";
}

def Torch_AtenNonzeroOp : Torch_Op<"aten.nonzero", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nonzero : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRemainderTensorOp : Torch_Op<"aten.remainder.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::remainder.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenRemainderScalarTensorOp : Torch_Op<"aten.remainder.Scalar_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::remainder.Scalar_Tensor : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenRemainderScalarOp : Torch_Op<"aten.remainder.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::remainder.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSortOp : Torch_Op<"aten.sort", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sort : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$descending
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $descending attr-dict `:` type($self) `,` type($dim) `,` type($descending) `->` type($values) `,` type($indices)";
}

def Torch_AtenSortStableOp : Torch_Op<"aten.sort.stable", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sort.stable : (Tensor, bool?, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalBoolType:$stable,
    Torch_IntType:$dim,
    Torch_BoolType:$descending
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $stable `,` $dim `,` $descending attr-dict `:` type($self) `,` type($stable) `,` type($dim) `,` type($descending) `->` type($values) `,` type($indices)";
}

def Torch_AtenSortDimnameOp : Torch_Op<"aten.sort.dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sort.dimname : (Tensor, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$descending
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $descending attr-dict `:` type($self) `,` type($dim) `,` type($descending) `->` type($values) `,` type($indices)";
}

def Torch_AtenSortDimnameStableOp : Torch_Op<"aten.sort.dimname_stable", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sort.dimname_stable : (Tensor, bool?, str, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalBoolType:$stable,
    Torch_StringType:$dim,
    Torch_BoolType:$descending
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $stable `,` $dim `,` $descending attr-dict `:` type($self) `,` type($stable) `,` type($dim) `,` type($descending) `->` type($values) `,` type($indices)";
}

def Torch_AtenSpecialNdtriOp : Torch_Op<"aten.special_ndtri", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_ndtri : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNllLoss2dForwardOp : Torch_Op<"aten.nll_loss2d_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss2d_forward : (Tensor, Tensor, Tensor?, int, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$total_weight
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `->` type($output) `,` type($total_weight)";
}

def Torch_AtenReflectionPad3dOp : Torch_Op<"aten.reflection_pad3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reflection_pad3d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding attr-dict `:` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenLinalgPinvAtolRtolTensorOp : Torch_Op<"aten.linalg_pinv.atol_rtol_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.atol_rtol_tensor : (Tensor, Tensor?, Tensor?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$atol,
    AnyTorchOptionalTensorType:$rtol,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $atol `,` $rtol `,` $hermitian attr-dict `:` type($self) `,` type($atol) `,` type($rtol) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgPinvAtolRtolFloatOp : Torch_Op<"aten.linalg_pinv.atol_rtol_float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.atol_rtol_float : (Tensor, float?, float?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$atol,
    TorchOptionalFloatType:$rtol,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $atol `,` $rtol `,` $hermitian attr-dict `:` type($self) `,` type($atol) `,` type($rtol) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgPinvOp : Torch_Op<"aten.linalg_pinv", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_pinv : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$rcond,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $rcond `,` $hermitian attr-dict `:` type($self) `,` type($rcond) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenLinalgPinvRcondTensorOp : Torch_Op<"aten.linalg_pinv.rcond_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.rcond_tensor : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$rcond,
    Torch_BoolType:$hermitian
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $rcond `,` $hermitian attr-dict `:` type($self) `,` type($rcond) `,` type($hermitian) `->` type($result)";
}

def Torch_AtenUpsampleBicubic2dOp : Torch_Op<"aten.upsample_bicubic2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bicubic2d : (Tensor, int[], bool, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales_h `,` $scales_w attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleBicubic2dVecOp : Torch_Op<"aten.upsample_bicubic2d.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bicubic2d.vec : (Tensor, int[]?, bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchOptionalIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $output_size `,` $align_corners `,` $scale_factors attr-dict `:` type($input) `,` type($output_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenSpecialErfcxOp : Torch_Op<"aten.special_erfcx", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_erfcx : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialXlog1pyOp : Torch_Op<"aten.special_xlog1py", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_xlog1py : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialXlog1pySelfScalarOp : Torch_Op<"aten.special_xlog1py.self_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_xlog1py.self_scalar : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialXlog1pyOtherScalarOp : Torch_Op<"aten.special_xlog1py.other_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_xlog1py.other_scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialZetaOp : Torch_Op<"aten.special_zeta", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_zeta : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialZetaSelfScalarOp : Torch_Op<"aten.special_zeta.self_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_zeta.self_scalar : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialZetaOtherScalarOp : Torch_Op<"aten.special_zeta.other_scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_zeta.other_scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenSpecialI0eOp : Torch_Op<"aten.special_i0e", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_i0e : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialI1Op : Torch_Op<"aten.special_i1", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_i1 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSpecialI1eOp : Torch_Op<"aten.special_i1e", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::special_i1e : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgMatrixExpOp : Torch_Op<"aten.linalg_matrix_exp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_exp : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgSlogdetOp : Torch_Op<"aten.linalg_slogdet", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_slogdet : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$sign,
    AnyTorchTensorType:$logabsdet
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($sign) `,` type($logabsdet)";
}

def Torch_AtenLinalgVectorNormOp : Torch_Op<"aten.linalg_vector_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::linalg_vector_norm : (Tensor, Scalar, int[]?, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$ord,
    TorchOptionalIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenSegmentReduceOp : Torch_Op<"aten.segment_reduce", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::segment_reduce : (Tensor, str, Tensor?, Tensor?, int, bool, Scalar?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$data,
    Torch_StringType:$reduce,
    AnyTorchOptionalTensorType:$lengths,
    AnyTorchOptionalTensorType:$indices,
    Torch_IntType:$axis,
    Torch_BoolType:$unsafe,
    AnyTorchOptionalScalarType:$initial
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$data `,` $reduce `,` $lengths `,` $indices `,` $axis `,` $unsafe `,` $initial attr-dict `:` type($data) `,` type($reduce) `,` type($lengths) `,` type($indices) `,` type($axis) `,` type($unsafe) `,` type($initial) `->` type($result)";
}

def Torch_AtenSelectScatterOp : Torch_Op<"aten.select_scatter", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::select_scatter : (Tensor, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$src,
    Torch_IntType:$dim,
    Torch_IntType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $src `,` $dim `,` $index attr-dict `:` type($self) `,` type($src) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenSlogdetOp : Torch_Op<"aten.slogdet", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slogdet : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$sign,
    AnyTorchTensorType:$logabsdet
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($sign) `,` type($logabsdet)";
}

def Torch_AtenRot90Op : Torch_Op<"aten.rot90", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rot90 : (Tensor, int, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    TorchIntListType:$dims
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $k `,` $dims attr-dict `:` type($self) `,` type($k) `,` type($dims) `->` type($result)";
}

def Torch_AtenConvDepthwise3dOp : Torch_Op<"aten.conv_depthwise3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_depthwise3d : (Tensor, Tensor, int[], Tensor?, int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $dilation attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `->` type($result)";
}

def Torch_Aten_TorchCudaCuLinkerSymbolOpOp : Torch_Op<"aten._torch_cuda_cu_linker_symbol_op", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_torch_cuda_cu_linker_symbol_op : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_ThnnFusedGruCellBackwardOp : Torch_Op<"aten._thnn_fused_gru_cell_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_thnn_fused_gru_cell_backward : (Tensor, Tensor, bool) -> (Tensor, Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_hy,
    AnyTorchTensorType:$workspace,
    Torch_BoolType:$has_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    AnyTorchTensorType:$result4
  );
  let assemblyFormat = "$grad_hy `,` $workspace `,` $has_bias attr-dict `:` type($grad_hy) `,` type($workspace) `,` type($has_bias) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_Aten_ThnnFusedLstmCellBackwardOp : Torch_Op<"aten._thnn_fused_lstm_cell_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_thnn_fused_lstm_cell_backward : (Tensor?, Tensor?, Tensor, Tensor, Tensor, bool) -> (Tensor, Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchOptionalTensorType:$grad_hy,
    AnyTorchOptionalTensorType:$grad_cy,
    AnyTorchTensorType:$cx,
    AnyTorchTensorType:$cy,
    AnyTorchTensorType:$workspace,
    Torch_BoolType:$has_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    AnyTorchTensorType:$result4
  );
  let assemblyFormat = "$grad_hy `,` $grad_cy `,` $cx `,` $cy `,` $workspace `,` $has_bias attr-dict `:` type($grad_hy) `,` type($grad_cy) `,` type($cx) `,` type($cy) `,` type($workspace) `,` type($has_bias) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_Aten_CoalesceOp : Torch_Op<"aten._coalesce", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_coalesce : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_NnzOp : Torch_Op<"aten._nnz", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_nnz : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_DimVOp : Torch_Op<"aten._dimV", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_dimV : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDenseDimOp : Torch_Op<"aten.dense_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::dense_dim : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_DimIOp : Torch_Op<"aten._dimI", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_dimI : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSparseDimOp : Torch_Op<"aten.sparse_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sparse_dim : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_SparseLogSoftmaxBackwardDataOp : Torch_Op<"aten._sparse_log_softmax_backward_data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_log_softmax_backward_data : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    Torch_IntType:$dim,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $dim `,` $self attr-dict `:` type($grad_output) `,` type($output) `,` type($dim) `,` type($self) `->` type($result)";
}

def Torch_Aten_SparseSoftmaxBackwardDataOp : Torch_Op<"aten._sparse_softmax_backward_data", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_softmax_backward_data : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    Torch_IntType:$dim,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $dim `,` $self attr-dict `:` type($grad_output) `,` type($output) `,` type($dim) `,` type($self) `->` type($result)";
}

def Torch_Aten_SparseSumBackwardOp : Torch_Op<"aten._sparse_sum_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_sum_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self,
    TorchIntListType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self `,` $dim attr-dict `:` type($grad) `,` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenNativeNormOp : Torch_Op<"aten.native_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_norm : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenNativeNormScalarOptDimDtypeOp : Torch_Op<"aten.native_norm.ScalarOpt_dim_dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_norm.ScalarOpt_dim_dtype : (Tensor, Scalar?, int[], bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $dtype attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_WeightNormCudaInterfaceBackwardOp : Torch_Op<"aten._weight_norm_cuda_interface_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_weight_norm_cuda_interface_backward : (Tensor, Tensor, Tensor, Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_w,
    AnyTorchTensorType:$saved_v,
    AnyTorchTensorType:$saved_g,
    AnyTorchTensorType:$saved_norms,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_w `,` $saved_v `,` $saved_g `,` $saved_norms `,` $dim attr-dict `:` type($grad_w) `,` type($saved_v) `,` type($saved_g) `,` type($saved_norms) `,` type($dim) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_WeightNormCudaInterfaceOp : Torch_Op<"aten._weight_norm_cuda_interface", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_weight_norm_cuda_interface : (Tensor, Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$v,
    AnyTorchTensorType:$g,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$v `,` $g `,` $dim attr-dict `:` type($v) `,` type($g) `,` type($dim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenBatchNormBackwardElemtOp : Torch_Op<"aten.batch_norm_backward_elemt", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_backward_elemt : (Tensor, Tensor, Tensor, Tensor, Tensor?, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$invstd,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchTensorType:$mean_dy,
    AnyTorchTensorType:$mean_dy_xmu,
    AnyTorchTensorType:$count
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_out `,` $input `,` $mean `,` $invstd `,` $weight `,` $mean_dy `,` $mean_dy_xmu `,` $count attr-dict `:` type($grad_out) `,` type($input) `,` type($mean) `,` type($invstd) `,` type($weight) `,` type($mean_dy) `,` type($mean_dy_xmu) `,` type($count) `->` type($result)";
}

def Torch_AtenBatchNormBackwardReduceOp : Torch_Op<"aten.batch_norm_backward_reduce", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_backward_reduce : (Tensor, Tensor, Tensor, Tensor, Tensor?, bool, bool, bool) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$invstd,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$input_g,
    Torch_BoolType:$weight_g,
    Torch_BoolType:$bias_g
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3
  );
  let assemblyFormat = "$grad_out `,` $input `,` $mean `,` $invstd `,` $weight `,` $input_g `,` $weight_g `,` $bias_g attr-dict `:` type($grad_out) `,` type($input) `,` type($mean) `,` type($invstd) `,` type($weight) `,` type($input_g) `,` type($weight_g) `,` type($bias_g) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_AtenBatchNormGatherStatsWithCountsOp : Torch_Op<"aten.batch_norm_gather_stats_with_counts", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_gather_stats_with_counts : (Tensor, Tensor, Tensor, Tensor?, Tensor?, float, float, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$invstd,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps,
    AnyTorchTensorType:$counts
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $mean `,` $invstd `,` $running_mean `,` $running_var `,` $momentum `,` $eps `,` $counts attr-dict `:` type($input) `,` type($mean) `,` type($invstd) `,` type($running_mean) `,` type($running_var) `,` type($momentum) `,` type($eps) `,` type($counts) `->` type($result0) `,` type($result1)";
}

def Torch_AtenBatchNormGatherStatsOp : Torch_Op<"aten.batch_norm_gather_stats", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_gather_stats : (Tensor, Tensor, Tensor, Tensor?, Tensor?, float, float, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$invstd,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps,
    Torch_IntType:$count
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $mean `,` $invstd `,` $running_mean `,` $running_var `,` $momentum `,` $eps `,` $count attr-dict `:` type($input) `,` type($mean) `,` type($invstd) `,` type($running_mean) `,` type($running_var) `,` type($momentum) `,` type($eps) `,` type($count) `->` type($result0) `,` type($result1)";
}

def Torch_AtenBatchNormStatsOp : Torch_Op<"aten.batch_norm_stats", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_stats : (Tensor, float) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    Torch_FloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $eps attr-dict `:` type($input) `,` type($eps) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_SparseMaskHelperOp : Torch_Op<"aten._sparse_mask_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_mask_helper : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$t,
    AnyTorchTensorType:$mask_indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$t `,` $mask_indices attr-dict `:` type($t) `,` type($mask_indices) `->` type($result)";
}

def Torch_Aten_SparseSparseMatmulOp : Torch_Op<"aten._sparse_sparse_matmul", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_sparse_matmul : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMiopenRnnBackwardOp : Torch_Op<"aten.miopen_rnn_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_rnn_backward : (Tensor, Tensor[], int, Tensor, Tensor, Tensor?, Tensor, Tensor?, Tensor?, Tensor?, int, int, int, bool, float, bool, bool, int[], Tensor?, Tensor, bool[]) -> (Tensor, Tensor, Tensor, Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$weight,
    Torch_IntType:$weight_stride0,
    AnyTorchTensorType:$weight_buf,
    AnyTorchTensorType:$hx,
    AnyTorchOptionalTensorType:$cx,
    AnyTorchTensorType:$output,
    AnyTorchOptionalTensorType:$grad_output,
    AnyTorchOptionalTensorType:$grad_hy,
    AnyTorchOptionalTensorType:$grad_cy,
    Torch_IntType:$mode,
    Torch_IntType:$hidden_size,
    Torch_IntType:$num_layers,
    Torch_BoolType:$batch_first,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    TorchIntListType:$batch_sizes,
    AnyTorchOptionalTensorType:$dropout_state,
    AnyTorchTensorType:$reserve,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorListType:$result3
  );
  let assemblyFormat = "$input `,` $weight `,` $weight_stride0 `,` $weight_buf `,` $hx `,` $cx `,` $output `,` $grad_output `,` $grad_hy `,` $grad_cy `,` $mode `,` $hidden_size `,` $num_layers `,` $batch_first `,` $dropout `,` $train `,` $bidirectional `,` $batch_sizes `,` $dropout_state `,` $reserve `,` $output_mask attr-dict `:` type($input) `,` type($weight) `,` type($weight_stride0) `,` type($weight_buf) `,` type($hx) `,` type($cx) `,` type($output) `,` type($grad_output) `,` type($grad_hy) `,` type($grad_cy) `,` type($mode) `,` type($hidden_size) `,` type($num_layers) `,` type($batch_first) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_sizes) `,` type($dropout_state) `,` type($reserve) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_AtenMiopenRnnOp : Torch_Op<"aten.miopen_rnn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_rnn : (Tensor, Tensor[], int, Tensor, Tensor?, int, int, int, bool, float, bool, bool, int[], Tensor?) -> (Tensor, Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$weight,
    Torch_IntType:$weight_stride0,
    AnyTorchTensorType:$hx,
    AnyTorchOptionalTensorType:$cx,
    Torch_IntType:$mode,
    Torch_IntType:$hidden_size,
    Torch_IntType:$num_layers,
    Torch_BoolType:$batch_first,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    TorchIntListType:$batch_sizes,
    AnyTorchOptionalTensorType:$dropout_state
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    AnyTorchTensorType:$result4
  );
  let assemblyFormat = "$input `,` $weight `,` $weight_stride0 `,` $hx `,` $cx `,` $mode `,` $hidden_size `,` $num_layers `,` $batch_first `,` $dropout `,` $train `,` $bidirectional `,` $batch_sizes `,` $dropout_state attr-dict `:` type($input) `,` type($weight) `,` type($weight_stride0) `,` type($hx) `,` type($cx) `,` type($mode) `,` type($hidden_size) `,` type($num_layers) `,` type($batch_first) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_sizes) `,` type($dropout_state) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_AtenMiopenDepthwiseConvolutionBackwardWeightOp : Torch_Op<"aten.miopen_depthwise_convolution_backward_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_depthwise_convolution_backward_weight : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$weight_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight_size `,` $grad_output `,` $self `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($weight_size) `,` type($grad_output) `,` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenDepthwiseConvolutionBackwardOp : Torch_Op<"aten.miopen_depthwise_convolution_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_depthwise_convolution_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int, bool, bool, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMiopenDepthwiseConvolutionBackwardInputOp : Torch_Op<"aten.miopen_depthwise_convolution_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_depthwise_convolution_backward_input : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$self_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self_size `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self_size) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenDepthwiseConvolutionOp : Torch_Op<"aten.miopen_depthwise_convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_depthwise_convolution : (Tensor, Tensor, Tensor?, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenConvolutionTransposeBackwardWeightOp : Torch_Op<"aten.miopen_convolution_transpose_backward_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_transpose_backward_weight : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$weight_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight_size `,` $grad_output `,` $self `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($weight_size) `,` type($grad_output) `,` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenConvolutionTransposeBackwardInputOp : Torch_Op<"aten.miopen_convolution_transpose_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_transpose_backward_input : (Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenConvolutionTransposeBackwardOp : Torch_Op<"aten.miopen_convolution_transpose_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_transpose_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int, bool, bool, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $padding `,` $output_padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($output_padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMiopenConvolutionTransposeOp : Torch_Op<"aten.miopen_convolution_transpose", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_transpose : (Tensor, Tensor, Tensor?, int[], int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $padding `,` $output_padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($output_padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenConvolutionBackwardWeightOp : Torch_Op<"aten.miopen_convolution_backward_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_backward_weight : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$weight_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight_size `,` $grad_output `,` $self `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($weight_size) `,` type($grad_output) `,` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenConvolutionBackwardBiasOp : Torch_Op<"aten.miopen_convolution_backward_bias", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_backward_bias : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output attr-dict `:` type($grad_output) `->` type($result)";
}

def Torch_AtenMiopenConvolutionBackwardOp : Torch_Op<"aten.miopen_convolution_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int, bool, bool, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMiopenConvolutionBackwardInputOp : Torch_Op<"aten.miopen_convolution_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution_backward_input : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$self_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self_size `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self_size) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenConvolutionOp : Torch_Op<"aten.miopen_convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_convolution : (Tensor, Tensor, Tensor?, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenMiopenBatchNormBackwardOp : Torch_Op<"aten.miopen_batch_norm_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_batch_norm_backward : (Tensor, Tensor, Tensor, Tensor?, Tensor?, Tensor?, Tensor?, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    AnyTorchOptionalTensorType:$save_mean,
    AnyTorchOptionalTensorType:$save_var,
    Torch_FloatType:$epsilon
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $grad_output `,` $weight `,` $running_mean `,` $running_var `,` $save_mean `,` $save_var `,` $epsilon attr-dict `:` type($input) `,` type($grad_output) `,` type($weight) `,` type($running_mean) `,` type($running_var) `,` type($save_mean) `,` type($save_var) `,` type($epsilon) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMiopenBatchNormOp : Torch_Op<"aten.miopen_batch_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::miopen_batch_norm : (Tensor, Tensor, Tensor?, Tensor?, Tensor?, bool, float, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$training,
    Torch_FloatType:$exponential_average_factor,
    Torch_FloatType:$epsilon
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $training `,` $exponential_average_factor `,` $epsilon attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($training) `,` type($exponential_average_factor) `,` type($epsilon) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenCudnnGridSamplerBackwardOp : Torch_Op<"aten.cudnn_grid_sampler_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_grid_sampler_backward : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grid,
    AnyTorchTensorType:$grad_output
  );
  let results = (outs
    AnyTorchTensorType:$grad_self,
    AnyTorchTensorType:$grad_grid
  );
  let assemblyFormat = "$self `,` $grid `,` $grad_output attr-dict `:` type($self) `,` type($grid) `,` type($grad_output) `->` type($grad_self) `,` type($grad_grid)";
}

def Torch_AtenCudnnGridSamplerOp : Torch_Op<"aten.cudnn_grid_sampler", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_grid_sampler : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grid
  );
  let results = (outs
    AnyTorchTensorType:$output
  );
  let assemblyFormat = "$self `,` $grid attr-dict `:` type($self) `,` type($grid) `->` type($output)";
}

def Torch_AtenCudnnConvolutionAddReluOp : Torch_Op<"aten.cudnn_convolution_add_relu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_add_relu : (Tensor, Tensor, Tensor, Scalar?, Tensor?, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$z,
    AnyTorchOptionalScalarType:$alpha,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $z `,` $alpha `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($self) `,` type($weight) `,` type($z) `,` type($alpha) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenCudnnConvolutionReluOp : Torch_Op<"aten.cudnn_convolution_relu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_relu : (Tensor, Tensor, Tensor?, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenCudnnConvolutionTransposeBackwardWeightOp : Torch_Op<"aten.cudnn_convolution_transpose_backward_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_transpose_backward_weight : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$weight_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight_size `,` $grad_output `,` $self `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 attr-dict `:` type($weight_size) `,` type($grad_output) `,` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `->` type($result)";
}

def Torch_AtenCudnnConvolutionTransposeBackwardInputOp : Torch_Op<"aten.cudnn_convolution_transpose_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_transpose_backward_input : (Tensor, Tensor, int[], int[], int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 attr-dict `:` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `->` type($result)";
}

def Torch_AtenCudnnConvolutionTransposeBackwardOp : Torch_Op<"aten.cudnn_convolution_transpose_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_transpose_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int, bool, bool, bool, bool[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $padding `,` $output_padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($output_padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `,` type($output_mask) `->` type($result0) `,` type($result1)";
}

def Torch_AtenCudnnConvolutionBackwardWeightOp : Torch_Op<"aten.cudnn_convolution_backward_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_backward_weight : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$weight_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight_size `,` $grad_output `,` $self `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 attr-dict `:` type($weight_size) `,` type($grad_output) `,` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `->` type($result)";
}

def Torch_AtenCudnnConvolutionBackwardOp : Torch_Op<"aten.cudnn_convolution_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int, bool, bool, bool, bool[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `,` type($output_mask) `->` type($result0) `,` type($result1)";
}

def Torch_AtenCudnnConvolutionBackwardInputOp : Torch_Op<"aten.cudnn_convolution_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_backward_input : (int[], Tensor, Tensor, int[], int[], int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$self_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self_size `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 attr-dict `:` type($self_size) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `->` type($result)";
}

def Torch_AtenCudnnBatchNormBackwardOp : Torch_Op<"aten.cudnn_batch_norm_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_batch_norm_backward : (Tensor, Tensor, Tensor, Tensor?, Tensor?, Tensor?, Tensor?, float, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    AnyTorchOptionalTensorType:$save_mean,
    AnyTorchOptionalTensorType:$save_var,
    Torch_FloatType:$epsilon,
    AnyTorchTensorType:$reserveSpace
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $grad_output `,` $weight `,` $running_mean `,` $running_var `,` $save_mean `,` $save_var `,` $epsilon `,` $reserveSpace attr-dict `:` type($input) `,` type($grad_output) `,` type($weight) `,` type($running_mean) `,` type($running_var) `,` type($save_mean) `,` type($save_var) `,` type($epsilon) `,` type($reserveSpace) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenCudnnBatchNormOp : Torch_Op<"aten.cudnn_batch_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_batch_norm : (Tensor, Tensor, Tensor?, Tensor?, Tensor?, bool, float, float) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$training,
    Torch_FloatType:$exponential_average_factor,
    Torch_FloatType:$epsilon
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $training `,` $exponential_average_factor `,` $epsilon attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($training) `,` type($exponential_average_factor) `,` type($epsilon) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_Aten_CopyFromAndResizeOp : Torch_Op<"aten._copy_from_and_resize", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_copy_from_and_resize : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$dst
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dst attr-dict `:` type($self) `,` type($dst) `->` type($result)";
}

def Torch_Aten_CopyFromOp : Torch_Op<"aten._copy_from", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_copy_from : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$dst,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dst `,` $non_blocking attr-dict `:` type($self) `,` type($dst) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_MaskedScaleOp : Torch_Op<"aten._masked_scale", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_masked_scale : (Tensor, Tensor, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    Torch_FloatType:$scale
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $scale attr-dict `:` type($self) `,` type($mask) `,` type($scale) `->` type($result)";
}

def Torch_Aten_CudnnRnnBackwardOp : Torch_Op<"aten._cudnn_rnn_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cudnn_rnn_backward : (Tensor, Tensor[], int, Tensor, Tensor, Tensor?, Tensor, Tensor?, Tensor?, Tensor?, int, int, int, int, bool, float, bool, bool, int[], Tensor?, Tensor, bool[]) -> (Tensor, Tensor, Tensor, Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$weight,
    Torch_IntType:$weight_stride0,
    AnyTorchTensorType:$weight_buf,
    AnyTorchTensorType:$hx,
    AnyTorchOptionalTensorType:$cx,
    AnyTorchTensorType:$output,
    AnyTorchOptionalTensorType:$grad_output,
    AnyTorchOptionalTensorType:$grad_hy,
    AnyTorchOptionalTensorType:$grad_cy,
    Torch_IntType:$mode,
    Torch_IntType:$hidden_size,
    Torch_IntType:$proj_size,
    Torch_IntType:$num_layers,
    Torch_BoolType:$batch_first,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    TorchIntListType:$batch_sizes,
    AnyTorchOptionalTensorType:$dropout_state,
    AnyTorchTensorType:$reserve,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorListType:$result3
  );
  let assemblyFormat = "$input `,` $weight `,` $weight_stride0 `,` $weight_buf `,` $hx `,` $cx `,` $output `,` $grad_output `,` $grad_hy `,` $grad_cy `,` $mode `,` $hidden_size `,` $proj_size `,` $num_layers `,` $batch_first `,` $dropout `,` $train `,` $bidirectional `,` $batch_sizes `,` $dropout_state `,` $reserve `,` $output_mask attr-dict `:` type($input) `,` type($weight) `,` type($weight_stride0) `,` type($weight_buf) `,` type($hx) `,` type($cx) `,` type($output) `,` type($grad_output) `,` type($grad_hy) `,` type($grad_cy) `,` type($mode) `,` type($hidden_size) `,` type($proj_size) `,` type($num_layers) `,` type($batch_first) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_sizes) `,` type($dropout_state) `,` type($reserve) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_Aten_CudnnRnnOp : Torch_Op<"aten._cudnn_rnn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cudnn_rnn : (Tensor, Tensor[], int, Tensor?, Tensor, Tensor?, int, int, int, int, bool, float, bool, bool, int[], Tensor?) -> (Tensor, Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorListType:$weight,
    Torch_IntType:$weight_stride0,
    AnyTorchOptionalTensorType:$weight_buf,
    AnyTorchTensorType:$hx,
    AnyTorchOptionalTensorType:$cx,
    Torch_IntType:$mode,
    Torch_IntType:$hidden_size,
    Torch_IntType:$proj_size,
    Torch_IntType:$num_layers,
    Torch_BoolType:$batch_first,
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_BoolType:$bidirectional,
    TorchIntListType:$batch_sizes,
    AnyTorchOptionalTensorType:$dropout_state
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    AnyTorchTensorType:$result4
  );
  let assemblyFormat = "$input `,` $weight `,` $weight_stride0 `,` $weight_buf `,` $hx `,` $cx `,` $mode `,` $hidden_size `,` $proj_size `,` $num_layers `,` $batch_first `,` $dropout `,` $train `,` $bidirectional `,` $batch_sizes `,` $dropout_state attr-dict `:` type($input) `,` type($weight) `,` type($weight_stride0) `,` type($weight_buf) `,` type($hx) `,` type($cx) `,` type($mode) `,` type($hidden_size) `,` type($proj_size) `,` type($num_layers) `,` type($batch_first) `,` type($dropout) `,` type($train) `,` type($bidirectional) `,` type($batch_sizes) `,` type($dropout_state) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_Aten_CudnnRnnFlattenWeightOp : Torch_Op<"aten._cudnn_rnn_flatten_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cudnn_rnn_flatten_weight : (Tensor[], int, int, int, int, int, int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$weight_arr,
    Torch_IntType:$weight_stride0,
    Torch_IntType:$input_size,
    Torch_IntType:$mode,
    Torch_IntType:$hidden_size,
    Torch_IntType:$proj_size,
    Torch_IntType:$num_layers,
    Torch_BoolType:$batch_first,
    Torch_BoolType:$bidirectional
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight_arr `,` $weight_stride0 `,` $input_size `,` $mode `,` $hidden_size `,` $proj_size `,` $num_layers `,` $batch_first `,` $bidirectional attr-dict `:` type($weight_arr) `,` type($weight_stride0) `,` type($input_size) `,` type($mode) `,` type($hidden_size) `,` type($proj_size) `,` type($num_layers) `,` type($batch_first) `,` type($bidirectional) `->` type($result)";
}

def Torch_Aten_CudnnCtcLossOp : Torch_Op<"aten._cudnn_ctc_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cudnn_ctc_loss : (Tensor, Tensor, int[], int[], int, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$log_probs,
    AnyTorchTensorType:$targets,
    TorchIntListType:$input_lengths,
    TorchIntListType:$target_lengths,
    Torch_IntType:$blank,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$zero_infinity
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$log_probs `,` $targets `,` $input_lengths `,` $target_lengths `,` $blank `,` $deterministic `,` $zero_infinity attr-dict `:` type($log_probs) `,` type($targets) `,` type($input_lengths) `,` type($target_lengths) `,` type($blank) `,` type($deterministic) `,` type($zero_infinity) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_UseCudnnCtcLossOp : Torch_Op<"aten._use_cudnn_ctc_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_use_cudnn_ctc_loss : (Tensor, Tensor, int[], int[], int) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$log_probs,
    AnyTorchTensorType:$targets,
    TorchIntListType:$input_lengths,
    TorchIntListType:$target_lengths,
    Torch_IntType:$blank
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$log_probs `,` $targets `,` $input_lengths `,` $target_lengths `,` $blank attr-dict `:` type($log_probs) `,` type($targets) `,` type($input_lengths) `,` type($target_lengths) `,` type($blank) `->` type($result)";
}

def Torch_AtenQPerChannelAxisOp : Torch_Op<"aten.q_per_channel_axis", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::q_per_channel_axis : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenQZeroPointOp : Torch_Op<"aten.q_zero_point", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::q_zero_point : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenQScaleOp : Torch_Op<"aten.q_scale", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::q_scale : (Tensor) -> (float)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_FloatType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenQuantizedMaxPool2dOp : Torch_Op<"aten.quantized_max_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_max_pool2d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenQuantizedMaxPool1dOp : Torch_Op<"aten.quantized_max_pool1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_max_pool1d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenQuantizedBatchNormOp : Torch_Op<"aten.quantized_batch_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::quantized_batch_norm : (Tensor, Tensor?, Tensor?, Tensor, Tensor, float, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$var,
    Torch_FloatType:$eps,
    Torch_FloatType:$output_scale,
    Torch_IntType:$output_zero_point
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $mean `,` $var `,` $eps `,` $output_scale `,` $output_zero_point attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($mean) `,` type($var) `,` type($eps) `,` type($output_scale) `,` type($output_zero_point) `->` type($result)";
}

def Torch_AtenMkldnnAdaptiveAvgPool2dBackwardOp : Torch_Op<"aten.mkldnn_adaptive_avg_pool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_adaptive_avg_pool2d_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_AtenMkldnnAdaptiveAvgPool2dOp : Torch_Op<"aten.mkldnn_adaptive_avg_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_adaptive_avg_pool2d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result)";
}

def Torch_AtenMkldnnReorderConv3dWeightOp : Torch_Op<"aten.mkldnn_reorder_conv3d_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_reorder_conv3d_weight : (Tensor, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $stride `,` $dilation `,` $groups attr-dict `:` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenMkldnnReorderConv2dWeightOp : Torch_Op<"aten.mkldnn_reorder_conv2d_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_reorder_conv2d_weight : (Tensor, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $stride `,` $dilation `,` $groups attr-dict `:` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_Aten_MkldnnTransposeOp : Torch_Op<"aten._mkldnn_transpose", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_mkldnn_transpose : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim0,
    Torch_IntType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_Aten_MkldnnReshapeOp : Torch_Op<"aten._mkldnn_reshape", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_mkldnn_reshape : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$shape
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $shape attr-dict `:` type($self) `,` type($shape) `->` type($result)";
}

def Torch_AtenMkldnnMaxPool3dBackwardOp : Torch_Op<"aten.mkldnn_max_pool3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_max_pool3d_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$input,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $input `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($grad_output) `,` type($output) `,` type($input) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenMkldnnMaxPool3dOp : Torch_Op<"aten.mkldnn_max_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_max_pool3d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenMkldnnMaxPool2dBackwardOp : Torch_Op<"aten.mkldnn_max_pool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_max_pool2d_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$input,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $input `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($grad_output) `,` type($output) `,` type($input) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenMkldnnMaxPool2dOp : Torch_Op<"aten.mkldnn_max_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_max_pool2d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenMkldnnLinearBackwardOp : Torch_Op<"aten.mkldnn_linear_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_linear_backward : (Tensor, Tensor, Tensor, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenMkldnnLinearBackwardWeightsOp : Torch_Op<"aten.mkldnn_linear_backward_weights", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_linear_backward_weights : (Tensor, Tensor, Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    Torch_BoolType:$bias_defined
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_output `,` $input `,` $weight `,` $bias_defined attr-dict `:` type($grad_output) `,` type($input) `,` type($weight) `,` type($bias_defined) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMkldnnLinearBackwardInputOp : Torch_Op<"aten.mkldnn_linear_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_linear_backward_input : (int[], Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$input_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input_size `,` $grad_output `,` $weight attr-dict `:` type($input_size) `,` type($grad_output) `,` type($weight) `->` type($result)";
}

def Torch_AtenMkldnnLinearOp : Torch_Op<"aten.mkldnn_linear", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_linear : (Tensor, Tensor, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias attr-dict `:` type($self) `,` type($weight) `,` type($bias) `->` type($result)";
}

def Torch_AtenConvDepthwise3dBackwardGradInputOp : Torch_Op<"aten.conv_depthwise3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::conv_depthwise3d_backward.grad_input : (Tensor, Tensor, Tensor, int[], int[], int[], int[], Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $grad_input `,` $grad_weight `,` $grad_bias attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($grad_input) `,` type($grad_weight) `,` type($grad_bias) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenConvDepthwise3dBackwardOutputMaskOp : Torch_Op<"aten.conv_depthwise3d_backward.output_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_depthwise3d_backward.output_mask : (Tensor, Tensor, Tensor, int[], int[], int[], int[], bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_Aten_ConvDepthwise2dBackwardGradInputOp : Torch_Op<"aten._conv_depthwise2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_conv_depthwise2d_backward.grad_input : (Tensor, Tensor, Tensor, int[], int[], int[], int[], Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $grad_input `,` $grad_weight attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($grad_input) `,` type($grad_weight) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_ConvDepthwise2dBackwardOutputMaskOp : Torch_Op<"aten._conv_depthwise2d_backward.output_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_conv_depthwise2d_backward.output_mask : (Tensor, Tensor, Tensor, int[], int[], int[], int[], bool[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight)";
}

def Torch_Aten_AmpForeachNonFiniteCheckAndUnscale_Op : Torch_Op<"aten._amp_foreach_non_finite_check_and_unscale_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_amp_foreach_non_finite_check_and_unscale_ : (Tensor[], Tensor, Tensor) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorType:$found_inf,
    AnyTorchTensorType:$inv_scale
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $found_inf `,` $inv_scale attr-dict `:` type($self) `,` type($found_inf) `,` type($inv_scale)";
}

def Torch_AtenCopySparseToSparse_Op : Torch_Op<"aten.copy_sparse_to_sparse_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::copy_sparse_to_sparse_ : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$src,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $src `,` $non_blocking attr-dict `:` type($self) `,` type($src) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_ValuesOp : Torch_Op<"aten._values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_values : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSparseResizeAndClear_Op : Torch_Op<"aten.sparse_resize_and_clear_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sparse_resize_and_clear_ : (Tensor, int[], int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    Torch_IntType:$sparse_dim,
    Torch_IntType:$dense_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $sparse_dim `,` $dense_dim attr-dict `:` type($self) `,` type($size) `,` type($sparse_dim) `,` type($dense_dim) `->` type($result)";
}

def Torch_AtenHspmmOutOp : Torch_Op<"aten.hspmm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hspmm.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$mat1 `,` $mat2 `,` $out attr-dict `:` type($mat1) `,` type($mat2) `,` type($out) `->` type($result)";
}

def Torch_Aten_IndicesOp : Torch_Op<"aten._indices", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_indices : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenResizeAsSparse_Op : Torch_Op<"aten.resize_as_sparse_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::resize_as_sparse_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$the_template
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $the_template attr-dict `:` type($self) `,` type($the_template) `->` type($result)";
}

def Torch_Aten_AmpUpdateScale_Op : Torch_Op<"aten._amp_update_scale_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_amp_update_scale_ : (Tensor, Tensor, Tensor, float, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$growth_tracker,
    AnyTorchTensorType:$found_inf,
    Torch_FloatType:$scale_growth_factor,
    Torch_FloatType:$scale_backoff_factor,
    Torch_IntType:$growth_interval
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $growth_tracker `,` $found_inf `,` $scale_growth_factor `,` $scale_backoff_factor `,` $growth_interval attr-dict `:` type($self) `,` type($growth_tracker) `,` type($found_inf) `,` type($scale_growth_factor) `,` type($scale_backoff_factor) `,` type($growth_interval) `->` type($result)";
}

def Torch_Aten_Coalesced_Op : Torch_Op<"aten._coalesced_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_coalesced_ : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$coalesced
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $coalesced attr-dict `:` type($self) `,` type($coalesced) `->` type($result)";
}

def Torch_Aten_MkldnnTranspose_Op : Torch_Op<"aten._mkldnn_transpose_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_mkldnn_transpose_ : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim0,
    Torch_IntType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_AtenBatchNormElemtOutOp : Torch_Op<"aten.batch_norm_elemt.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::batch_norm_elemt.out : (Tensor, Tensor?, Tensor?, Tensor, Tensor, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$invstd,
    Torch_FloatType:$eps,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $mean `,` $invstd `,` $eps `,` $out attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($mean) `,` type($invstd) `,` type($eps) `,` type($out) `->` type($result)";
}

def Torch_AtenBatchNormElemtOp : Torch_Op<"aten.batch_norm_elemt", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_elemt : (Tensor, Tensor?, Tensor?, Tensor, Tensor, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$invstd,
    Torch_FloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $mean `,` $invstd `,` $eps attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($mean) `,` type($invstd) `,` type($eps) `->` type($result)";
}

def Torch_Aten_ConvDepthwise2dOutOp : Torch_Op<"aten._conv_depthwise2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_conv_depthwise2d.out : (Tensor, Tensor, int[], Tensor?, int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $dilation `,` $out attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($out) `->` type($result)";
}

def Torch_Aten_ConvDepthwise2dOp : Torch_Op<"aten._conv_depthwise2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_conv_depthwise2d : (Tensor, Tensor, int[], Tensor?, int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $dilation attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `->` type($result)";
}

def Torch_AtenSparseResize_Op : Torch_Op<"aten.sparse_resize_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sparse_resize_ : (Tensor, int[], int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    Torch_IntType:$sparse_dim,
    Torch_IntType:$dense_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $sparse_dim `,` $dense_dim attr-dict `:` type($self) `,` type($size) `,` type($sparse_dim) `,` type($dense_dim) `->` type($result)";
}

def Torch_Aten_TestAmbiguousDefaultsAOp : Torch_Op<"aten._test_ambiguous_defaults.a", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_ambiguous_defaults.a : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$dummy,
    Torch_IntType:$a,
    Torch_IntType:$b
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$dummy `,` $a `,` $b attr-dict `:` type($dummy) `,` type($a) `,` type($b) `->` type($result)";
}

def Torch_Aten_TestAmbiguousDefaultsBOp : Torch_Op<"aten._test_ambiguous_defaults.b", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_ambiguous_defaults.b : (Tensor, int, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$dummy,
    Torch_IntType:$a,
    Torch_StringType:$b
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$dummy `,` $a `,` $b attr-dict `:` type($dummy) `,` type($a) `,` type($b) `->` type($result)";
}

def Torch_Aten_TestStringDefaultOp : Torch_Op<"aten._test_string_default", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_string_default : (Tensor, str, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$dummy,
    Torch_StringType:$a,
    Torch_StringType:$b
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$dummy `,` $a `,` $b attr-dict `:` type($dummy) `,` type($a) `,` type($b) `->` type($result)";
}

def Torch_Aten_TestSerializationSubcmulOp : Torch_Op<"aten._test_serialization_subcmul", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_serialization_subcmul : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenLinalgMatrixPowerOutOp : Torch_Op<"aten.linalg_matrix_power.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_power.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $out attr-dict `:` type($self) `,` type($n) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgNormOutOp : Torch_Op<"aten.linalg_norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_norm.out : (Tensor, Scalar?, int[]?, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$ord,
    TorchOptionalIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgNormOrdStrOutOp : Torch_Op<"aten.linalg_norm.ord_str_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_norm.ord_str_out : (Tensor, str, int[]?, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$ord,
    TorchOptionalIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenGerOutOp : Torch_Op<"aten.ger.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ger.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec2,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec2 `,` $out attr-dict `:` type($self) `,` type($vec2) `,` type($out) `->` type($result)";
}

def Torch_AtenOuterOutOp : Torch_Op<"aten.outer.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::outer.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec2,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec2 `,` $out attr-dict `:` type($self) `,` type($vec2) `,` type($out) `->` type($result)";
}

def Torch_AtenInnerOutOp : Torch_Op<"aten.inner.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::inner.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatmulOutOp : Torch_Op<"aten.linalg_matmul.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matmul.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgDetOutOp : Torch_Op<"aten.linalg_det.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_det.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenFftIhfftnOutOp : Torch_Op<"aten.fft_ihfftn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_ihfftn.out : (Tensor, int[]?, int[]?, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenFftHfftnOutOp : Torch_Op<"aten.fft_hfftn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_hfftn.out : (Tensor, int[]?, int[]?, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenFftIhfft2OutOp : Torch_Op<"aten.fft_ihfft2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_ihfft2.out : (Tensor, int[]?, int[], str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenFftHfft2OutOp : Torch_Op<"aten.fft_hfft2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_hfft2.out : (Tensor, int[]?, int[], str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialMultigammalnOutOp : Torch_Op<"aten.special_multigammaln.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_multigammaln.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$p,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $out attr-dict `:` type($self) `,` type($p) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialGammainccOutOp : Torch_Op<"aten.special_gammaincc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_gammaincc.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialGammaincOutOp : Torch_Op<"aten.special_gammainc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_gammainc.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialLog1pOutOp : Torch_Op<"aten.special_log1p.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_log1p.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialRoundOutOp : Torch_Op<"aten.special_round.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_round.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialSincOutOp : Torch_Op<"aten.special_sinc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_sinc.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialExpitOutOp : Torch_Op<"aten.special_expit.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_expit.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialLogsumexpOutOp : Torch_Op<"aten.special_logsumexp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_logsumexp.out : (Tensor, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialPolygammaOutOp : Torch_Op<"aten.special_polygamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_polygamma.out : (int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $self `,` $out attr-dict `:` type($n) `,` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialLogitOutOp : Torch_Op<"aten.special_logit.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_logit.out : (Tensor, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $eps `,` $out attr-dict `:` type($self) `,` type($eps) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialI0OutOp : Torch_Op<"aten.special_i0.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_i0.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialXlogyOutOp : Torch_Op<"aten.special_xlogy.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_xlogy.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialXlogySelfScalarOutOp : Torch_Op<"aten.special_xlogy.self_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_xlogy.self_scalar_out : (Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialXlogyOtherScalarOutOp : Torch_Op<"aten.special_xlogy.other_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_xlogy.other_scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialNdtrOutOp : Torch_Op<"aten.special_ndtr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_ndtr.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialErfinvOutOp : Torch_Op<"aten.special_erfinv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_erfinv.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialErfcOutOp : Torch_Op<"aten.special_erfc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_erfc.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialErfOutOp : Torch_Op<"aten.special_erf.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_erf.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialGammalnOutOp : Torch_Op<"aten.special_gammaln.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_gammaln.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialDigammaOutOp : Torch_Op<"aten.special_digamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_digamma.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialPsiOutOp : Torch_Op<"aten.special_psi.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_psi.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialExp2OutOp : Torch_Op<"aten.special_exp2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_exp2.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialExpm1OutOp : Torch_Op<"aten.special_expm1.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_expm1.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenColumnStackOutOp : Torch_Op<"aten.column_stack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::column_stack.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $out attr-dict `:` type($tensors) `,` type($out) `->` type($result)";
}

def Torch_AtenSlowConv3dOp : Torch_Op<"aten.slow_conv3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv3d : (Tensor, Tensor, int[], Tensor?, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `->` type($result)";
}

def Torch_AtenSlowConv3dOutOp : Torch_Op<"aten.slow_conv3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv3d.out : (Tensor, Tensor, int[], Tensor?, int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $out attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_AtenThnnConv2dOp : Torch_Op<"aten.thnn_conv2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::thnn_conv2d : (Tensor, Tensor, int[], Tensor?, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `->` type($result)";
}

def Torch_AtenThnnConv2dOutOp : Torch_Op<"aten.thnn_conv2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::thnn_conv2d.out : (Tensor, Tensor, int[], Tensor?, int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $out attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_AtenFloatPower_TensorOp : Torch_Op<"aten.float_power_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::float_power_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenFloatPower_ScalarOp : Torch_Op<"aten.float_power_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::float_power_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenFloatPowerTensorTensorOutOp : Torch_Op<"aten.float_power.Tensor_Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::float_power.Tensor_Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$exponent,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent `,` $out attr-dict `:` type($self) `,` type($exponent) `,` type($out) `->` type($result)";
}

def Torch_AtenFloatPowerScalarOutOp : Torch_Op<"aten.float_power.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::float_power.Scalar_out : (Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$exponent,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent `,` $out attr-dict `:` type($self) `,` type($exponent) `,` type($out) `->` type($result)";
}

def Torch_AtenFloatPowerTensorScalarOutOp : Torch_Op<"aten.float_power.Tensor_Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::float_power.Tensor_Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$exponent,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent `,` $out attr-dict `:` type($self) `,` type($exponent) `,` type($out) `->` type($result)";
}

def Torch_AtenMsortOutOp : Torch_Op<"aten.msort.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::msort.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSwapdims_Op : Torch_Op<"aten.swapdims_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::swapdims_ : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim0,
    Torch_IntType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_AtenSwapaxes_Op : Torch_Op<"aten.swapaxes_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::swapaxes_ : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$axis0,
    Torch_IntType:$axis1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $axis0 `,` $axis1 attr-dict `:` type($self) `,` type($axis0) `,` type($axis1) `->` type($result)";
}

def Torch_Aten_GatherSparseBackwardOp : Torch_Op<"aten._gather_sparse_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_gather_sparse_backward : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $grad attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($grad) `->` type($result)";
}

def Torch_AtenGatherBackwardOp : Torch_Op<"aten.gather_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::gather_backward : (Tensor, Tensor, int, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    Torch_BoolType:$sparse_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self `,` $dim `,` $index `,` $sparse_grad attr-dict `:` type($grad) `,` type($self) `,` type($dim) `,` type($index) `,` type($sparse_grad) `->` type($result)";
}

def Torch_AtenMaskedSelectBackwardOp : Torch_Op<"aten.masked_select_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::masked_select_backward : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$mask
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input `,` $mask attr-dict `:` type($grad) `,` type($input) `,` type($mask) `->` type($result)";
}

def Torch_AtenIndexSelectBackwardOp : Torch_Op<"aten.index_select_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::index_select_backward : (Tensor, int[], int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    TorchIntListType:$self_sizes,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self_sizes `,` $dim `,` $index attr-dict `:` type($grad) `,` type($self_sizes) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenTakeAlongDimOutOp : Torch_Op<"aten.take_along_dim.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::take_along_dim.out : (Tensor, Tensor, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchOptionalIntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $dim `,` $out attr-dict `:` type($self) `,` type($indices) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenLess_ScalarOp : Torch_Op<"aten.less_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLess_TensorOp : Torch_Op<"aten.less_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLessScalarOutOp : Torch_Op<"aten.less.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLessTensorOutOp : Torch_Op<"aten.less.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGreater_ScalarOp : Torch_Op<"aten.greater_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreater_TensorOp : Torch_Op<"aten.greater_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterScalarOutOp : Torch_Op<"aten.greater.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGreaterTensorOutOp : Torch_Op<"aten.greater.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLessEqual_ScalarOp : Torch_Op<"aten.less_equal_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less_equal_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLessEqual_TensorOp : Torch_Op<"aten.less_equal_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less_equal_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLessEqualScalarOutOp : Torch_Op<"aten.less_equal.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less_equal.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLessEqualTensorOutOp : Torch_Op<"aten.less_equal.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::less_equal.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGreaterEqual_ScalarOp : Torch_Op<"aten.greater_equal_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater_equal_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterEqual_TensorOp : Torch_Op<"aten.greater_equal_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater_equal_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenGreaterEqualScalarOutOp : Torch_Op<"aten.greater_equal.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater_equal.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGreaterEqualTensorOutOp : Torch_Op<"aten.greater_equal.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::greater_equal.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenNotEqual_ScalarOp : Torch_Op<"aten.not_equal_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::not_equal_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNotEqual_TensorOp : Torch_Op<"aten.not_equal_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::not_equal_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNotEqualScalarOutOp : Torch_Op<"aten.not_equal.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::not_equal.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenNotEqualTensorOutOp : Torch_Op<"aten.not_equal.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::not_equal.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenDiagBackwardOp : Torch_Op<"aten.diag_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diag_backward : (Tensor, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    TorchIntListType:$input_sizes,
    Torch_IntType:$diagonal
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input_sizes `,` $diagonal attr-dict `:` type($grad) `,` type($input_sizes) `,` type($diagonal) `->` type($result)";
}

def Torch_Aten__Ixor__ScalarOp : Torch_Op<"aten.__ixor__.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__ixor__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Ixor__TensorOp : Torch_Op<"aten.__ixor__.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__ixor__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Xor__ScalarOp : Torch_Op<"aten.__xor__.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__xor__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Xor__TensorOp : Torch_Op<"aten.__xor__.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__xor__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Ior__ScalarOp : Torch_Op<"aten.__ior__.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__ior__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Ior__TensorOp : Torch_Op<"aten.__ior__.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__ior__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Or__ScalarOp : Torch_Op<"aten.__or__.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__or__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Or__TensorOp : Torch_Op<"aten.__or__.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__or__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Iand__ScalarOp : Torch_Op<"aten.__iand__.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__iand__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Iand__TensorOp : Torch_Op<"aten.__iand__.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__iand__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__And__ScalarOp : Torch_Op<"aten.__and__.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__and__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten_PadPackedSequenceOp : Torch_Op<"aten._pad_packed_sequence", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_pad_packed_sequence : (Tensor, Tensor, bool, Scalar, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$data,
    AnyTorchTensorType:$batch_sizes,
    Torch_BoolType:$batch_first,
    AnyTorchScalarType:$padding_value,
    Torch_IntType:$total_length
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$data `,` $batch_sizes `,` $batch_first `,` $padding_value `,` $total_length attr-dict `:` type($data) `,` type($batch_sizes) `,` type($batch_first) `,` type($padding_value) `,` type($total_length) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_PackPaddedSequenceBackwardOp : Torch_Op<"aten._pack_padded_sequence_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_pack_padded_sequence_backward : (Tensor, int[], Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    TorchIntListType:$input_size,
    AnyTorchTensorType:$batch_sizes,
    Torch_BoolType:$batch_first
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input_size `,` $batch_sizes `,` $batch_first attr-dict `:` type($grad) `,` type($input_size) `,` type($batch_sizes) `,` type($batch_first) `->` type($result)";
}

def Torch_Aten_ThnnDifferentiableGruCellBackwardOp : Torch_Op<"aten._thnn_differentiable_gru_cell_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_thnn_differentiable_gru_cell_backward : (Tensor, Tensor, Tensor, Tensor, Tensor?, Tensor?) -> (Tensor, Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_hy,
    AnyTorchTensorType:$input_gates,
    AnyTorchTensorType:$hidden_gates,
    AnyTorchTensorType:$hx,
    AnyTorchOptionalTensorType:$input_bias,
    AnyTorchOptionalTensorType:$hidden_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    AnyTorchTensorType:$result4
  );
  let assemblyFormat = "$grad_hy `,` $input_gates `,` $hidden_gates `,` $hx `,` $input_bias `,` $hidden_bias attr-dict `:` type($grad_hy) `,` type($input_gates) `,` type($hidden_gates) `,` type($hx) `,` type($input_bias) `,` type($hidden_bias) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_Aten_ThnnDifferentiableLstmCellBackwardOp : Torch_Op<"aten._thnn_differentiable_lstm_cell_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_thnn_differentiable_lstm_cell_backward : (Tensor?, Tensor?, Tensor, Tensor, Tensor?, Tensor?, Tensor, Tensor) -> (Tensor, Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchOptionalTensorType:$grad_hy,
    AnyTorchOptionalTensorType:$grad_cy,
    AnyTorchTensorType:$input_gates,
    AnyTorchTensorType:$hidden_gates,
    AnyTorchOptionalTensorType:$input_bias,
    AnyTorchOptionalTensorType:$hidden_bias,
    AnyTorchTensorType:$cx,
    AnyTorchTensorType:$cy
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    AnyTorchTensorType:$result4
  );
  let assemblyFormat = "$grad_hy `,` $grad_cy `,` $input_gates `,` $hidden_gates `,` $input_bias `,` $hidden_bias `,` $cx `,` $cy attr-dict `:` type($grad_hy) `,` type($grad_cy) `,` type($input_gates) `,` type($hidden_gates) `,` type($input_bias) `,` type($hidden_bias) `,` type($cx) `,` type($cy) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_AtenPromoteTypesOp : Torch_Op<"aten.promote_types", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::promote_types : (int, int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$type1,
    Torch_IntType:$type2
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$type1 `,` $type2 attr-dict `:` type($type1) `,` type($type2) `->` type($result)";
}

def Torch_AtenCanCastOp : Torch_Op<"aten.can_cast", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::can_cast : (int, int) -> (bool)`";
  let arguments = (ins
    Torch_IntType:$from,
    Torch_IntType:$to
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$from `,` $to attr-dict `:` type($from) `,` type($to) `->` type($result)";
}

def Torch_Aten_AutocastToFullPrecisionOp : Torch_Op<"aten._autocast_to_full_precision", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_autocast_to_full_precision : (Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$cuda_enabled,
    Torch_BoolType:$cpu_enabled
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $cuda_enabled `,` $cpu_enabled attr-dict `:` type($self) `,` type($cuda_enabled) `,` type($cpu_enabled) `->` type($result)";
}

def Torch_Aten_AutocastToReducedPrecisionOp : Torch_Op<"aten._autocast_to_reduced_precision", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_autocast_to_reduced_precision : (Tensor, bool, bool, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$cuda_enabled,
    Torch_BoolType:$cpu_enabled,
    Torch_IntType:$cuda_dtype,
    Torch_IntType:$cpu_dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $cuda_enabled `,` $cpu_enabled `,` $cuda_dtype `,` $cpu_dtype attr-dict `:` type($self) `,` type($cuda_enabled) `,` type($cpu_enabled) `,` type($cuda_dtype) `,` type($cpu_dtype) `->` type($result)";
}

def Torch_Aten_SaturateWeightToFp16Op : Torch_Op<"aten._saturate_weight_to_fp16", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_saturate_weight_to_fp16 : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$weight attr-dict `:` type($weight) `->` type($result)";
}

def Torch_Aten_ChooseQparamsPerTensorOp : Torch_Op<"aten._choose_qparams_per_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_choose_qparams_per_tensor : (Tensor, bool) -> (float, int)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$reduce_range
  );
  let results = (outs
    Torch_FloatType:$result0,
    Torch_IntType:$result1
  );
  let assemblyFormat = "$self `,` $reduce_range attr-dict `:` type($self) `,` type($reduce_range) `->` type($result0) `,` type($result1)";
}

def Torch_AtenFusedMovingAvgObsFakeQuantOp : Torch_Op<"aten.fused_moving_avg_obs_fake_quant", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fused_moving_avg_obs_fake_quant : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, float, int, int, int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$observer_on,
    AnyTorchTensorType:$fake_quant_on,
    AnyTorchTensorType:$running_min,
    AnyTorchTensorType:$running_max,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_FloatType:$averaging_const,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max,
    Torch_IntType:$ch_axis,
    Torch_BoolType:$per_row_fake_quant,
    Torch_BoolType:$symmetric_quant
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $observer_on `,` $fake_quant_on `,` $running_min `,` $running_max `,` $scale `,` $zero_point `,` $averaging_const `,` $quant_min `,` $quant_max `,` $ch_axis `,` $per_row_fake_quant `,` $symmetric_quant attr-dict `:` type($self) `,` type($observer_on) `,` type($fake_quant_on) `,` type($running_min) `,` type($running_max) `,` type($scale) `,` type($zero_point) `,` type($averaging_const) `,` type($quant_min) `,` type($quant_max) `,` type($ch_axis) `,` type($per_row_fake_quant) `,` type($symmetric_quant) `->` type($result)";
}

def Torch_Aten_FakeQuantizeLearnablePerChannelAffineBackwardOp : Torch_Op<"aten._fake_quantize_learnable_per_channel_affine_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fake_quantize_learnable_per_channel_affine_backward : (Tensor, Tensor, Tensor, Tensor, int, int, int, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$axis,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max,
    Torch_FloatType:$grad_factor
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad `,` $self `,` $scale `,` $zero_point `,` $axis `,` $quant_min `,` $quant_max `,` $grad_factor attr-dict `:` type($grad) `,` type($self) `,` type($scale) `,` type($zero_point) `,` type($axis) `,` type($quant_min) `,` type($quant_max) `,` type($grad_factor) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenFakeQuantizePerChannelAffineCachemaskBackwardOp : Torch_Op<"aten.fake_quantize_per_channel_affine_cachemask_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_channel_affine_cachemask_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$mask
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $mask attr-dict `:` type($grad) `,` type($mask) `->` type($result)";
}

def Torch_Aten_FakeQuantizeLearnablePerTensorAffineBackwardOp : Torch_Op<"aten._fake_quantize_learnable_per_tensor_affine_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fake_quantize_learnable_per_tensor_affine_backward : (Tensor, Tensor, Tensor, Tensor, int, int, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max,
    Torch_FloatType:$grad_factor
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad `,` $self `,` $scale `,` $zero_point `,` $quant_min `,` $quant_max `,` $grad_factor attr-dict `:` type($grad) `,` type($self) `,` type($scale) `,` type($zero_point) `,` type($quant_min) `,` type($quant_max) `,` type($grad_factor) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenFakeQuantizePerTensorAffineCachemaskBackwardOp : Torch_Op<"aten.fake_quantize_per_tensor_affine_cachemask_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fake_quantize_per_tensor_affine_cachemask_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$mask
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $mask attr-dict `:` type($grad) `,` type($mask) `->` type($result)";
}

def Torch_AtenToMkldnnBackwardOp : Torch_Op<"aten.to_mkldnn_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::to_mkldnn_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input attr-dict `:` type($grad) `,` type($input) `->` type($result)";
}

def Torch_AtenToDenseBackwardOp : Torch_Op<"aten.to_dense_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::to_dense_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input attr-dict `:` type($grad) `,` type($input) `->` type($result)";
}

def Torch_Aten_ToCpuOp : Torch_Op<"aten._to_cpu", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_to_cpu : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ValidateSparseCsrTensorArgsOp : Torch_Op<"aten._validate_sparse_csr_tensor_args", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_validate_sparse_csr_tensor_args : (Tensor, Tensor, Tensor, int[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$crow_indices,
    AnyTorchTensorType:$col_indices,
    AnyTorchTensorType:$values,
    TorchIntListType:$size
  );
  let results = (outs
  );
  let assemblyFormat = "$crow_indices `,` $col_indices `,` $values `,` $size attr-dict `:` type($crow_indices) `,` type($col_indices) `,` type($values) `,` type($size)";
}

def Torch_Aten_ValidateSparseCooTensorArgsOp : Torch_Op<"aten._validate_sparse_coo_tensor_args", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_validate_sparse_coo_tensor_args : (Tensor, Tensor, int[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$values,
    TorchIntListType:$size
  );
  let results = (outs
  );
  let assemblyFormat = "$indices `,` $values `,` $size attr-dict `:` type($indices) `,` type($values) `,` type($size)";
}

def Torch_AtenSubtract_TensorOp : Torch_Op<"aten.subtract_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::subtract_.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSubtract_ScalarOp : Torch_Op<"aten.subtract_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::subtract_.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenSubtractOutOp : Torch_Op<"aten.subtract.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::subtract.out : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha `,` $out attr-dict `:` type($self) `,` type($other) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_Aten_WeightNormDifferentiableBackwardOp : Torch_Op<"aten._weight_norm_differentiable_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_weight_norm_differentiable_backward : (Tensor, Tensor, Tensor, Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_w,
    AnyTorchTensorType:$saved_v,
    AnyTorchTensorType:$saved_g,
    AnyTorchTensorType:$saved_norms,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_w `,` $saved_v `,` $saved_g `,` $saved_norms `,` $dim attr-dict `:` type($grad_w) `,` type($saved_v) `,` type($saved_g) `,` type($saved_norms) `,` type($dim) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_WeightNormOp : Torch_Op<"aten._weight_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_weight_norm : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$v,
    AnyTorchTensorType:$g,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$v `,` $g `,` $dim attr-dict `:` type($v) `,` type($g) `,` type($dim) `->` type($result)";
}

def Torch_Aten_HasCompatibleShallowCopyTypeOp : Torch_Op<"aten._has_compatible_shallow_copy_type", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_has_compatible_shallow_copy_type : (Tensor, Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$from
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $from attr-dict `:` type($self) `,` type($from) `->` type($result)";
}

def Torch_AtenFix_Op : Torch_Op<"aten.fix_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fix_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFixOutOp : Torch_Op<"aten.fix.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fix.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenDstackOutOp : Torch_Op<"aten.dstack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::dstack.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $out attr-dict `:` type($tensors) `,` type($out) `->` type($result)";
}

def Torch_AtenVstackOutOp : Torch_Op<"aten.vstack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::vstack.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $out attr-dict `:` type($tensors) `,` type($out) `->` type($result)";
}

def Torch_AtenHstackOutOp : Torch_Op<"aten.hstack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hstack.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $out attr-dict `:` type($tensors) `,` type($out) `->` type($result)";
}

def Torch_AtenSelu_Op : Torch_Op<"aten.selu_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::selu_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenInfinitelyDifferentiableGeluBackwardOp : Torch_Op<"aten.infinitely_differentiable_gelu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::infinitely_differentiable_gelu_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self attr-dict `:` type($grad) `,` type($self) `->` type($result)";
}

def Torch_AtenRelu6_Op : Torch_Op<"aten.relu6_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::relu6_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNegative_Op : Torch_Op<"aten.negative_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::negative_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenNegativeOutOp : Torch_Op<"aten.negative.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::negative.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_NnpackSpatialConvolutionBackwardWeightOp : Torch_Op<"aten._nnpack_spatial_convolution_backward_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_nnpack_spatial_convolution_backward_weight : (Tensor, int[], Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    TorchIntListType:$weightsize,
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weightsize `,` $grad_output `,` $padding attr-dict `:` type($input) `,` type($weightsize) `,` type($grad_output) `,` type($padding) `->` type($result)";
}

def Torch_Aten_NnpackSpatialConvolutionBackwardInputOp : Torch_Op<"aten._nnpack_spatial_convolution_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_nnpack_spatial_convolution_backward_input : (Tensor, Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $grad_output `,` $weight `,` $padding attr-dict `:` type($input) `,` type($grad_output) `,` type($weight) `,` type($padding) `->` type($result)";
}

def Torch_Aten_NnpackSpatialConvolutionBackwardOp : Torch_Op<"aten._nnpack_spatial_convolution_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_nnpack_spatial_convolution_backward : (Tensor, Tensor, Tensor, int[], bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $grad_output `,` $weight `,` $padding `,` $output_mask attr-dict `:` type($input) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_NnpackAvailableOp : Torch_Op<"aten._nnpack_available", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_nnpack_available : () -> (bool)`";
  let arguments = (ins
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = " attr-dict `:` type($result)";
}

def Torch_AtenIsVulkanAvailableOp : Torch_Op<"aten.is_vulkan_available", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_vulkan_available : () -> (bool)`";
  let arguments = (ins
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = " attr-dict `:` type($result)";
}

def Torch_AtenMultiply_TensorOp : Torch_Op<"aten.multiply_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multiply_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMultiply_ScalarOp : Torch_Op<"aten.multiply_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multiply_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMultiplyOutOp : Torch_Op<"aten.multiply.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multiply.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_SparseMmOp : Torch_Op<"aten._sparse_mm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_mm : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$sparse,
    AnyTorchTensorType:$dense
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sparse `,` $dense attr-dict `:` type($sparse) `,` type($dense) `->` type($result)";
}

def Torch_AtenMkldnnConvolutionBackwardWeightsOp : Torch_Op<"aten.mkldnn_convolution_backward_weights", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_convolution_backward_weights : (int[], Tensor, Tensor, int[], int[], int[], int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    TorchIntListType:$weight_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$bias_defined
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$weight_size `,` $grad_output `,` $self `,` $padding `,` $stride `,` $dilation `,` $groups `,` $bias_defined attr-dict `:` type($weight_size) `,` type($grad_output) `,` type($self) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($bias_defined) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMkldnnConvolutionBackwardInputOp : Torch_Op<"aten.mkldnn_convolution_backward_input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_convolution_backward_input : (int[], Tensor, Tensor, int[], int[], int[], int, bool) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$self_size,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$bias_defined
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self_size `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $bias_defined attr-dict `:` type($self_size) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($bias_defined) `->` type($result)";
}

def Torch_AtenNanmeanOutOp : Torch_Op<"aten.nanmean.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanmean.out : (Tensor, int[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenValueSelectingReductionBackwardOp : Torch_Op<"aten.value_selecting_reduction_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::value_selecting_reduction_backward : (Tensor, int, Tensor, int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    Torch_IntType:$dim,
    AnyTorchTensorType:$indices,
    TorchIntListType:$sizes,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $dim `,` $indices `,` $sizes `,` $keepdim attr-dict `:` type($grad) `,` type($dim) `,` type($indices) `,` type($sizes) `,` type($keepdim) `->` type($result)";
}

def Torch_AtenMatrixExpBackwardOp : Torch_Op<"aten.matrix_exp_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::matrix_exp_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $grad attr-dict `:` type($self) `,` type($grad) `->` type($result)";
}

def Torch_AtenMatrixPowerOutOp : Torch_Op<"aten.matrix_power.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::matrix_power.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $out attr-dict `:` type($self) `,` type($n) `,` type($out) `->` type($result)";
}

def Torch_AtenLdexp_Op : Torch_Op<"aten.ldexp_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ldexp_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLdexpOutOp : Torch_Op<"aten.ldexp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ldexp.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenKronOutOp : Torch_Op<"aten.kron.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::kron.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenIsNegOp : Torch_Op<"aten.is_neg", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_neg : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsConjOp : Torch_Op<"aten.is_conj", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_conj : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsDistributedOp : Torch_Op<"aten.is_distributed", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_distributed : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_CufftClearPlanCacheOp : Torch_Op<"aten._cufft_clear_plan_cache", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cufft_clear_plan_cache : (int) -> ()`";
  let arguments = (ins
    Torch_IntType:$device_index
  );
  let results = (outs
  );
  let assemblyFormat = "$device_index attr-dict `:` type($device_index)";
}

def Torch_Aten_CufftSetPlanCacheMaxSizeOp : Torch_Op<"aten._cufft_set_plan_cache_max_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cufft_set_plan_cache_max_size : (int, int) -> ()`";
  let arguments = (ins
    Torch_IntType:$device_index,
    Torch_IntType:$max_size
  );
  let results = (outs
  );
  let assemblyFormat = "$device_index `,` $max_size attr-dict `:` type($device_index) `,` type($max_size)";
}

def Torch_Aten_CufftGetPlanCacheMaxSizeOp : Torch_Op<"aten._cufft_get_plan_cache_max_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cufft_get_plan_cache_max_size : (int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$device_index
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$device_index attr-dict `:` type($device_index) `->` type($result)";
}

def Torch_Aten_CufftGetPlanCacheSizeOp : Torch_Op<"aten._cufft_get_plan_cache_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cufft_get_plan_cache_size : (int) -> (int)`";
  let arguments = (ins
    Torch_IntType:$device_index
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$device_index attr-dict `:` type($device_index) `->` type($result)";
}

def Torch_Aten_GridSampler2dCpuFallbackBackwardOp : Torch_Op<"aten._grid_sampler_2d_cpu_fallback_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_grid_sampler_2d_cpu_fallback_backward : (Tensor, Tensor, Tensor, int, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_output `,` $input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners attr-dict `:` type($grad_output) `,` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_EmbeddingBagSparseBackwardOp : Torch_Op<"aten._embedding_bag_sparse_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_embedding_bag_sparse_backward : (Tensor, Tensor, Tensor, Tensor, Tensor, int, bool, int, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    AnyTorchTensorType:$offset2bag,
    AnyTorchTensorType:$bag_size,
    Torch_IntType:$num_weights,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_IntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $indices `,` $offsets `,` $offset2bag `,` $bag_size `,` $num_weights `,` $scale_grad_by_freq `,` $mode `,` $per_sample_weights `,` $padding_idx attr-dict `:` type($grad) `,` type($indices) `,` type($offsets) `,` type($offset2bag) `,` type($bag_size) `,` type($num_weights) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($per_sample_weights) `,` type($padding_idx) `->` type($result)";
}

def Torch_Aten_EmbeddingBagBackwardOp : Torch_Op<"aten._embedding_bag_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_embedding_bag_backward : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, int, bool, int, bool, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    AnyTorchTensorType:$offset2bag,
    AnyTorchTensorType:$bag_size,
    AnyTorchTensorType:$maximum_indices,
    Torch_IntType:$num_weights,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    Torch_BoolType:$sparse,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_IntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $indices `,` $offsets `,` $offset2bag `,` $bag_size `,` $maximum_indices `,` $num_weights `,` $scale_grad_by_freq `,` $mode `,` $sparse `,` $per_sample_weights `,` $padding_idx attr-dict `:` type($grad) `,` type($indices) `,` type($offsets) `,` type($offset2bag) `,` type($bag_size) `,` type($maximum_indices) `,` type($num_weights) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($sparse) `,` type($per_sample_weights) `,` type($padding_idx) `->` type($result)";
}

def Torch_AtenRowStackOutOp : Torch_Op<"aten.row_stack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::row_stack.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $out attr-dict `:` type($tensors) `,` type($out) `->` type($result)";
}

def Torch_Aten_RowwisePruneOp : Torch_Op<"aten._rowwise_prune", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_rowwise_prune : (Tensor, Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$mask,
    Torch_IntType:$compressed_indices_dtype
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$weight `,` $mask `,` $compressed_indices_dtype attr-dict `:` type($weight) `,` type($mask) `,` type($compressed_indices_dtype) `->` type($result0) `,` type($result1)";
}

def Torch_AtenEmbeddingSparseBackwardOp : Torch_Op<"aten.embedding_sparse_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::embedding_sparse_backward : (Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$indices,
    Torch_IntType:$num_weights,
    Torch_IntType:$padding_idx,
    Torch_BoolType:$scale_grad_by_freq
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $indices `,` $num_weights `,` $padding_idx `,` $scale_grad_by_freq attr-dict `:` type($grad) `,` type($indices) `,` type($num_weights) `,` type($padding_idx) `,` type($scale_grad_by_freq) `->` type($result)";
}

def Torch_AtenEmbeddingBackwardOp : Torch_Op<"aten.embedding_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::embedding_backward : (Tensor, Tensor, int, int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$indices,
    Torch_IntType:$num_weights,
    Torch_IntType:$padding_idx,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_BoolType:$sparse
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $indices `,` $num_weights `,` $padding_idx `,` $scale_grad_by_freq `,` $sparse attr-dict `:` type($grad) `,` type($indices) `,` type($num_weights) `,` type($padding_idx) `,` type($scale_grad_by_freq) `,` type($sparse) `->` type($result)";
}

def Torch_AtenDivide_TensorOp : Torch_Op<"aten.divide_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::divide_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDivide_ScalarOp : Torch_Op<"aten.divide_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::divide_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDivide_TensorModeOp : Torch_Op<"aten.divide_.Tensor_mode", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::divide_.Tensor_mode : (Tensor, Tensor, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenDivide_ScalarModeOp : Torch_Op<"aten.divide_.Scalar_mode", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::divide_.Scalar_mode : (Tensor, Scalar, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenDivideOutOp : Torch_Op<"aten.divide.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::divide.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenDivideOutModeOp : Torch_Op<"aten.divide.out_mode", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::divide.out_mode : (Tensor, Tensor, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalStringType:$rounding_mode,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode `,` $out attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `,` type($out) `->` type($result)";
}

def Torch_AtenDiffOutOp : Torch_Op<"aten.diff.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::diff.out : (Tensor, int, int, Tensor?, Tensor?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n,
    Torch_IntType:$dim,
    AnyTorchOptionalTensorType:$prepend,
    AnyTorchOptionalTensorType:$append,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $prepend `,` $append `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($prepend) `,` type($append) `,` type($out) `->` type($result)";
}

def Torch_AtenFillDiagonal_Op : Torch_Op<"aten.fill_diagonal_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fill_diagonal_ : (Tensor, Scalar, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$fill_value,
    Torch_BoolType:$wrap
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $fill_value `,` $wrap attr-dict `:` type($self) `,` type($fill_value) `,` type($wrap) `->` type($result)";
}

def Torch_AtenCumprodBackwardOp : Torch_Op<"aten.cumprod_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cumprod_backward : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$input,
    Torch_IntType:$dim,
    AnyTorchTensorType:$output
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input `,` $dim `,` $output attr-dict `:` type($grad) `,` type($input) `,` type($dim) `,` type($output) `->` type($result)";
}

def Torch_AtenCummaxminBackwardOp : Torch_Op<"aten.cummaxmin_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cummaxmin_backward : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$indices,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $input `,` $indices `,` $dim attr-dict `:` type($grad) `,` type($input) `,` type($indices) `,` type($dim) `->` type($result)";
}

def Torch_AtenConvTbcBackwardOp : Torch_Op<"aten.conv_tbc_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_tbc_backward : (Tensor, Tensor, Tensor, Tensor, int) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$bias,
    Torch_IntType:$pad
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $input `,` $weight `,` $bias `,` $pad attr-dict `:` type($self) `,` type($input) `,` type($weight) `,` type($bias) `,` type($pad) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_ConvolutionDoubleBackwardOp : Torch_Op<"aten._convolution_double_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_convolution_double_backward : (Tensor?, Tensor?, Tensor?, Tensor, Tensor, Tensor, int[], int[], int[], bool, int[], int, bool, bool, bool, bool, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchOptionalTensorType:$ggI,
    AnyTorchOptionalTensorType:$ggW,
    AnyTorchOptionalTensorType:$ggb,
    AnyTorchTensorType:$gO,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$self,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$cudnn_enabled,
    Torch_BoolType:$allow_tf32,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$ggI `,` $ggW `,` $ggb `,` $gO `,` $weight `,` $self `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding `,` $groups `,` $benchmark `,` $deterministic `,` $cudnn_enabled `,` $allow_tf32 `,` $output_mask attr-dict `:` type($ggI) `,` type($ggW) `,` type($ggb) `,` type($gO) `,` type($weight) `,` type($self) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($cudnn_enabled) `,` type($allow_tf32) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_ConvolutionModeOp : Torch_Op<"aten._convolution_mode", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_convolution_mode : (Tensor, Tensor, Tensor?, int[], str, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    Torch_StringType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenCudnnIsAcceptableOp : Torch_Op<"aten.cudnn_is_acceptable", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_is_acceptable : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenClip_Op : Torch_Op<"aten.clip_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clip_ : (Tensor, Scalar?, Scalar?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$min,
    AnyTorchOptionalScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenClip_TensorOp : Torch_Op<"aten.clip_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clip_.Tensor : (Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$min,
    AnyTorchOptionalTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenClipOutOp : Torch_Op<"aten.clip.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clip.out : (Tensor, Scalar?, Scalar?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$min,
    AnyTorchOptionalScalarType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max `,` $out attr-dict `:` type($self) `,` type($min) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenClipTensorOutOp : Torch_Op<"aten.clip.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clip.Tensor_out : (Tensor, Tensor?, Tensor?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$min,
    AnyTorchOptionalTensorType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max `,` $out attr-dict `:` type($self) `,` type($min) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenConcatOutOp : Torch_Op<"aten.concat.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::concat.out : (Tensor[], int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenConcatNamesOutOp : Torch_Op<"aten.concat.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::concat.names_out : (Tensor[], str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_StringType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenBinaryCrossEntropyWithLogitsBackwardOp : Torch_Op<"aten.binary_cross_entropy_with_logits_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::binary_cross_entropy_with_logits_backward : (Tensor, Tensor, Tensor, Tensor?, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$pos_weight,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $pos_weight `,` $reduction attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($pos_weight) `,` type($reduction) `->` type($result)";
}

def Torch_Aten_BatchNormImplIndexBackwardOp : Torch_Op<"aten._batch_norm_impl_index_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_batch_norm_impl_index_backward : (int, Tensor, Tensor, Tensor?, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, bool[], Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    Torch_IntType:$impl_index,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grad_output,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    AnyTorchOptionalTensorType:$save_mean,
    AnyTorchOptionalTensorType:$save_var_transform,
    Torch_BoolType:$train,
    Torch_FloatType:$eps,
    TorchBoolListType:$output_mask,
    AnyTorchTensorType:$reservedSpace
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$impl_index `,` $input `,` $grad_output `,` $weight `,` $running_mean `,` $running_var `,` $save_mean `,` $save_var_transform `,` $train `,` $eps `,` $output_mask `,` $reservedSpace attr-dict `:` type($impl_index) `,` type($input) `,` type($grad_output) `,` type($weight) `,` type($running_mean) `,` type($running_var) `,` type($save_mean) `,` type($save_var_transform) `,` type($train) `,` type($eps) `,` type($output_mask) `,` type($reservedSpace) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_BatchNormImplIndexOp : Torch_Op<"aten._batch_norm_impl_index", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_batch_norm_impl_index : (Tensor, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, float, bool) -> (Tensor, Tensor, Tensor, Tensor, int)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$training,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps,
    Torch_BoolType:$cudnn_enabled
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3,
    Torch_IntType:$result4
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $training `,` $momentum `,` $eps `,` $cudnn_enabled attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($training) `,` type($momentum) `,` type($eps) `,` type($cudnn_enabled) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3) `,` type($result4)";
}

def Torch_AtenArctan_Op : Torch_Op<"aten.arctan_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arctan_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArctanOutOp : Torch_Op<"aten.arctan.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arctan.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenArcsin_Op : Torch_Op<"aten.arcsin_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arcsin_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArcsinOutOp : Torch_Op<"aten.arcsin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arcsin.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenArctanh_Op : Torch_Op<"aten.arctanh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arctanh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArctanhOutOp : Torch_Op<"aten.arctanh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arctanh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenArcsinh_Op : Torch_Op<"aten.arcsinh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arcsinh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArcsinhOutOp : Torch_Op<"aten.arcsinh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arcsinh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_DimArangeOp : Torch_Op<"aten._dim_arange", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_dim_arange : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$like,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$like `,` $dim attr-dict `:` type($like) `,` type($dim) `->` type($result)";
}

def Torch_AtenAllcloseOp : Torch_Op<"aten.allclose", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::allclose : (Tensor, Tensor, float, float, bool) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    Torch_FloatType:$rtol,
    Torch_FloatType:$atol,
    Torch_BoolType:$equal_nan
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rtol `,` $atol `,` $equal_nan attr-dict `:` type($self) `,` type($other) `,` type($rtol) `,` type($atol) `,` type($equal_nan) `->` type($result)";
}

def Torch_AtenAdaptiveAvgPool1dOp : Torch_Op<"aten.adaptive_avg_pool1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_avg_pool1d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result)";
}

def Torch_AtenArccos_Op : Torch_Op<"aten.arccos_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arccos_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArccosOutOp : Torch_Op<"aten.arccos.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arccos.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenFeatureAlphaDropout_Op : Torch_Op<"aten.feature_alpha_dropout_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::feature_alpha_dropout_ : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $train attr-dict `:` type($self) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenCoshOutOp : Torch_Op<"aten.cosh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cosh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenCosOutOp : Torch_Op<"aten.cos.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cos.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenConvolutionOp : Torch_Op<"aten.convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::convolution : (Tensor, Tensor, Tensor?, int[], int[], int[], bool, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `,` type($groups) `->` type($result)";
}

def Torch_AtenConvTranspose1dOp : Torch_Op<"aten.conv_transpose1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_transpose1d : (Tensor, Tensor, Tensor?, int[], int[], int[], int, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $groups `,` $dilation attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($groups) `,` type($dilation) `->` type($result)";
}

def Torch_AtenConv3dOp : Torch_Op<"aten.conv3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv3d : (Tensor, Tensor, Tensor?, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenConv3dPaddingOp : Torch_Op<"aten.conv3d.padding", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv3d.padding : (Tensor, Tensor, Tensor?, int[], str, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    Torch_StringType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenRetainGradOp : Torch_Op<"aten.retain_grad", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::retain_grad : (Tensor) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenConv1dOp : Torch_Op<"aten.conv1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv1d : (Tensor, Tensor, Tensor?, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_AtenConv1dPaddingOp : Torch_Op<"aten.conv1d.padding", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv1d.padding : (Tensor, Tensor, Tensor?, int[], str, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    Torch_StringType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_Aten_VersionOp : Torch_Op<"aten._version", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_version : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsLeafOp : Torch_Op<"aten.is_leaf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_leaf : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenPolarOutOp : Torch_Op<"aten.polar.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::polar.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$abs,
    AnyTorchTensorType:$angle,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$abs `,` $angle `,` $out attr-dict `:` type($abs) `,` type($angle) `,` type($out) `->` type($result)";
}

def Torch_Aten_BackwardOp : Torch_Op<"aten._backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_backward : (Tensor, Tensor[], Tensor?, bool?, bool) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorListType:$inputs,
    AnyTorchOptionalTensorType:$gradient,
    TorchOptionalBoolType:$retain_graph,
    Torch_BoolType:$create_graph
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $inputs `,` $gradient `,` $retain_graph `,` $create_graph attr-dict `:` type($self) `,` type($inputs) `,` type($gradient) `,` type($retain_graph) `,` type($create_graph)";
}

def Torch_AtenComplexOutOp : Torch_Op<"aten.complex.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::complex.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$real,
    AnyTorchTensorType:$imag,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$real `,` $imag `,` $out attr-dict `:` type($real) `,` type($imag) `,` type($out) `->` type($result)";
}

def Torch_AtenTrueDivide_ScalarOp : Torch_Op<"aten.true_divide_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::true_divide_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenTrueDivide_TensorOp : Torch_Op<"aten.true_divide_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::true_divide_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenTrueDivideOutOp : Torch_Op<"aten.true_divide.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::true_divide.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenTan_Op : Torch_Op<"aten.tan_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tan_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSquare_Op : Torch_Op<"aten.square_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::square_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenConjPhysical_Op : Torch_Op<"aten.conj_physical_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::conj_physical_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSinh_Op : Torch_Op<"aten.sinh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sinh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_ConjOp : Torch_Op<"aten._conj", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_conj : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSignbitOutOp : Torch_Op<"aten.signbit.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::signbit.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSign_Op : Torch_Op<"aten.sign_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sign_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRound_Op : Torch_Op<"aten.round_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::round_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenResizeAs_Op : Torch_Op<"aten.resize_as_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::resize_as_ : (Tensor, Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$the_template,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $the_template `,` $memory_format attr-dict `:` type($self) `,` type($the_template) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenRad2deg_Op : Torch_Op<"aten.rad2deg_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rad2deg_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenCholeskyInverseOutOp : Torch_Op<"aten.cholesky_inverse.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cholesky_inverse.out : (Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upper `,` $out attr-dict `:` type($self) `,` type($upper) `,` type($out) `->` type($result)";
}

def Torch_AtenRad2degOutOp : Torch_Op<"aten.rad2deg.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rad2deg.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_AdaptiveAvgPool2dBackwardOp : Torch_Op<"aten._adaptive_avg_pool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_adaptive_avg_pool2d_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_AtenPow_ScalarOp : Torch_Op<"aten.pow_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::pow_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenPow_TensorOp : Torch_Op<"aten.pow_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::pow_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent attr-dict `:` type($self) `,` type($exponent) `->` type($result)";
}

def Torch_AtenCholeskyOutOp : Torch_Op<"aten.cholesky.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cholesky.out : (Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upper `,` $out attr-dict `:` type($self) `,` type($upper) `,` type($out) `->` type($result)";
}

def Torch_AtenPolygammaOutOp : Torch_Op<"aten.polygamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::polygamma.out : (int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $self `,` $out attr-dict `:` type($n) `,` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLgamma_Op : Torch_Op<"aten._foreach_lgamma_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_lgamma_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenNextafter_Op : Torch_Op<"aten.nextafter_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nextafter_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNextafterOutOp : Torch_Op<"aten.nextafter.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nextafter.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachExpm1_Op : Torch_Op<"aten._foreach_expm1_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_expm1_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenMinDimMinOp : Torch_Op<"aten.min.dim_min", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::min.dim_min : (Tensor, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$min,
    AnyTorchTensorType:$min_indices
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $min `,` $min_indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($min) `,` type($min_indices) `->` type($values) `,` type($indices)";
}

def Torch_AtenMinNamesDimMinOp : Torch_Op<"aten.min.names_dim_min", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::min.names_dim_min : (Tensor, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$min,
    AnyTorchTensorType:$min_indices
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $min `,` $min_indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($min) `,` type($min_indices) `->` type($values) `,` type($indices)";
}

def Torch_AtenMinOutOp : Torch_Op<"aten.min.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::min.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseAnd_ScalarOp : Torch_Op<"aten.bitwise_and_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_and_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenNanmedianDimValuesOp : Torch_Op<"aten.nanmedian.dim_values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanmedian.dim_values : (Tensor, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenNanmedianNamesDimValuesOp : Torch_Op<"aten.nanmedian.names_dim_values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanmedian.names_dim_values : (Tensor, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenScatterAdd_Op : Torch_Op<"aten.scatter_add_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter_add_ : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `->` type($result)";
}

def Torch_AtenMedianDimValuesOp : Torch_Op<"aten.median.dim_values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::median.dim_values : (Tensor, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenMedianNamesDimValuesOp : Torch_Op<"aten.median.names_dim_values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::median.names_dim_values : (Tensor, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenScatter_SrcOp : Torch_Op<"aten.scatter_.src", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter_.src : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `->` type($result)";
}

def Torch_AtenScatter_ValueOp : Torch_Op<"aten.scatter_.value", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter_.value : (Tensor, int, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenScatter_ReduceOp : Torch_Op<"aten.scatter_.reduce", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter_.reduce : (Tensor, int, Tensor, Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src,
    Torch_StringType:$reduce
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src `,` $reduce attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `,` type($reduce) `->` type($result)";
}

def Torch_AtenScatter_ValueReduceOp : Torch_Op<"aten.scatter_.value_reduce", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter_.value_reduce : (Tensor, int, Tensor, Scalar, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value,
    Torch_StringType:$reduce
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value `,` $reduce attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `,` type($reduce) `->` type($result)";
}

def Torch_AtenMeanNamesOutOp : Torch_Op<"aten.mean.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mean.names_out : (Tensor, str[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenMeanOutOp : Torch_Op<"aten.mean.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mean.out : (Tensor, int[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenPut_Op : Torch_Op<"aten.put_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::put_ : (Tensor, Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source,
    Torch_BoolType:$accumulate
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $index `,` $source `,` $accumulate attr-dict `:` type($self) `,` type($index) `,` type($source) `,` type($accumulate) `->` type($result)";
}

def Torch_AtenMaxPool3dWithIndicesOp : Torch_Op<"aten.max_pool3d_with_indices", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool3d_with_indices : (Tensor, int[], int[], int[], int[], bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMaxPool3dWithIndicesOutOp : Torch_Op<"aten.max_pool3d_with_indices.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_pool3d_with_indices.out : (Tensor, int[], int[], int[], int[], bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode,
    AnyTorchTensorType:$out,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode `,` $out `,` $indices attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `,` type($out) `,` type($indices) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMaxPool2dWithIndicesOp : Torch_Op<"aten.max_pool2d_with_indices", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool2d_with_indices : (Tensor, int[], int[], int[], int[], bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMaxPool2dWithIndicesOutOp : Torch_Op<"aten.max_pool2d_with_indices.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_pool2d_with_indices.out : (Tensor, int[], int[], int[], int[], bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode,
    AnyTorchTensorType:$out,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode `,` $out `,` $indices attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `,` type($out) `,` type($indices) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_Unique2Op : Torch_Op<"aten._unique2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_unique2 : (Tensor, bool, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$sorted,
    Torch_BoolType:$return_inverse,
    Torch_BoolType:$return_counts
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $sorted `,` $return_inverse `,` $return_counts attr-dict `:` type($self) `,` type($sorted) `,` type($return_inverse) `,` type($return_counts) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenTrunc_Op : Torch_Op<"aten.trunc_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::trunc_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMaxPool1dWithIndicesOp : Torch_Op<"aten.max_pool1d_with_indices", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool1d_with_indices : (Tensor, int[], int[], int[], int[], bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMaxDimMaxOp : Torch_Op<"aten.max.dim_max", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max.dim_max : (Tensor, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$max,
    AnyTorchTensorType:$max_values
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $max `,` $max_values attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($max) `,` type($max_values) `->` type($values) `,` type($indices)";
}

def Torch_AtenMaxNamesDimMaxOp : Torch_Op<"aten.max.names_dim_max", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max.names_dim_max : (Tensor, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$max,
    AnyTorchTensorType:$max_values
  );
  let results = (outs
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $max `,` $max_values attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($max) `,` type($max_values) `->` type($values) `,` type($indices)";
}

def Torch_AtenMaxOutOp : Torch_Op<"aten.max.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenMaskedSelectOutOp : Torch_Op<"aten.masked_select.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::masked_select.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $out attr-dict `:` type($self) `,` type($mask) `,` type($out) `->` type($result)";
}

def Torch_AtenSinc_Op : Torch_Op<"aten.sinc_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sinc_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMaskedFill_TensorOp : Torch_Op<"aten.masked_fill_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::masked_fill_.Tensor : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $value attr-dict `:` type($self) `,` type($mask) `,` type($value) `->` type($result)";
}

def Torch_AtenMishBackwardOp : Torch_Op<"aten.mish_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mish_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_AtenLogsumexpNamesOutOp : Torch_Op<"aten.logsumexp.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logsumexp.names_out : (Tensor, str[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenLogsumexpOutOp : Torch_Op<"aten.logsumexp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logsumexp.out : (Tensor, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenLogicalNotOutOp : Torch_Op<"aten.logical_not.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_not.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLogOp : Torch_Op<"aten._foreach_log", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenLogaddexpOutOp : Torch_Op<"aten.logaddexp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logaddexp.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLog1p_Op : Torch_Op<"aten.log1p_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log1p_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenKthvalueDimnameOutOp : Torch_Op<"aten.kthvalue.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::kthvalue.dimname_out : (Tensor, int, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $k `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($k) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenKthvalueValuesOp : Torch_Op<"aten.kthvalue.values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::kthvalue.values : (Tensor, int, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $k `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($k) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_Aten_CummaxHelperOp : Torch_Op<"aten._cummax_helper", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_cummax_helper : (Tensor, Tensor, Tensor, int) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices,
    Torch_IntType:$dim
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $values `,` $indices `,` $dim attr-dict `:` type($self) `,` type($values) `,` type($indices) `,` type($dim)";
}

def Torch_AtenIsSignedOp : Torch_Op<"aten.is_signed", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_signed : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsNonzeroOp : Torch_Op<"aten.is_nonzero", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_nonzero : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsInferenceOp : Torch_Op<"aten.is_inference", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_inference : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsCoalescedOp : Torch_Op<"aten.is_coalesced", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_coalesced : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLogicalXorOutOp : Torch_Op<"aten.logical_xor.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_xor.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog10Op : Torch_Op<"aten._foreach_log10", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log10 : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenIgammac_Op : Torch_Op<"aten.igammac_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::igammac_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogicalOrOutOp : Torch_Op<"aten.logical_or.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_or.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog_Op : Torch_Op<"aten._foreach_log_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenIgammacOutOp : Torch_Op<"aten.igammac.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::igammac.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLogicalAndOutOp : Torch_Op<"aten.logical_and.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_and.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachFloor_Op : Torch_Op<"aten._foreach_floor_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_floor_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenIgamma_Op : Torch_Op<"aten.igamma_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::igamma_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIgammaOutOp : Torch_Op<"aten.igamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::igamma.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenI0_Op : Torch_Op<"aten.i0_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::i0_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenHypotOutOp : Torch_Op<"aten.hypot.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hypot.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenFrac_Op : Torch_Op<"aten.frac_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::frac_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenFloorDivide_ScalarOp : Torch_Op<"aten.floor_divide_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::floor_divide_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFloorDivide_TensorOp : Torch_Op<"aten.floor_divide_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::floor_divide_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenModeDimnameOutOp : Torch_Op<"aten.mode.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mode.dimname_out : (Tensor, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenModeValuesOp : Torch_Op<"aten.mode.values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mode.values : (Tensor, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_Aten_ForeachSub_ScalarOp : Torch_Op<"aten._foreach_sub_.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sub_.Scalar : (Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalar attr-dict `:` type($self) `,` type($scalar)";
}

def Torch_Aten_ForeachSub_ListOp : Torch_Op<"aten._foreach_sub_.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sub_.List : (Tensor[], Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha)";
}

def Torch_Aten_ForeachSub_ScalarListOp : Torch_Op<"aten._foreach_sub_.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sub_.ScalarList : (Tensor[], Scalar[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalars attr-dict `:` type($self) `,` type($scalars)";
}

def Torch_AtenErfcOutOp : Torch_Op<"aten.erfc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::erfc.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenErfOutOp : Torch_Op<"aten.erf.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::erf.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenEqualOp : Torch_Op<"aten.equal", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::equal : (Tensor, Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenDiv_TensorModeOp : Torch_Op<"aten.div_.Tensor_mode", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::div_.Tensor_mode : (Tensor, Tensor, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenDiv_ScalarModeOp : Torch_Op<"aten.div_.Scalar_mode", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::div_.Scalar_mode : (Tensor, Scalar, str?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    TorchOptionalStringType:$rounding_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `->` type($result)";
}

def Torch_AtenDeg2radOutOp : Torch_Op<"aten.deg2rad.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::deg2rad.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenClampMin_Op : Torch_Op<"aten.clamp_min_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_min_ : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min attr-dict `:` type($self) `,` type($min) `->` type($result)";
}

def Torch_AtenClampMin_TensorOp : Torch_Op<"aten.clamp_min_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_min_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$min
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min attr-dict `:` type($self) `,` type($min) `->` type($result)";
}

def Torch_AtenClampMax_Op : Torch_Op<"aten.clamp_max_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_max_ : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $max attr-dict `:` type($self) `,` type($max) `->` type($result)";
}

def Torch_AtenClampMax_TensorOp : Torch_Op<"aten.clamp_max_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_max_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $max attr-dict `:` type($self) `,` type($max) `->` type($result)";
}

def Torch_AtenClamp_TensorOp : Torch_Op<"aten.clamp_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_.Tensor : (Tensor, Tensor?, Tensor?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$min,
    AnyTorchOptionalTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max attr-dict `:` type($self) `,` type($min) `,` type($max) `->` type($result)";
}

def Torch_AtenBitwiseNotOutOp : Torch_Op<"aten.bitwise_not.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_not.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog1pOp : Torch_Op<"aten._foreach_log1p", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log1p : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenAtanh_Op : Torch_Op<"aten.atanh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::atanh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAtanhOutOp : Torch_Op<"aten.atanh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::atanh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAtan_Op : Torch_Op<"aten.atan_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::atan_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAsinh_Op : Torch_Op<"aten.asinh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::asinh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAsinhOutOp : Torch_Op<"aten.asinh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::asinh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAsin_Op : Torch_Op<"aten.asin_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::asin_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenArccosh_Op : Torch_Op<"aten.arccosh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arccosh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenVarNamesOutOp : Torch_Op<"aten.var.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::var.names_out : (Tensor, str[], bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenVarOutOp : Torch_Op<"aten.var.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::var.out : (Tensor, int[], bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenVarCorrectionOutOp : Torch_Op<"aten.var.correction_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::var.correction_out : (Tensor, int[]?, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenVarCorrectionNamesOutOp : Torch_Op<"aten.var.correction_names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::var.correction_names_out : (Tensor, str[], int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenAddmv_Op : Torch_Op<"aten.addmv_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addmv_ : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat,
    AnyTorchTensorType:$vec,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat `,` $vec `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($mat) `,` type($vec) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenAddcdiv_Op : Torch_Op<"aten.addcdiv_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addcdiv_ : (Tensor, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor1,
    AnyTorchTensorType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value) `->` type($result)";
}

def Torch_Aten_AddRelu_TensorOp : Torch_Op<"aten._add_relu_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_add_relu_.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_Aten_AddRelu_ScalarOp : Torch_Op<"aten._add_relu_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_add_relu_.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenAmaxOutOp : Torch_Op<"aten.amax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::amax.out : (Tensor, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_Aten_AddReluTensorOp : Torch_Op<"aten._add_relu.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_add_relu.Tensor : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_Aten_AddReluOutOp : Torch_Op<"aten._add_relu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_add_relu.out : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha `,` $out attr-dict `:` type($self) `,` type($other) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_Aten_AddReluScalarOp : Torch_Op<"aten._add_relu.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_add_relu.Scalar : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha) `->` type($result)";
}

def Torch_AtenArgminOutOp : Torch_Op<"aten.argmin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::argmin.out : (Tensor, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenAcosh_Op : Torch_Op<"aten.acosh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::acosh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAcoshOutOp : Torch_Op<"aten.acosh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::acosh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAcos_Op : Torch_Op<"aten.acos_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::acos_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAbsolute_Op : Torch_Op<"aten.absolute_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::absolute_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAbsoluteOutOp : Torch_Op<"aten.absolute.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::absolute.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_LocalScalarDenseOp : Torch_Op<"aten._local_scalar_dense", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_local_scalar_dense : (Tensor) -> (Scalar)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchScalarType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgInvExInverseOp : Torch_Op<"aten.linalg_inv_ex.inverse", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_inv_ex.inverse : (Tensor, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$check_errors,
    AnyTorchTensorType:$inverse,
    AnyTorchTensorType:$info
  );
  let results = (outs
    AnyTorchTensorType:$res_inverse,
    AnyTorchTensorType:$res_info
  );
  let assemblyFormat = "$self `,` $check_errors `,` $inverse `,` $info attr-dict `:` type($self) `,` type($check_errors) `,` type($inverse) `,` type($info) `->` type($res_inverse) `,` type($res_info)";
}

def Torch_AtenLinalgSvdUOp : Torch_Op<"aten.linalg_svd.U", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_svd.U : (Tensor, bool, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$full_matrices,
    AnyTorchTensorType:$U,
    AnyTorchTensorType:$S,
    AnyTorchTensorType:$Vh
  );
  let results = (outs
    AnyTorchTensorType:$res_U,
    AnyTorchTensorType:$res_S,
    AnyTorchTensorType:$res_Vh
  );
  let assemblyFormat = "$self `,` $full_matrices `,` $U `,` $S `,` $Vh attr-dict `:` type($self) `,` type($full_matrices) `,` type($U) `,` type($S) `,` type($Vh) `->` type($res_U) `,` type($res_S) `,` type($res_Vh)";
}

def Torch_AtenMultilabelMarginLossForwardOutputOp : Torch_Op<"aten.multilabel_margin_loss_forward.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multilabel_margin_loss_forward.output : (Tensor, Tensor, int, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$is_target
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $output `,` $is_target attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($output) `,` type($is_target) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_ForeachAbsOp : Torch_Op<"aten._foreach_abs", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_abs : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenFractionalMaxPool3dOp : Torch_Op<"aten.fractional_max_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool3d : (Tensor, int[], int[], Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$random_samples
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $output_size `,` $random_samples attr-dict `:` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($random_samples) `->` type($result0) `,` type($result1)";
}

def Torch_AtenFractionalMaxPool3dOutputOp : Torch_Op<"aten.fractional_max_pool3d.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool3d.output : (Tensor, int[], int[], Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$random_samples,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $output_size `,` $random_samples `,` $output `,` $indices attr-dict `:` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($random_samples) `,` type($output) `,` type($indices) `->` type($result0) `,` type($result1)";
}

def Torch_AtenAddmmOutOp : Torch_Op<"aten.addmm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addmm.out : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat1 `,` $mat2 `,` $beta `,` $alpha `,` $out attr-dict `:` type($self) `,` type($mat1) `,` type($mat2) `,` type($beta) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenFractionalMaxPool2dOp : Torch_Op<"aten.fractional_max_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool2d : (Tensor, int[], int[], Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$random_samples
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $output_size `,` $random_samples attr-dict `:` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($random_samples) `->` type($result0) `,` type($result1)";
}

def Torch_AtenFractionalMaxPool2dOutputOp : Torch_Op<"aten.fractional_max_pool2d.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool2d.output : (Tensor, int[], int[], Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$random_samples,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $output_size `,` $random_samples `,` $output `,` $indices attr-dict `:` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($random_samples) `,` type($output) `,` type($indices) `->` type($result0) `,` type($result1)";
}

def Torch_AtenSolveSolutionOp : Torch_Op<"aten.solve.solution", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::solve.solution : (Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A,
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$lu
  );
  let results = (outs
    AnyTorchTensorType:$res_solution,
    AnyTorchTensorType:$LU
  );
  let assemblyFormat = "$self `,` $A `,` $solution `,` $lu attr-dict `:` type($self) `,` type($A) `,` type($solution) `,` type($lu) `->` type($res_solution) `,` type($LU)";
}

def Torch_AtenQrQOp : Torch_Op<"aten.qr.Q", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::qr.Q : (Tensor, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$some,
    AnyTorchTensorType:$Q,
    AnyTorchTensorType:$R
  );
  let results = (outs
    AnyTorchTensorType:$res_Q,
    AnyTorchTensorType:$res_R
  );
  let assemblyFormat = "$self `,` $some `,` $Q `,` $R attr-dict `:` type($self) `,` type($some) `,` type($Q) `,` type($R) `->` type($res_Q) `,` type($res_R)";
}

def Torch_AtenHardswishBackwardOp : Torch_Op<"aten.hardswish_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardswish_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_Aten_LuWithInfoOp : Torch_Op<"aten._lu_with_info", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_lu_with_info : (Tensor, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$pivot,
    Torch_BoolType:$check_errors
  );
  let results = (outs
    AnyTorchTensorType:$LU,
    AnyTorchTensorType:$pivots,
    AnyTorchTensorType:$info
  );
  let assemblyFormat = "$self `,` $pivot `,` $check_errors attr-dict `:` type($self) `,` type($pivot) `,` type($check_errors) `->` type($LU) `,` type($pivots) `,` type($info)";
}

def Torch_AtenLstsqXOp : Torch_Op<"aten.lstsq.X", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lstsq.X : (Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A,
    AnyTorchTensorType:$X,
    AnyTorchTensorType:$qr
  );
  let results = (outs
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$QR
  );
  let assemblyFormat = "$self `,` $A `,` $X `,` $qr attr-dict `:` type($self) `,` type($A) `,` type($X) `,` type($qr) `->` type($solution) `,` type($QR)";
}

def Torch_Aten_ReshapeAliasOp : Torch_Op<"aten._reshape_alias", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_reshape_alias : (Tensor, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchIntListType:$stride
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $stride attr-dict `:` type($self) `,` type($size) `,` type($stride) `->` type($result)";
}

def Torch_AtenGeqrfAOp : Torch_Op<"aten.geqrf.a", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::geqrf.a : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$a,
    AnyTorchTensorType:$tau
  );
  let results = (outs
    AnyTorchTensorType:$res_a,
    AnyTorchTensorType:$res_tau
  );
  let assemblyFormat = "$self `,` $a `,` $tau attr-dict `:` type($self) `,` type($a) `,` type($tau) `->` type($res_a) `,` type($res_tau)";
}

def Torch_AtenEigEOp : Torch_Op<"aten.eig.e", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eig.e : (Tensor, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$eigenvectors,
    AnyTorchTensorType:$e,
    AnyTorchTensorType:$v
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$res_eigenvectors
  );
  let assemblyFormat = "$self `,` $eigenvectors `,` $e `,` $v attr-dict `:` type($self) `,` type($eigenvectors) `,` type($e) `,` type($v) `->` type($eigenvalues) `,` type($res_eigenvectors)";
}

def Torch_AtenCumminDimnameOutOp : Torch_Op<"aten.cummin.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cummin.dimname_out : (Tensor, str, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenCumminOutOp : Torch_Op<"aten.cummin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cummin.out : (Tensor, int, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenCummaxDimnameOutOp : Torch_Op<"aten.cummax.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cummax.dimname_out : (Tensor, str, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenCummaxOutOp : Torch_Op<"aten.cummax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cummax.out : (Tensor, int, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenLinalgHouseholderProductOutOp : Torch_Op<"aten.linalg_householder_product.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_householder_product.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$tau,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $tau `,` $out attr-dict `:` type($input) `,` type($tau) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgInvOutOp : Torch_Op<"aten.linalg_inv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_inv.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAddOutOp : Torch_Op<"aten.add.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::add.out : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha `,` $out attr-dict `:` type($self) `,` type($other) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgSolveOutOp : Torch_Op<"aten.linalg_solve.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_solve.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $other `,` $out attr-dict `:` type($input) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool2dBackwardOp : Torch_Op<"aten.adaptive_max_pool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool2d_backward : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool2dBackwardGradInputOp : Torch_Op<"aten.adaptive_max_pool2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool2d_backward.grad_input : (Tensor, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenTriangularSolveXOp : Torch_Op<"aten.triangular_solve.X", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::triangular_solve.X : (Tensor, Tensor, bool, bool, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A,
    Torch_BoolType:$upper,
    Torch_BoolType:$transpose,
    Torch_BoolType:$unitriangular,
    AnyTorchTensorType:$X,
    AnyTorchTensorType:$M
  );
  let results = (outs
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$cloned_coefficient
  );
  let assemblyFormat = "$self `,` $A `,` $upper `,` $transpose `,` $unitriangular `,` $X `,` $M attr-dict `:` type($self) `,` type($A) `,` type($upper) `,` type($transpose) `,` type($unitriangular) `,` type($X) `,` type($M) `->` type($solution) `,` type($cloned_coefficient)";
}

def Torch_AtenFftIrfftOutOp : Torch_Op<"aten.fft_irfft.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_irfft.out : (Tensor, int?, int, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenAllOutOp : Torch_Op<"aten.all.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::all.out : (Tensor, int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenAllAllOutOp : Torch_Op<"aten.all.all_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::all.all_out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAllDimnameOutOp : Torch_Op<"aten.all.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::all.dimname_out : (Tensor, str, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgLstsqOutOp : Torch_Op<"aten.linalg_lstsq.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_lstsq.out : (Tensor, Tensor, float?, str?, Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$b,
    TorchOptionalFloatType:$rcond,
    TorchOptionalStringType:$driver,
    AnyTorchTensorType:$solution,
    AnyTorchTensorType:$residuals,
    AnyTorchTensorType:$rank,
    AnyTorchTensorType:$singular_values
  );
  let results = (outs
    AnyTorchTensorType:$res_solution,
    AnyTorchTensorType:$res_residuals,
    AnyTorchTensorType:$res_rank,
    AnyTorchTensorType:$res_singular_values
  );
  let assemblyFormat = "$self `,` $b `,` $rcond `,` $driver `,` $solution `,` $residuals `,` $rank `,` $singular_values attr-dict `:` type($self) `,` type($b) `,` type($rcond) `,` type($driver) `,` type($solution) `,` type($residuals) `,` type($rank) `,` type($singular_values) `->` type($res_solution) `,` type($res_residuals) `,` type($res_rank) `,` type($res_singular_values)";
}

def Torch_AtenFftIfftnOutOp : Torch_Op<"aten.fft_ifftn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_ifftn.out : (Tensor, int[]?, int[]?, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenFftIfft2OutOp : Torch_Op<"aten.fft_ifft2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_ifft2.out : (Tensor, int[]?, int[], str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenSqrt_Op : Torch_Op<"aten.sqrt_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sqrt_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenConjPhysicalOutOp : Torch_Op<"aten.conj_physical.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::conj_physical.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSoftshrinkOutOp : Torch_Op<"aten.softshrink.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::softshrink.out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $lambd `,` $out attr-dict `:` type($self) `,` type($lambd) `,` type($out) `->` type($result)";
}

def Torch_AtenHardsigmoidOutOp : Torch_Op<"aten.hardsigmoid.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardsigmoid.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatrixNormOutOp : Torch_Op<"aten.linalg_matrix_norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_norm.out : (Tensor, Scalar, int[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$ord,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatrixNormStrOrdOutOp : Torch_Op<"aten.linalg_matrix_norm.str_ord_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_norm.str_ord_out : (Tensor, str, int[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$ord,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenHardshrinkOutOp : Torch_Op<"aten.hardshrink.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardshrink.out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $lambd `,` $out attr-dict `:` type($self) `,` type($lambd) `,` type($out) `->` type($result)";
}

def Torch_AtenEluOutOp : Torch_Op<"aten.elu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::elu.out : (Tensor, Scalar, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$alpha,
    AnyTorchScalarType:$scale,
    AnyTorchScalarType:$input_scale,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $alpha `,` $scale `,` $input_scale `,` $out attr-dict `:` type($self) `,` type($alpha) `,` type($scale) `,` type($input_scale) `,` type($out) `->` type($result)";
}

def Torch_AtenReplicationPad3dOutOp : Torch_Op<"aten.replication_pad3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::replication_pad3d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $out attr-dict `:` type($self) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_Aten_DebugHasInternalOverlapOp : Torch_Op<"aten._debug_has_internal_overlap", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_debug_has_internal_overlap : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenReplicationPad2dOutOp : Torch_Op<"aten.replication_pad2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::replication_pad2d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $out attr-dict `:` type($self) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_AtenRetainsGradOp : Torch_Op<"aten.retains_grad", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::retains_grad : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenReplicationPad1dOutOp : Torch_Op<"aten.replication_pad1d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::replication_pad1d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $out attr-dict `:` type($self) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_AtenReflectionPad2dOutOp : Torch_Op<"aten.reflection_pad2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reflection_pad2d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $out attr-dict `:` type($self) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_Aten_TestOptionalFloatlistOp : Torch_Op<"aten._test_optional_floatlist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_optional_floatlist : (Tensor, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$values,
    TorchOptionalFloatListType:$addends
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$values `,` $addends attr-dict `:` type($values) `,` type($addends) `->` type($result)";
}

def Torch_AtenReflectionPad1dOutOp : Torch_Op<"aten.reflection_pad1d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reflection_pad1d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $out attr-dict `:` type($self) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_Aten_LinalgQrHelperOp : Torch_Op<"aten._linalg_qr_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_linalg_qr_helper : (Tensor, str) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$mode
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $mode attr-dict `:` type($self) `,` type($mode) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMaxUnpool3dOp : Torch_Op<"aten.max_unpool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_unpool3d : (Tensor, Tensor, int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $output_size `,` $stride `,` $padding attr-dict `:` type($self) `,` type($indices) `,` type($output_size) `,` type($stride) `,` type($padding) `->` type($result)";
}

def Torch_AtenMaxUnpool3dOutOp : Torch_Op<"aten.max_unpool3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_unpool3d.out : (Tensor, Tensor, int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $output_size `,` $stride `,` $padding `,` $out attr-dict `:` type($self) `,` type($indices) `,` type($output_size) `,` type($stride) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_AtenMaxUnpool2dOp : Torch_Op<"aten.max_unpool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_unpool2d : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $output_size attr-dict `:` type($self) `,` type($indices) `,` type($output_size) `->` type($result)";
}

def Torch_AtenMaxUnpool2dOutOp : Torch_Op<"aten.max_unpool2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_unpool2d.out : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $output_size `,` $out attr-dict `:` type($self) `,` type($indices) `,` type($output_size) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachTrunc_Op : Torch_Op<"aten._foreach_trunc_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_trunc_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenOrmqrOutOp : Torch_Op<"aten.ormqr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ormqr.out : (Tensor, Tensor, Tensor, bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input2,
    AnyTorchTensorType:$input3,
    Torch_BoolType:$left,
    Torch_BoolType:$transpose,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $input2 `,` $input3 `,` $left `,` $transpose `,` $out attr-dict `:` type($self) `,` type($input2) `,` type($input3) `,` type($left) `,` type($transpose) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachFracOp : Torch_Op<"aten._foreach_frac", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_frac : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenOrgqrOutOp : Torch_Op<"aten.orgqr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::orgqr.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input2,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $input2 `,` $out attr-dict `:` type($self) `,` type($input2) `,` type($out) `->` type($result)";
}

def Torch_Aten_StackOp : Torch_Op<"aten._stack", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_stack : (Tensor[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_Aten_StackOutOp : Torch_Op<"aten._stack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_stack.out : (Tensor[], int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenLuSolveOutOp : Torch_Op<"aten.lu_solve.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lu_solve.out : (Tensor, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$LU_data,
    AnyTorchTensorType:$LU_pivots,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $LU_data `,` $LU_pivots `,` $out attr-dict `:` type($self) `,` type($LU_data) `,` type($LU_pivots) `,` type($out) `->` type($result)";
}

def Torch_AtenSiluBackwardOp : Torch_Op<"aten.silu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::silu_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_AtenSiluBackwardGradInputOp : Torch_Op<"aten.silu_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::silu_backward.grad_input : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenInverseOutOp : Torch_Op<"aten.inverse.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::inverse.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenErfinv_Op : Torch_Op<"aten.erfinv_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::erfinv_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAvgPool3dBackwardOp : Torch_Op<"aten.avg_pool3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::avg_pool3d_backward : (Tensor, Tensor, int[], int[], int[], bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `->` type($result)";
}

def Torch_AtenAvgPool3dBackwardGradInputOp : Torch_Op<"aten.avg_pool3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::avg_pool3d_backward.grad_input : (Tensor, Tensor, int[], int[], int[], bool, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenCholeskySolveOutOp : Torch_Op<"aten.cholesky_solve.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cholesky_solve.out : (Tensor, Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$input2,
    Torch_BoolType:$upper,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $input2 `,` $upper `,` $out attr-dict `:` type($self) `,` type($input2) `,` type($upper) `,` type($out) `->` type($result)";
}

def Torch_AtenErfc_Op : Torch_Op<"aten.erfc_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::erfc_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAvgPool3dOp : Torch_Op<"aten.avg_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::avg_pool3d : (Tensor, int[], int[], int[], bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `->` type($result)";
}

def Torch_AtenAvgPool3dOutOp : Torch_Op<"aten.avg_pool3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::avg_pool3d.out : (Tensor, int[], int[], int[], bool, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override `,` $out attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `,` type($out) `->` type($result)";
}

def Torch_AtenAminmaxOutOp : Torch_Op<"aten.aminmax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::aminmax.out : (Tensor, int?, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$min,
    AnyTorchTensorType:$max
  );
  let results = (outs
    AnyTorchTensorType:$res_min,
    AnyTorchTensorType:$res_max
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $min `,` $max attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($min) `,` type($max) `->` type($res_min) `,` type($res_max)";
}

def Torch_AtenFftRfftnOutOp : Torch_Op<"aten.fft_rfftn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_rfftn.out : (Tensor, int[]?, int[]?, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenTriuOutOp : Torch_Op<"aten.triu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::triu.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal `,` $out attr-dict `:` type($self) `,` type($diagonal) `,` type($out) `->` type($result)";
}

def Torch_AtenLogcumsumexpDimnameOutOp : Torch_Op<"aten.logcumsumexp.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logcumsumexp.dimname_out : (Tensor, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenLogcumsumexpOutOp : Torch_Op<"aten.logcumsumexp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logcumsumexp.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_Aten_ComputeLinearCombinationOp : Torch_Op<"aten._compute_linear_combination", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_compute_linear_combination : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$coefficients
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $coefficients attr-dict `:` type($input) `,` type($coefficients) `->` type($result)";
}

def Torch_Aten_ComputeLinearCombinationOutOp : Torch_Op<"aten._compute_linear_combination.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_compute_linear_combination.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$coefficients,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $coefficients `,` $out attr-dict `:` type($input) `,` type($coefficients) `,` type($out) `->` type($result)";
}

def Torch_AtenHistcOutOp : Torch_Op<"aten.histc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::histc.out : (Tensor, int, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$bins,
    AnyTorchScalarType:$min,
    AnyTorchScalarType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $bins `,` $min `,` $max `,` $out attr-dict `:` type($self) `,` type($bins) `,` type($min) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenDiagOutOp : Torch_Op<"aten.diag.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::diag.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal `,` $out attr-dict `:` type($self) `,` type($diagonal) `,` type($out) `->` type($result)";
}

def Torch_AtenNanquantileScalarOutOp : Torch_Op<"aten.nanquantile.scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanquantile.scalar_out : (Tensor, float, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenNanquantileOutOp : Torch_Op<"aten.nanquantile.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanquantile.out : (Tensor, Tensor, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenNanquantileNewScalarOutOp : Torch_Op<"aten.nanquantile.new_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanquantile.new_scalar_out : (Tensor, float, int?, bool, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `,` type($out) `->` type($result)";
}

def Torch_AtenNanquantileNewOutOp : Torch_Op<"aten.nanquantile.new_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nanquantile.new_out : (Tensor, Tensor, int?, bool, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `,` type($out) `->` type($result)";
}

def Torch_Aten_AdaptiveAvgPool2dOp : Torch_Op<"aten._adaptive_avg_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_adaptive_avg_pool2d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result)";
}

def Torch_AtenQuantileScalarOutOp : Torch_Op<"aten.quantile.scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::quantile.scalar_out : (Tensor, float, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenQuantileOutOp : Torch_Op<"aten.quantile.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::quantile.out : (Tensor, Tensor, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenQuantileNewScalarOutOp : Torch_Op<"aten.quantile.new_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::quantile.new_scalar_out : (Tensor, float, int?, bool, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `,` type($out) `->` type($result)";
}

def Torch_AtenQuantileNewOutOp : Torch_Op<"aten.quantile.new_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::quantile.new_out : (Tensor, Tensor, int?, bool, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$q,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    Torch_StringType:$interpolation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $q `,` $dim `,` $keepdim `,` $interpolation `,` $out attr-dict `:` type($self) `,` type($q) `,` type($dim) `,` type($keepdim) `,` type($interpolation) `,` type($out) `->` type($result)";
}

def Torch_AtenArccoshOutOp : Torch_Op<"aten.arccosh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arccosh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenFmodTensorOutOp : Torch_Op<"aten.fmod.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fmod.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenFmodScalarOutOp : Torch_Op<"aten.fmod.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fmod.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_CdistForwardOp : Torch_Op<"aten._cdist_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cdist_forward : (Tensor, Tensor, float, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x1,
    AnyTorchTensorType:$x2,
    Torch_FloatType:$p,
    TorchOptionalIntType:$compute_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x1 `,` $x2 `,` $p `,` $compute_mode attr-dict `:` type($x1) `,` type($x2) `,` type($p) `,` type($compute_mode) `->` type($result)";
}

def Torch_AtenUpsampleNearest3dOutOp : Torch_Op<"aten.upsample_nearest3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_nearest3d.out : (Tensor, int[], float?, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $scales_d `,` $scales_h `,` $scales_w `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgEighEigvalsOp : Torch_Op<"aten.linalg_eigh.eigvals", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_eigh.eigvals : (Tensor, str, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$UPLO,
    AnyTorchTensorType:$eigvals,
    AnyTorchTensorType:$eigvecs
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$eigenvectors
  );
  let assemblyFormat = "$self `,` $UPLO `,` $eigvals `,` $eigvecs attr-dict `:` type($self) `,` type($UPLO) `,` type($eigvals) `,` type($eigvecs) `->` type($eigenvalues) `,` type($eigenvectors)";
}

def Torch_AtenUpsampleNearest2dOutOp : Torch_Op<"aten.upsample_nearest2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_nearest2d.out : (Tensor, int[], float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $scales_h `,` $scales_w `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($scales_h) `,` type($scales_w) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgCholeskyExLOp : Torch_Op<"aten.linalg_cholesky_ex.L", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_cholesky_ex.L : (Tensor, bool, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper,
    Torch_BoolType:$check_errors,
    AnyTorchTensorType:$L,
    AnyTorchTensorType:$info
  );
  let results = (outs
    AnyTorchTensorType:$res_L,
    AnyTorchTensorType:$res_info
  );
  let assemblyFormat = "$self `,` $upper `,` $check_errors `,` $L `,` $info attr-dict `:` type($self) `,` type($upper) `,` type($check_errors) `,` type($L) `,` type($info) `->` type($res_L) `,` type($res_info)";
}

def Torch_AtenAddrOutOp : Torch_Op<"aten.addr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addr.out : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec1,
    AnyTorchTensorType:$vec2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec1 `,` $vec2 `,` $beta `,` $alpha `,` $out attr-dict `:` type($self) `,` type($vec1) `,` type($vec2) `,` type($beta) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenUpsampleNearest1dOutOp : Torch_Op<"aten.upsample_nearest1d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_nearest1d.out : (Tensor, int[], float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchOptionalFloatType:$scales,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $scales `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($scales) `,` type($out) `->` type($result)";
}

def Torch_AtenGeluOutOp : Torch_Op<"aten.gelu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gelu.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgQrOutOp : Torch_Op<"aten.linalg_qr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_qr.out : (Tensor, str, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$mode,
    AnyTorchTensorType:$Q,
    AnyTorchTensorType:$R
  );
  let results = (outs
    AnyTorchTensorType:$res_Q,
    AnyTorchTensorType:$res_R
  );
  let assemblyFormat = "$self `,` $mode `,` $Q `,` $R attr-dict `:` type($self) `,` type($mode) `,` type($Q) `,` type($R) `->` type($res_Q) `,` type($res_R)";
}

def Torch_AtenAddmvOutOp : Torch_Op<"aten.addmv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addmv.out : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat,
    AnyTorchTensorType:$vec,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat `,` $vec `,` $beta `,` $alpha `,` $out attr-dict `:` type($self) `,` type($mat) `,` type($vec) `,` type($beta) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenFloorDivideOutOp : Torch_Op<"aten.floor_divide.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::floor_divide.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ToCopyOp : Torch_Op<"aten._to_copy", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_to_copy : (Tensor, int?, int?, Device?, bool?, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    Torch_BoolType:$non_blocking,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $non_blocking `,` $memory_format attr-dict `:` type($self) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($non_blocking) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenArgmaxOutOp : Torch_Op<"aten.argmax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::argmax.out : (Tensor, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenUpsampleTrilinear3dOutOp : Torch_Op<"aten.upsample_trilinear3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_trilinear3d.out : (Tensor, int[], bool, float?, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales_d `,` $scales_h `,` $scales_w `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `,` type($out) `->` type($result)";
}

def Torch_AtenBinaryCrossEntropyOutOp : Torch_Op<"aten.binary_cross_entropy.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::binary_cross_entropy.out : (Tensor, Tensor, Tensor?, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $out attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($out) `->` type($result)";
}

def Torch_AtenScatterAddOutOp : Torch_Op<"aten.scatter_add.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter_add.out : (Tensor, int, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `,` type($out) `->` type($result)";
}

def Torch_AtenCatNamesOutOp : Torch_Op<"aten.cat.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cat.names_out : (Tensor[], str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_StringType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenCatOutOp : Torch_Op<"aten.cat.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cat.out : (Tensor[], int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenMmOutOp : Torch_Op<"aten.mm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mm.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat2,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat2 `,` $out attr-dict `:` type($self) `,` type($mat2) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachSubScalarOp : Torch_Op<"aten._foreach_sub.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sub.Scalar : (Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalar attr-dict `:` type($tensors) `,` type($scalar) `->` type($result)";
}

def Torch_Aten_ForeachSubListOp : Torch_Op<"aten._foreach_sub.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sub.List : (Tensor[], Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors1,
    AnyTorchTensorListType:$tensors2,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors1 `,` $tensors2 `,` $alpha attr-dict `:` type($tensors1) `,` type($tensors2) `,` type($alpha) `->` type($result)";
}

def Torch_Aten_ForeachSubScalarListOp : Torch_Op<"aten._foreach_sub.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sub.ScalarList : (Tensor[], Scalar[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalars attr-dict `:` type($tensors) `,` type($scalars) `->` type($result)";
}

def Torch_AtenAngleOutOp : Torch_Op<"aten.angle.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::angle.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLog10_Op : Torch_Op<"aten.log10_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log10_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLgamma_Op : Torch_Op<"aten.lgamma_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lgamma_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenHypot_Op : Torch_Op<"aten.hypot_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hypot_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenIndexFill_DimnameScalarOp : Torch_Op<"aten.index_fill_.Dimname_Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_fill_.Dimname_Scalar : (Tensor, str, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenIndexFill_DimnameTensorOp : Torch_Op<"aten.index_fill_.Dimname_Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_fill_.Dimname_Tensor : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenIndexFill_IntScalarOp : Torch_Op<"aten.index_fill_.int_Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_fill_.int_Scalar : (Tensor, int, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenIndexFill_IntTensorOp : Torch_Op<"aten.index_fill_.int_Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_fill_.int_Tensor : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `->` type($result)";
}

def Torch_AtenDigamma_Op : Torch_Op<"aten.digamma_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::digamma_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAvgPool2dBackwardOp : Torch_Op<"aten.avg_pool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::avg_pool2d_backward : (Tensor, Tensor, int[], int[], int[], bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `->` type($result)";
}

def Torch_AtenAvgPool2dBackwardGradInputOp : Torch_Op<"aten.avg_pool2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::avg_pool2d_backward.grad_input : (Tensor, Tensor, int[], int[], int[], bool, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenPolygamma_Op : Torch_Op<"aten.polygamma_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::polygamma_ : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n attr-dict `:` type($self) `,` type($n) `->` type($result)";
}

def Torch_AtenMultilabelMarginLossOutOp : Torch_Op<"aten.multilabel_margin_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multilabel_margin_loss.out : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $out attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachSqrtOp : Torch_Op<"aten._foreach_sqrt", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sqrt : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_SobolEngineInitializeState_Op : Torch_Op<"aten._sobol_engine_initialize_state_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_sobol_engine_initialize_state_ : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dimension
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dimension attr-dict `:` type($self) `,` type($dimension) `->` type($result)";
}

def Torch_AtenResultTypeTensorOp : Torch_Op<"aten.result_type.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::result_type.Tensor : (Tensor, Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$tensor,
    AnyTorchTensorType:$other
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$tensor `,` $other attr-dict `:` type($tensor) `,` type($other) `->` type($result)";
}

def Torch_AtenResultTypeScalarOp : Torch_Op<"aten.result_type.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::result_type.Scalar : (Tensor, Scalar) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$tensor,
    AnyTorchScalarType:$other
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$tensor `,` $other attr-dict `:` type($tensor) `,` type($other) `->` type($result)";
}

def Torch_AtenResultTypeScalarTensorOp : Torch_Op<"aten.result_type.Scalar_Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::result_type.Scalar_Tensor : (Scalar, Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchScalarType:$scalar,
    AnyTorchTensorType:$tensor
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$scalar `,` $tensor attr-dict `:` type($scalar) `,` type($tensor) `->` type($result)";
}

def Torch_AtenResultTypeScalarScalarOp : Torch_Op<"aten.result_type.Scalar_Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::result_type.Scalar_Scalar : (Scalar, Scalar) -> (int)`";
  let arguments = (ins
    AnyTorchScalarType:$scalar1,
    AnyTorchScalarType:$scalar2
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$scalar1 `,` $scalar2 attr-dict `:` type($scalar1) `,` type($scalar2) `->` type($result)";
}

def Torch_AtenFftFft2OutOp : Torch_Op<"aten.fft_fft2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_fft2.out : (Tensor, int[]?, int[], str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenAddcdivOutOp : Torch_Op<"aten.addcdiv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addcdiv.out : (Tensor, Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor1,
    AnyTorchTensorType:$tensor2,
    AnyTorchScalarType:$value,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value `,` $out attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value) `,` type($out) `->` type($result)";
}

def Torch_AtenAvgPool2dOp : Torch_Op<"aten.avg_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::avg_pool2d : (Tensor, int[], int[], int[], bool, bool, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `->` type($result)";
}

def Torch_AtenAvgPool2dOutOp : Torch_Op<"aten.avg_pool2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::avg_pool2d.out : (Tensor, int[], int[], int[], bool, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad,
    TorchOptionalIntType:$divisor_override,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad `,` $divisor_override `,` $out attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `,` type($divisor_override) `,` type($out) `->` type($result)";
}

def Torch_AtenDeg2rad_Op : Torch_Op<"aten.deg2rad_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::deg2rad_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMaxPool1dOp : Torch_Op<"aten.max_pool1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool1d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenTruncOutOp : Torch_Op<"aten.trunc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::trunc.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSearchsortedTensorOutOp : Torch_Op<"aten.searchsorted.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::searchsorted.Tensor_out : (Tensor, Tensor, bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$sorted_sequence,
    AnyTorchTensorType:$self,
    Torch_BoolType:$out_int32,
    Torch_BoolType:$right,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sorted_sequence `,` $self `,` $out_int32 `,` $right `,` $out attr-dict `:` type($sorted_sequence) `,` type($self) `,` type($out_int32) `,` type($right) `,` type($out) `->` type($result)";
}

def Torch_Aten_UniqueOp : Torch_Op<"aten._unique", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_unique : (Tensor, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$sorted,
    Torch_BoolType:$return_inverse
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $sorted `,` $return_inverse attr-dict `:` type($self) `,` type($sorted) `,` type($return_inverse) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMulOutOp : Torch_Op<"aten.mul.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mul.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSignOutOp : Torch_Op<"aten.sign.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sign.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSigmoidOutOp : Torch_Op<"aten.sigmoid.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sigmoid.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenMvlgamma_Op : Torch_Op<"aten.mvlgamma_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mvlgamma_ : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_AtenFracOutOp : Torch_Op<"aten.frac.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::frac.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLog1pOutOp : Torch_Op<"aten.log1p.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log1p.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenExpm1_Op : Torch_Op<"aten.expm1_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::expm1_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenBaddbmmOutOp : Torch_Op<"aten.baddbmm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::baddbmm.out : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$batch1,
    AnyTorchTensorType:$batch2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch1 `,` $batch2 `,` $beta `,` $alpha `,` $out attr-dict `:` type($self) `,` type($batch1) `,` type($batch2) `,` type($beta) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenClampMaxOutOp : Torch_Op<"aten.clamp_max.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_max.out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $max `,` $out attr-dict `:` type($self) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenClampMaxTensorOutOp : Torch_Op<"aten.clamp_max.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_max.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $max `,` $out attr-dict `:` type($self) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenLog10OutOp : Torch_Op<"aten.log10.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log10.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_FftC2rOp : Torch_Op<"aten._fft_c2r", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fft_c2r : (Tensor, int[], int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$normalization,
    Torch_IntType:$last_dim_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $normalization `,` $last_dim_size attr-dict `:` type($self) `,` type($dim) `,` type($normalization) `,` type($last_dim_size) `->` type($result)";
}

def Torch_Aten_FftC2rOutOp : Torch_Op<"aten._fft_c2r.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_fft_c2r.out : (Tensor, int[], int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$normalization,
    Torch_IntType:$last_dim_size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $normalization `,` $last_dim_size `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($normalization) `,` type($last_dim_size) `,` type($out) `->` type($result)";
}

def Torch_AtenTensordotOutOp : Torch_Op<"aten.tensordot.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tensordot.out : (Tensor, Tensor, int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchIntListType:$dims_self,
    TorchIntListType:$dims_other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $dims_self `,` $dims_other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($dims_self) `,` type($dims_other) `,` type($out) `->` type($result)";
}

def Torch_AtenSigmoidBackwardOp : Torch_Op<"aten.sigmoid_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::sigmoid_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output attr-dict `:` type($grad_output) `,` type($output) `->` type($result)";
}

def Torch_AtenSigmoidBackwardGradInputOp : Torch_Op<"aten.sigmoid_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sigmoid_backward.grad_input : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $grad_input attr-dict `:` type($grad_output) `,` type($output) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenFloorOutOp : Torch_Op<"aten.floor.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::floor.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenExpm1OutOp : Torch_Op<"aten.expm1.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::expm1.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenTanOutOp : Torch_Op<"aten.tan.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tan.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSelectBackwardOp : Torch_Op<"aten.select_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::select_backward : (Tensor, int[], int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$input_sizes,
    Torch_IntType:$dim,
    Torch_IntType:$index
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $input_sizes `,` $dim `,` $index attr-dict `:` type($grad_output) `,` type($input_sizes) `,` type($dim) `,` type($index) `->` type($result)";
}

def Torch_AtenDigammaOutOp : Torch_Op<"aten.digamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::digamma.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenCosh_Op : Torch_Op<"aten.cosh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cosh_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAvgPool1dOp : Torch_Op<"aten.avg_pool1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::avg_pool1d : (Tensor, int[], int[], int[], bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    Torch_BoolType:$ceil_mode,
    Torch_BoolType:$count_include_pad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $ceil_mode `,` $count_include_pad attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($ceil_mode) `,` type($count_include_pad) `->` type($result)";
}

def Torch_AtenSinhOutOp : Torch_Op<"aten.sinh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sinh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenDivOutOp : Torch_Op<"aten.div.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::div.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenDivOutModeOp : Torch_Op<"aten.div.out_mode", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::div.out_mode : (Tensor, Tensor, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalStringType:$rounding_mode,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $rounding_mode `,` $out attr-dict `:` type($self) `,` type($other) `,` type($rounding_mode) `,` type($out) `->` type($result)";
}

def Torch_AtenMvOutOp : Torch_Op<"aten.mv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mv.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec `,` $out attr-dict `:` type($self) `,` type($vec) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAcosOp : Torch_Op<"aten._foreach_acos", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_acos : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenSinOutOp : Torch_Op<"aten.sin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sin.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAbs_Op : Torch_Op<"aten._foreach_abs_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_abs_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenPowScalarOutOp : Torch_Op<"aten.pow.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::pow.Scalar_out : (Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$exponent,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent `,` $out attr-dict `:` type($self) `,` type($exponent) `,` type($out) `->` type($result)";
}

def Torch_AtenPowTensorScalarOutOp : Torch_Op<"aten.pow.Tensor_Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::pow.Tensor_Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$exponent,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent `,` $out attr-dict `:` type($self) `,` type($exponent) `,` type($out) `->` type($result)";
}

def Torch_AtenPowTensorTensorOutOp : Torch_Op<"aten.pow.Tensor_Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::pow.Tensor_Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$exponent,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $exponent `,` $out attr-dict `:` type($self) `,` type($exponent) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAddcmulScalarOp : Torch_Op<"aten._foreach_addcmul.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcmul.Scalar : (Tensor[], Tensor[], Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$input,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$input `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($input) `,` type($tensor1) `,` type($tensor2) `,` type($value) `->` type($result)";
}

def Torch_Aten_ForeachAddcmulScalarListOp : Torch_Op<"aten._foreach_addcmul.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcmul.ScalarList : (Tensor[], Tensor[], Tensor[], Scalar[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$input,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$input `,` $tensor1 `,` $tensor2 `,` $scalars attr-dict `:` type($input) `,` type($tensor1) `,` type($tensor2) `,` type($scalars) `->` type($result)";
}

def Torch_AtenSliceBackwardOp : Torch_Op<"aten.slice_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slice_backward : (Tensor, int[], int, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$input_sizes,
    Torch_IntType:$dim,
    Torch_IntType:$start,
    Torch_IntType:$end,
    Torch_IntType:$step
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $input_sizes `,` $dim `,` $start `,` $end `,` $step attr-dict `:` type($grad_output) `,` type($input_sizes) `,` type($dim) `,` type($start) `,` type($end) `,` type($step) `->` type($result)";
}

def Torch_AtenTanhOutOp : Torch_Op<"aten.tanh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tanh.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLuUnpackOutOp : Torch_Op<"aten.lu_unpack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lu_unpack.out : (Tensor, Tensor, bool, bool, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$LU_data,
    AnyTorchTensorType:$LU_pivots,
    Torch_BoolType:$unpack_data,
    Torch_BoolType:$unpack_pivots,
    AnyTorchTensorType:$P,
    AnyTorchTensorType:$L,
    AnyTorchTensorType:$U
  );
  let results = (outs
    AnyTorchTensorType:$res_P,
    AnyTorchTensorType:$res_L,
    AnyTorchTensorType:$res_U
  );
  let assemblyFormat = "$LU_data `,` $LU_pivots `,` $unpack_data `,` $unpack_pivots `,` $P `,` $L `,` $U attr-dict `:` type($LU_data) `,` type($LU_pivots) `,` type($unpack_data) `,` type($unpack_pivots) `,` type($P) `,` type($L) `,` type($U) `->` type($res_P) `,` type($res_L) `,` type($res_U)";
}

def Torch_AtenAddcmulOutOp : Torch_Op<"aten.addcmul.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addcmul.out : (Tensor, Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor1,
    AnyTorchTensorType:$tensor2,
    AnyTorchScalarType:$value,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value `,` $out attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value) `,` type($out) `->` type($result)";
}

def Torch_AtenUpsampleLinear1dOutOp : Torch_Op<"aten.upsample_linear1d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_linear1d.out : (Tensor, int[], bool, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales) `,` type($out) `->` type($result)";
}

def Torch_AtenIm2colOutOp : Torch_Op<"aten.im2col.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::im2col.out : (Tensor, int[], int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $dilation `,` $padding `,` $stride `,` $out attr-dict `:` type($self) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `,` type($out) `->` type($result)";
}

def Torch_AtenFftIfftOutOp : Torch_Op<"aten.fft_ifft.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_ifft.out : (Tensor, int?, int, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenThresholdBackwardGradInputOp : Torch_Op<"aten.threshold_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::threshold_backward.grad_input : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$threshold,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $threshold `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($threshold) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenAsinOutOp : Torch_Op<"aten.asin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::asin.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAcosOutOp : Torch_Op<"aten.acos.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::acos.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachReciprocal_Op : Torch_Op<"aten._foreach_reciprocal_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_reciprocal_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenClampMinOutOp : Torch_Op<"aten.clamp_min.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_min.out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $out attr-dict `:` type($self) `,` type($min) `,` type($out) `->` type($result)";
}

def Torch_AtenClampMinTensorOutOp : Torch_Op<"aten.clamp_min.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp_min.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$min,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $out attr-dict `:` type($self) `,` type($min) `,` type($out) `->` type($result)";
}

def Torch_AtenRename_Op : Torch_Op<"aten.rename_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rename_ : (Tensor, str[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalStringListType:$names
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $names attr-dict `:` type($self) `,` type($names) `->` type($result)";
}

def Torch_AtenAtan2_Op : Torch_Op<"aten.atan2_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::atan2_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenAtan2OutOp : Torch_Op<"aten.atan2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::atan2.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgSvdvalsOutOp : Torch_Op<"aten.linalg_svdvals.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_svdvals.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $out attr-dict `:` type($input) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool3dOp : Torch_Op<"aten.adaptive_max_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool3d : (Tensor, int[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result0) `,` type($result1)";
}

def Torch_AtenAdaptiveMaxPool3dOutOp : Torch_Op<"aten.adaptive_max_pool3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool3d.out : (Tensor, int[], Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$out,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $output_size `,` $out `,` $indices attr-dict `:` type($self) `,` type($output_size) `,` type($out) `,` type($indices) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_ThnnFusedGruCellOp : Torch_Op<"aten._thnn_fused_gru_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_thnn_fused_gru_cell : (Tensor, Tensor, Tensor, Tensor?, Tensor?) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input_gates,
    AnyTorchTensorType:$hidden_gates,
    AnyTorchTensorType:$hx,
    AnyTorchOptionalTensorType:$input_bias,
    AnyTorchOptionalTensorType:$hidden_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input_gates `,` $hidden_gates `,` $hx `,` $input_bias `,` $hidden_bias attr-dict `:` type($input_gates) `,` type($hidden_gates) `,` type($hx) `,` type($input_bias) `,` type($hidden_bias) `->` type($result0) `,` type($result1)";
}

def Torch_AtenBmmOutOp : Torch_Op<"aten.bmm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bmm.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat2,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat2 `,` $out attr-dict `:` type($self) `,` type($mat2) `,` type($out) `->` type($result)";
}

def Torch_AtenLogicalAnd_Op : Torch_Op<"aten.logical_and_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_and_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenAminOutOp : Torch_Op<"aten.amin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::amin.out : (Tensor, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenFftRfftOutOp : Torch_Op<"aten.fft_rfft.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_rfft.out : (Tensor, int?, int, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenAbsOutOp : Torch_Op<"aten.abs.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::abs.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAddmm_Op : Torch_Op<"aten.addmm_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addmm_ : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat1 `,` $mat2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($mat1) `,` type($mat2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenLinalgTensorinvOutOp : Torch_Op<"aten.linalg_tensorinv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_tensorinv.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$ind,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ind `,` $out attr-dict `:` type($self) `,` type($ind) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgEigvalsOutOp : Torch_Op<"aten.linalg_eigvals.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_eigvals.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool3dBackwardOp : Torch_Op<"aten.adaptive_max_pool3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool3d_backward : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool3dBackwardGradInputOp : Torch_Op<"aten.adaptive_max_pool3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool3d_backward.grad_input : (Tensor, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleBilinear2dOutOp : Torch_Op<"aten.upsample_bilinear2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_bilinear2d.out : (Tensor, int[], bool, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales_h `,` $scales_w `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankAtolRtolTensorOutOp : Torch_Op<"aten.linalg_matrix_rank.atol_rtol_tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.atol_rtol_tensor_out : (Tensor, Tensor?, Tensor?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$atol,
    AnyTorchOptionalTensorType:$rtol,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $atol `,` $rtol `,` $hermitian `,` $out attr-dict `:` type($input) `,` type($atol) `,` type($rtol) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankAtolRtolFloatOutOp : Torch_Op<"aten.linalg_matrix_rank.atol_rtol_float_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.atol_rtol_float_out : (Tensor, float?, float?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$atol,
    TorchOptionalFloatType:$rtol,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $atol `,` $rtol `,` $hermitian `,` $out attr-dict `:` type($self) `,` type($atol) `,` type($rtol) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankOutOp : Torch_Op<"aten.linalg_matrix_rank.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.out : (Tensor, float, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$tol,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tol `,` $hermitian `,` $out attr-dict `:` type($self) `,` type($tol) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMatrixRankOutTolTensorOp : Torch_Op<"aten.linalg_matrix_rank.out_tol_tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_matrix_rank.out_tol_tensor : (Tensor, Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$tol,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $tol `,` $hermitian `,` $out attr-dict `:` type($input) `,` type($tol) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool2dOp : Torch_Op<"aten.adaptive_max_pool2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool2d : (Tensor, int[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result0) `,` type($result1)";
}

def Torch_AtenAdaptiveMaxPool2dOutOp : Torch_Op<"aten.adaptive_max_pool2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool2d.out : (Tensor, int[], Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$out,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $output_size `,` $out `,` $indices attr-dict `:` type($self) `,` type($output_size) `,` type($out) `,` type($indices) `->` type($result0) `,` type($result1)";
}

def Torch_AtenLinalgTensorsolveOutOp : Torch_Op<"aten.linalg_tensorsolve.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_tensorsolve.out : (Tensor, Tensor, int[]?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalIntListType:$dims,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $dims `,` $out attr-dict `:` type($self) `,` type($other) `,` type($dims) `,` type($out) `->` type($result)";
}

def Torch_AtenAddbmmOutOp : Torch_Op<"aten.addbmm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addbmm.out : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$batch1,
    AnyTorchTensorType:$batch2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch1 `,` $batch2 `,` $beta `,` $alpha `,` $out attr-dict `:` type($self) `,` type($batch1) `,` type($batch2) `,` type($beta) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenFftFftnOutOp : Torch_Op<"aten.fft_fftn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_fftn.out : (Tensor, int[]?, int[]?, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenRsqrtOutOp : Torch_Op<"aten.rsqrt.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rsqrt.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenFftIhfftOutOp : Torch_Op<"aten.fft_ihfft.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_ihfft.out : (Tensor, int?, int, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenNuclearNormOutOp : Torch_Op<"aten.nuclear_norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nuclear_norm.out : (Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenNuclearNormDimOutOp : Torch_Op<"aten.nuclear_norm.dim_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nuclear_norm.dim_out : (Tensor, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachRoundOp : Torch_Op<"aten._foreach_round", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_round : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenDotOutOp : Torch_Op<"aten.dot.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::dot.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor `,` $out attr-dict `:` type($self) `,` type($tensor) `,` type($out) `->` type($result)";
}

def Torch_AtenMaxPool3dOp : Torch_Op<"aten.max_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool3d : (Tensor, int[], int[], int[], int[], bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode attr-dict `:` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `->` type($result)";
}

def Torch_AtenNegOutOp : Torch_Op<"aten.neg.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::neg.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLog2OutOp : Torch_Op<"aten.log2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log2.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_FftC2cOp : Torch_Op<"aten._fft_c2c", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fft_c2c : (Tensor, int[], int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$normalization,
    Torch_BoolType:$forward
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $normalization `,` $forward attr-dict `:` type($self) `,` type($dim) `,` type($normalization) `,` type($forward) `->` type($result)";
}

def Torch_Aten_FftC2cOutOp : Torch_Op<"aten._fft_c2c.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_fft_c2c.out : (Tensor, int[], int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$normalization,
    Torch_BoolType:$forward,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $normalization `,` $forward `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($normalization) `,` type($forward) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgCondOutOp : Torch_Op<"aten.linalg_cond.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_cond.out : (Tensor, Scalar?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $out attr-dict `:` type($self) `,` type($p) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgCondPStrOutOp : Torch_Op<"aten.linalg_cond.p_str_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_cond.p_str_out : (Tensor, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$p,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $out attr-dict `:` type($self) `,` type($p) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveMaxPool1dOp : Torch_Op<"aten.adaptive_max_pool1d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_max_pool1d : (Tensor, int[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result0) `,` type($result1)";
}

def Torch_AtenSubOutOp : Torch_Op<"aten.sub.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sub.out : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $alpha `,` $out attr-dict `:` type($self) `,` type($other) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenStrideIntOp : Torch_Op<"aten.stride.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::stride.int : (Tensor, int) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenStrideDimnameOp : Torch_Op<"aten.stride.Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::stride.Dimname : (Tensor, str) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenSgn_Op : Torch_Op<"aten.sgn_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sgn_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLogicalNot_Op : Torch_Op<"aten.logical_not_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_not_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenConv2dPaddingOp : Torch_Op<"aten.conv2d.padding", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv2d.padding : (Tensor, Tensor, Tensor?, int[], str, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    Torch_StringType:$padding,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_Aten_FwPrimalOp : Torch_Op<"aten._fw_primal", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_fw_primal : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$level
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $level attr-dict `:` type($self) `,` type($level) `->` type($result)";
}

def Torch_AtenSquareOutOp : Torch_Op<"aten.square.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::square.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenL1LossOutOp : Torch_Op<"aten.l1_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::l1_loss.out : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $out attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($out) `->` type($result)";
}

def Torch_Aten_CumminHelperOp : Torch_Op<"aten._cummin_helper", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_cummin_helper : (Tensor, Tensor, Tensor, int) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices,
    Torch_IntType:$dim
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $values `,` $indices `,` $dim attr-dict `:` type($self) `,` type($values) `,` type($indices) `,` type($dim)";
}

def Torch_AtenStdNamesOutOp : Torch_Op<"aten.std.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::std.names_out : (Tensor, str[], bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenStdOutOp : Torch_Op<"aten.std.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::std.out : (Tensor, int[], bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$unbiased,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $unbiased `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($unbiased) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenStdCorrectionOutOp : Torch_Op<"aten.std.correction_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::std.correction_out : (Tensor, int[]?, int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenStdCorrectionNamesOutOp : Torch_Op<"aten.std.correction_names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::std.correction_names_out : (Tensor, str[], int?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    TorchOptionalIntType:$correction,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $correction `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($correction) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenConvTbcOp : Torch_Op<"aten.conv_tbc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_tbc : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$bias,
    Torch_IntType:$pad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $pad attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($pad) `->` type($result)";
}

def Torch_AtenLogicalXor_Op : Torch_Op<"aten.logical_xor_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_xor_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMultiMarginLossOutOp : Torch_Op<"aten.multi_margin_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multi_margin_loss.out : (Tensor, Tensor, Scalar, Scalar, Tensor?, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchScalarType:$p,
    AnyTorchScalarType:$margin,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $p `,` $margin `,` $weight `,` $reduction `,` $out attr-dict `:` type($self) `,` type($target) `,` type($p) `,` type($margin) `,` type($weight) `,` type($reduction) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachExpOp : Torch_Op<"aten._foreach_exp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_exp : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenExpOutOp : Torch_Op<"aten.exp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::exp.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenRandintOutOp : Torch_Op<"aten.randint.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::randint.out : (int, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$high,
    TorchIntListType:$size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$high `,` $size `,` $out attr-dict `:` type($high) `,` type($size) `,` type($out) `->` type($result)";
}

def Torch_AtenRandintLowOutOp : Torch_Op<"aten.randint.low_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::randint.low_out : (int, int, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$low,
    Torch_IntType:$high,
    TorchIntListType:$size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$low `,` $high `,` $size `,` $out attr-dict `:` type($low) `,` type($high) `,` type($size) `,` type($out) `->` type($result)";
}

def Torch_AtenFractionalMaxPool3dBackwardOp : Torch_Op<"aten.fractional_max_pool3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool3d_backward : (Tensor, Tensor, int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $output_size `,` $indices attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($indices) `->` type($result)";
}

def Torch_AtenFractionalMaxPool3dBackwardGradInputOp : Torch_Op<"aten.fractional_max_pool3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool3d_backward.grad_input : (Tensor, Tensor, int[], int[], Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $output_size `,` $indices `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($indices) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenAnyOutOp : Torch_Op<"aten.any.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::any.out : (Tensor, int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenAnyAllOutOp : Torch_Op<"aten.any.all_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::any.all_out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenAnyDimnameOutOp : Torch_Op<"aten.any.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::any.dimname_out : (Tensor, str, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_Aten_SparseLogSoftmaxDimnameOp : Torch_Op<"aten._sparse_log_softmax.Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_log_softmax.Dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_SparseLogSoftmaxIntOp : Torch_Op<"aten._sparse_log_softmax.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_log_softmax.int : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_SparseLogSoftmaxOp : Torch_Op<"aten._sparse_log_softmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_log_softmax : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$half_to_float
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $half_to_float attr-dict `:` type($self) `,` type($dim) `,` type($half_to_float) `->` type($result)";
}

def Torch_AtenFftRfft2OutOp : Torch_Op<"aten.fft_rfft2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_rfft2.out : (Tensor, int[]?, int[], str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveAvgPool2dOutOp : Torch_Op<"aten.adaptive_avg_pool2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_avg_pool2d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($out) `->` type($result)";
}

def Torch_AtenTrilOutOp : Torch_Op<"aten.tril.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tril.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal `,` $out attr-dict `:` type($self) `,` type($diagonal) `,` type($out) `->` type($result)";
}

def Torch_AtenUpsampleNearest3dBackwardVecOp : Torch_Op<"aten.upsample_nearest3d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest3d_backward.vec : (Tensor, int[]?, int[], float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenUpsampleNearest3dBackwardOp : Torch_Op<"aten.upsample_nearest3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest3d_backward : (Tensor, int[], int[], float?, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scales_d `,` $scales_h `,` $scales_w attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleNearest3dBackwardGradInputOp : Torch_Op<"aten.upsample_nearest3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_nearest3d_backward.grad_input : (Tensor, int[], int[], float?, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scales_d `,` $scales_h `,` $scales_w `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenZero_Op : Torch_Op<"aten.zero_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::zero_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenStackOutOp : Torch_Op<"aten.stack.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::stack.out : (Tensor[], int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenLogitBackwardOp : Torch_Op<"aten.logit_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::logit_backward : (Tensor, Tensor, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $eps attr-dict `:` type($grad_output) `,` type($self) `,` type($eps) `->` type($result)";
}

def Torch_AtenLogitBackwardGradInputOp : Torch_Op<"aten.logit_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logit_backward.grad_input : (Tensor, Tensor, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $eps `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($eps) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenGluOutOp : Torch_Op<"aten.glu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::glu.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenClampOutOp : Torch_Op<"aten.clamp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp.out : (Tensor, Scalar?, Scalar?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$min,
    AnyTorchOptionalScalarType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max `,` $out attr-dict `:` type($self) `,` type($min) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenClampTensorOutOp : Torch_Op<"aten.clamp.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::clamp.Tensor_out : (Tensor, Tensor?, Tensor?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$min,
    AnyTorchOptionalTensorType:$max,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min `,` $max `,` $out attr-dict `:` type($self) `,` type($min) `,` type($max) `,` type($out) `->` type($result)";
}

def Torch_AtenRandpermOutOp : Torch_Op<"aten.randperm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::randperm.out : (int, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $out attr-dict `:` type($n) `,` type($out) `->` type($result)";
}

def Torch_Aten_DetLuBasedHelperOp : Torch_Op<"aten._det_lu_based_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_det_lu_based_helper : (Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$det,
    AnyTorchTensorType:$lu,
    AnyTorchTensorType:$pivs
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($det) `,` type($lu) `,` type($pivs)";
}

def Torch_Aten_SWhereOp : Torch_Op<"aten._s_where", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_s_where : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$condition,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$condition `,` $self `,` $other attr-dict `:` type($condition) `,` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten_ForeachSigmoid_Op : Torch_Op<"aten._foreach_sigmoid_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sigmoid_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenFftIrfftnOutOp : Torch_Op<"aten.fft_irfftn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_irfftn.out : (Tensor, int[]?, int[]?, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchOptionalIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveAvgPool3dOp : Torch_Op<"aten.adaptive_avg_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::adaptive_avg_pool3d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result)";
}

def Torch_AtenAdaptiveAvgPool3dOutOp : Torch_Op<"aten.adaptive_avg_pool3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_avg_pool3d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($out) `->` type($result)";
}

def Torch_AtenUpsampleTrilinear3dBackwardOp : Torch_Op<"aten.upsample_trilinear3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_trilinear3d_backward : (Tensor, int[], int[], bool, float?, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales_d `,` $scales_h `,` $scales_w attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleTrilinear3dBackwardGradInputOp : Torch_Op<"aten.upsample_trilinear3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_trilinear3d_backward.grad_input : (Tensor, int[], int[], bool, float?, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_d,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales_d `,` $scales_h `,` $scales_w `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales_d) `,` type($scales_h) `,` type($scales_w) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleTrilinear3dBackwardVecOp : Torch_Op<"aten.upsample_trilinear3d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_trilinear3d_backward.vec : (Tensor, int[]?, int[], bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_Aten_ConjPhysicalOp : Torch_Op<"aten._conj_physical", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_conj_physical : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_StandardGammaGradOp : Torch_Op<"aten._standard_gamma_grad", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_standard_gamma_grad : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$output
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output attr-dict `:` type($self) `,` type($output) `->` type($result)";
}

def Torch_Aten_SparseAddmmOp : Torch_Op<"aten._sparse_addmm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_addmm : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$sparse,
    AnyTorchTensorType:$dense,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $sparse `,` $dense `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($sparse) `,` type($dense) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenCeilOutOp : Torch_Op<"aten.ceil.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ceil.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenOutputNrOp : Torch_Op<"aten.output_nr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::output_nr : (Tensor) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenIsPinnedOp : Torch_Op<"aten.is_pinned", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_pinned : (Tensor, Device?) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalDeviceType:$device
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $device attr-dict `:` type($self) `,` type($device) `->` type($result)";
}

def Torch_AtenSizeDimnameOp : Torch_Op<"aten.size.Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::size.Dimname : (Tensor, str) -> (int)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    Torch_IntType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenSumDimnameListOutOp : Torch_Op<"aten.sum.DimnameList_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sum.DimnameList_out : (Tensor, str[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenSumIntListOutOp : Torch_Op<"aten.sum.IntList_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sum.IntList_out : (Tensor, int[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_Aten_AddBatchDimOp : Torch_Op<"aten._add_batch_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_add_batch_dim : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$batch_dim,
    Torch_IntType:$level
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch_dim `,` $level attr-dict `:` type($self) `,` type($batch_dim) `,` type($level) `->` type($result)";
}

def Torch_Aten_SparseCooTensorWithDimsOp : Torch_Op<"aten._sparse_coo_tensor_with_dims", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_coo_tensor_with_dims : (int, int, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$sparse_dim,
    Torch_IntType:$dense_dim,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sparse_dim `,` $dense_dim `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($sparse_dim) `,` type($dense_dim) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenMish_Op : Torch_Op<"aten.mish_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mish_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLinalgCholeskyOutOp : Torch_Op<"aten.linalg_cholesky.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_cholesky.out : (Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$upper,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $upper `,` $out attr-dict `:` type($self) `,` type($upper) `,` type($out) `->` type($result)";
}

def Torch_AtenSvdUOp : Torch_Op<"aten.svd.U", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::svd.U : (Tensor, bool, bool, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$some,
    Torch_BoolType:$compute_uv,
    AnyTorchTensorType:$U,
    AnyTorchTensorType:$S,
    AnyTorchTensorType:$V
  );
  let results = (outs
    AnyTorchTensorType:$res_U,
    AnyTorchTensorType:$res_S,
    AnyTorchTensorType:$res_V
  );
  let assemblyFormat = "$self `,` $some `,` $compute_uv `,` $U `,` $S `,` $V attr-dict `:` type($self) `,` type($some) `,` type($compute_uv) `,` type($U) `,` type($S) `,` type($V) `->` type($res_U) `,` type($res_S) `,` type($res_V)";
}

def Torch_Aten_MakeDualOp : Torch_Op<"aten._make_dual", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_make_dual : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$primal,
    AnyTorchTensorType:$tangent,
    Torch_IntType:$level
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$primal `,` $tangent `,` $level attr-dict `:` type($primal) `,` type($tangent) `,` type($level) `->` type($result)";
}

def Torch_Aten_SparseCooTensorUnsafeOp : Torch_Op<"aten._sparse_coo_tensor_unsafe", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_coo_tensor_unsafe : (Tensor, Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$values,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$indices `,` $values `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($indices) `,` type($values) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenFftHfftOutOp : Torch_Op<"aten.fft_hfft.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_hfft.out : (Tensor, int?, int, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenAdaptiveAvgPool3dBackwardGradInputOp : Torch_Op<"aten.adaptive_avg_pool3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::adaptive_avg_pool3d_backward.grad_input : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenLtScalarOutOp : Torch_Op<"aten.lt.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lt.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLtTensorOutOp : Torch_Op<"aten.lt.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lt.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenIsSameSizeOp : Torch_Op<"aten.is_same_size", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_same_size : (Tensor, Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten_EmptyAffineQuantizedOp : Torch_Op<"aten._empty_affine_quantized", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_empty_affine_quantized : (int[], int?, int?, Device?, bool?, float, int, int?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    Torch_FloatType:$scale,
    Torch_IntType:$zero_point,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $scale `,` $zero_point `,` $memory_format attr-dict `:` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($scale) `,` type($zero_point) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenSqrtOutOp : Torch_Op<"aten.sqrt.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sqrt.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenFill_TensorOp : Torch_Op<"aten.fill_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fill_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $value attr-dict `:` type($self) `,` type($value) `->` type($result)";
}

def Torch_AtenRoundOutOp : Torch_Op<"aten.round.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::round.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAsin_Op : Torch_Op<"aten._foreach_asin_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_asin_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenReciprocalOutOp : Torch_Op<"aten.reciprocal.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reciprocal.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_LinalgInvOutHelper_Op : Torch_Op<"aten._linalg_inv_out_helper_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_linalg_inv_out_helper_ : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$infos_lu,
    AnyTorchTensorType:$infos_getri
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $infos_lu `,` $infos_getri attr-dict `:` type($self) `,` type($infos_lu) `,` type($infos_getri) `->` type($result)";
}

def Torch_AtenLgammaOutOp : Torch_Op<"aten.lgamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lgamma.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenDetach_Op : Torch_Op<"aten.detach_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::detach_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_SobolEngineScramble_Op : Torch_Op<"aten._sobol_engine_scramble_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_sobol_engine_scramble_ : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$ltm,
    Torch_IntType:$dimension
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ltm `,` $dimension attr-dict `:` type($self) `,` type($ltm) `,` type($dimension) `->` type($result)";
}

def Torch_AtenLinalgEigvalshOutOp : Torch_Op<"aten.linalg_eigvalsh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_eigvalsh.out : (Tensor, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$UPLO,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $UPLO `,` $out attr-dict `:` type($self) `,` type($UPLO) `,` type($out) `->` type($result)";
}

def Torch_AtenEmbeddingRenorm_Op : Torch_Op<"aten.embedding_renorm_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::embedding_renorm_ : (Tensor, Tensor, float, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    Torch_FloatType:$max_norm,
    Torch_FloatType:$norm_type
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $max_norm `,` $norm_type attr-dict `:` type($self) `,` type($indices) `,` type($max_norm) `,` type($norm_type) `->` type($result)";
}

def Torch_AtenErf_Op : Torch_Op<"aten.erf_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::erf_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_ReshapeFromTensorOp : Torch_Op<"aten._reshape_from_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_reshape_from_tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$shape
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $shape attr-dict `:` type($self) `,` type($shape) `->` type($result)";
}

def Torch_AtenLogSigmoidOutOp : Torch_Op<"aten.log_sigmoid.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log_sigmoid.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_InverseHelperOp : Torch_Op<"aten._inverse_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_inverse_helper : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSet_SourceTensorOp : Torch_Op<"aten.set_.source_Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::set_.source_Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $source attr-dict `:` type($self) `,` type($source) `->` type($result)";
}

def Torch_AtenSet_Op : Torch_Op<"aten.set_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::set_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenDiagonalBackwardOp : Torch_Op<"aten.diagonal_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::diagonal_backward : (Tensor, int[], int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$input_sizes,
    Torch_IntType:$offset,
    Torch_IntType:$dim1,
    Torch_IntType:$dim2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $input_sizes `,` $offset `,` $dim1 `,` $dim2 attr-dict `:` type($grad_output) `,` type($input_sizes) `,` type($offset) `,` type($dim1) `,` type($dim2) `->` type($result)";
}

def Torch_Aten_SparseSumDimOp : Torch_Op<"aten._sparse_sum.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_sum.dim : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_Aten_SparseSumOp : Torch_Op<"aten._sparse_sum", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_sum : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_SparseSumDtypeOp : Torch_Op<"aten._sparse_sum.dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_sum.dtype : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_SparseSumDimDtypeOp : Torch_Op<"aten._sparse_sum.dim_dtype", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_sum.dim_dtype : (Tensor, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenLinalgEigOutOp : Torch_Op<"aten.linalg_eig.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_eig.out : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$eigenvectors
  );
  let results = (outs
    AnyTorchTensorType:$res_eigenvalues,
    AnyTorchTensorType:$res_eigenvectors
  );
  let assemblyFormat = "$self `,` $eigenvalues `,` $eigenvectors attr-dict `:` type($self) `,` type($eigenvalues) `,` type($eigenvectors) `->` type($res_eigenvalues) `,` type($res_eigenvectors)";
}

def Torch_AtenLogaddexp2OutOp : Torch_Op<"aten.logaddexp2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logaddexp2.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenMseLossOutOp : Torch_Op<"aten.mse_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mse_loss.out : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $out attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachMulScalarOp : Torch_Op<"aten._foreach_mul.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_mul.Scalar : (Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalar attr-dict `:` type($tensors) `,` type($scalar) `->` type($result)";
}

def Torch_Aten_ForeachMulListOp : Torch_Op<"aten._foreach_mul.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_mul.List : (Tensor[], Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors1,
    AnyTorchTensorListType:$tensors2
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors1 `,` $tensors2 attr-dict `:` type($tensors1) `,` type($tensors2) `->` type($result)";
}

def Torch_Aten_ForeachMulScalarListOp : Torch_Op<"aten._foreach_mul.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_mul.ScalarList : (Tensor[], Scalar[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalars attr-dict `:` type($tensors) `,` type($scalars) `->` type($result)";
}

def Torch_AtenEqScalarOutOp : Torch_Op<"aten.eq.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eq.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenEqTensorOutOp : Torch_Op<"aten.eq.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eq.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenIsComplexOp : Torch_Op<"aten.is_complex", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_complex : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenGtScalarOutOp : Torch_Op<"aten.gt.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gt.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGtTensorOutOp : Torch_Op<"aten.gt.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gt.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGeScalarOutOp : Torch_Op<"aten.ge.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ge.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGeTensorOutOp : Torch_Op<"aten.ge.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ge.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLeScalarOutOp : Torch_Op<"aten.le.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::le.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenLeTensorOutOp : Torch_Op<"aten.le.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::le.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenNeScalarOutOp : Torch_Op<"aten.ne.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ne.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenNeTensorOutOp : Torch_Op<"aten.ne.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ne.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBinaryCrossEntropyBackwardOp : Torch_Op<"aten.binary_cross_entropy_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::binary_cross_entropy_backward : (Tensor, Tensor, Tensor, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $reduction attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `->` type($result)";
}

def Torch_AtenBinaryCrossEntropyBackwardGradInputOp : Torch_Op<"aten.binary_cross_entropy_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::binary_cross_entropy_backward.grad_input : (Tensor, Tensor, Tensor, Tensor?, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $reduction `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenVdotOutOp : Torch_Op<"aten.vdot.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::vdot.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenCol2imOutOp : Torch_Op<"aten.col2im.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::col2im.out : (Tensor, int[], int[], int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $kernel_size `,` $dilation `,` $padding `,` $stride `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `,` type($out) `->` type($result)";
}

def Torch_Aten_UnsafeViewOp : Torch_Op<"aten._unsafe_view", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_unsafe_view : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size attr-dict `:` type($self) `,` type($size) `->` type($result)";
}

def Torch_AtenLinearOutOp : Torch_Op<"aten.linear.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linear.out : (Tensor, Tensor, Tensor?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $out attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($out) `->` type($result)";
}

def Torch_AtenNativeGroupNormOp : Torch_Op<"aten.native_group_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_group_norm : (Tensor, Tensor?, Tensor?, int, int, int, int, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    Torch_IntType:$N,
    Torch_IntType:$C,
    Torch_IntType:$HxW,
    Torch_IntType:$group,
    Torch_FloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $N `,` $C `,` $HxW `,` $group `,` $eps attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($N) `,` type($C) `,` type($HxW) `,` type($group) `,` type($eps) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenBaddbmm_Op : Torch_Op<"aten.baddbmm_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::baddbmm_ : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$batch1,
    AnyTorchTensorType:$batch2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch1 `,` $batch2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($batch1) `,` type($batch2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenAsStrided_Op : Torch_Op<"aten.as_strided_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::as_strided_ : (Tensor, int[], int[], int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$size,
    TorchIntListType:$stride,
    TorchOptionalIntType:$storage_offset
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $stride `,` $storage_offset attr-dict `:` type($self) `,` type($size) `,` type($stride) `,` type($storage_offset) `->` type($result)";
}

def Torch_AtenSqueeze_Op : Torch_Op<"aten.squeeze_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::squeeze_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSqueeze_DimOp : Torch_Op<"aten.squeeze_.dim", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::squeeze_.dim : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenSqueeze_DimnameOp : Torch_Op<"aten.squeeze_.dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::squeeze_.dimname : (Tensor, str) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenFftIrfft2OutOp : Torch_Op<"aten.fft_irfft2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_irfft2.out : (Tensor, int[]?, int[], str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntListType:$s,
    TorchIntListType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $s `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($s) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_Aten_SparseSoftmaxDimnameOp : Torch_Op<"aten._sparse_softmax.Dimname", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_softmax.Dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_SparseSoftmaxIntOp : Torch_Op<"aten._sparse_softmax.int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_softmax.int : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_SparseSoftmaxOp : Torch_Op<"aten._sparse_softmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_softmax : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$half_to_float
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $half_to_float attr-dict `:` type($self) `,` type($dim) `,` type($half_to_float) `->` type($result)";
}

def Torch_AtenArangeStartOutOp : Torch_Op<"aten.arange.start_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arange.start_out : (Scalar, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    AnyTorchScalarType:$step,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $step `,` $out attr-dict `:` type($start) `,` type($end) `,` type($step) `,` type($out) `->` type($result)";
}

def Torch_AtenArangeOutOp : Torch_Op<"aten.arange.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::arange.out : (Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$end,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$end `,` $out attr-dict `:` type($end) `,` type($out) `->` type($result)";
}

def Torch_AtenTranspose_Op : Torch_Op<"aten.transpose_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::transpose_ : (Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim0,
    Torch_IntType:$dim1
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim0 `,` $dim1 attr-dict `:` type($self) `,` type($dim0) `,` type($dim1) `->` type($result)";
}

def Torch_AtenT_Op : Torch_Op<"aten.t_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::t_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLogOutOp : Torch_Op<"aten.log.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_FftR2cOp : Torch_Op<"aten._fft_r2c", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fft_r2c : (Tensor, int[], int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$normalization,
    Torch_BoolType:$onesided
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $normalization `,` $onesided attr-dict `:` type($self) `,` type($dim) `,` type($normalization) `,` type($onesided) `->` type($result)";
}

def Torch_Aten_FftR2cOutOp : Torch_Op<"aten._fft_r2c.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_fft_r2c.out : (Tensor, int[], int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_IntType:$normalization,
    Torch_BoolType:$onesided,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $normalization `,` $onesided `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($normalization) `,` type($onesided) `,` type($out) `->` type($result)";
}

def Torch_AtenUnsqueeze_Op : Torch_Op<"aten.unsqueeze_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::unsqueeze_ : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_Aten_ForeachSigmoidOp : Torch_Op<"aten._foreach_sigmoid", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sigmoid : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenTraceBackwardOp : Torch_Op<"aten.trace_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::trace_backward : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    TorchIntListType:$sizes
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $sizes attr-dict `:` type($grad) `,` type($sizes) `->` type($result)";
}

def Torch_AtenAlphaDropout_Op : Torch_Op<"aten.alpha_dropout_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::alpha_dropout_ : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $train attr-dict `:` type($self) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenEmptyOutOp : Torch_Op<"aten.empty.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::empty.out : (int[], int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    TorchOptionalIntType:$memory_format,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $memory_format `,` $out attr-dict `:` type($size) `,` type($memory_format) `,` type($out) `->` type($result)";
}

def Torch_AtenAtanOutOp : Torch_Op<"aten.atan.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::atan.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenIsFloatingPointOp : Torch_Op<"aten.is_floating_point", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_floating_point : (Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenRequiresGrad_Op : Torch_Op<"aten.requires_grad_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::requires_grad_ : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$requires_grad
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $requires_grad attr-dict `:` type($self) `,` type($requires_grad) `->` type($result)";
}

def Torch_Aten_ForeachSinh_Op : Torch_Op<"aten._foreach_sinh_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sinh_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachAddcdivScalarOp : Torch_Op<"aten._foreach_addcdiv.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcdiv.Scalar : (Tensor[], Tensor[], Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$input,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$input `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($input) `,` type($tensor1) `,` type($tensor2) `,` type($value) `->` type($result)";
}

def Torch_Aten_ForeachAddcdivScalarListOp : Torch_Op<"aten._foreach_addcdiv.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcdiv.ScalarList : (Tensor[], Tensor[], Tensor[], Scalar[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$input,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$input `,` $tensor1 `,` $tensor2 `,` $scalars attr-dict `:` type($input) `,` type($tensor1) `,` type($tensor2) `,` type($scalars) `->` type($result)";
}

def Torch_Aten_AdaptiveAvgPool3dBackwardOp : Torch_Op<"aten._adaptive_avg_pool3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_adaptive_avg_pool3d_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_AtenCol2imBackwardOp : Torch_Op<"aten.col2im_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::col2im_backward : (Tensor, int[], int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $kernel_size `,` $dilation `,` $padding `,` $stride attr-dict `:` type($grad_output) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `->` type($result)";
}

def Torch_AtenCol2imBackwardGradInputOp : Torch_Op<"aten.col2im_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::col2im_backward.grad_input : (Tensor, int[], int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $kernel_size `,` $dilation `,` $padding `,` $stride `,` $grad_input attr-dict `:` type($grad_output) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenRandOutOp : Torch_Op<"aten.rand.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::rand.out : (int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $out attr-dict `:` type($size) `,` type($out) `->` type($result)";
}

def Torch_Aten_AdaptiveAvgPool3dOp : Torch_Op<"aten._adaptive_avg_pool3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_adaptive_avg_pool3d : (Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size attr-dict `:` type($self) `,` type($output_size) `->` type($result)";
}

def Torch_Aten_ConvolutionDeprecatedOp : Torch_Op<"aten._convolution.deprecated", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_convolution.deprecated : (Tensor, Tensor, Tensor?, int[], int[], int[], bool, int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$cudnn_enabled
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding `,` $groups `,` $benchmark `,` $deterministic `,` $cudnn_enabled attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($cudnn_enabled) `->` type($result)";
}

def Torch_Aten_ConvolutionOp : Torch_Op<"aten._convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_convolution : (Tensor, Tensor, Tensor?, int[], int[], int[], bool, int[], int, bool, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$cudnn_enabled,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding `,` $groups `,` $benchmark `,` $deterministic `,` $cudnn_enabled `,` $allow_tf32 attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($cudnn_enabled) `,` type($allow_tf32) `->` type($result)";
}

def Torch_AtenRandnOutOp : Torch_Op<"aten.randn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::randn.out : (int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $out attr-dict `:` type($size) `,` type($out) `->` type($result)";
}

def Torch_AtenTanhBackwardGradInputOp : Torch_Op<"aten.tanh_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tanh_backward.grad_input : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $grad_input attr-dict `:` type($grad_output) `,` type($output) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_ConvolutionNogroupOp : Torch_Op<"aten._convolution_nogroup", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_convolution_nogroup : (Tensor, Tensor, Tensor?, int[], int[], int[], bool, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `->` type($result)";
}

def Torch_AtenLogicalOr_Op : Torch_Op<"aten.logical_or_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logical_or_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenConvTranspose2dInputOp : Torch_Op<"aten.conv_transpose2d.input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_transpose2d.input : (Tensor, Tensor, Tensor?, int[], int[], int[], int, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $groups `,` $dilation attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($groups) `,` type($dilation) `->` type($result)";
}

def Torch_Aten_ThnnFusedLstmCellOp : Torch_Op<"aten._thnn_fused_lstm_cell", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_thnn_fused_lstm_cell : (Tensor, Tensor, Tensor, Tensor?, Tensor?) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input_gates,
    AnyTorchTensorType:$hidden_gates,
    AnyTorchTensorType:$cx,
    AnyTorchOptionalTensorType:$input_bias,
    AnyTorchOptionalTensorType:$hidden_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input_gates `,` $hidden_gates `,` $cx `,` $input_bias `,` $hidden_bias attr-dict `:` type($input_gates) `,` type($hidden_gates) `,` type($cx) `,` type($input_bias) `,` type($hidden_bias) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenErfinvOutOp : Torch_Op<"aten.erfinv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::erfinv.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenConvTranspose3dInputOp : Torch_Op<"aten.conv_transpose3d.input", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::conv_transpose3d.input : (Tensor, Tensor, Tensor?, int[], int[], int[], int, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $groups `,` $dilation attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($groups) `,` type($dilation) `->` type($result)";
}

def Torch_AtenSetDataOp : Torch_Op<"aten.set_data", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::set_data : (Tensor, Tensor) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$new_data
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $new_data attr-dict `:` type($self) `,` type($new_data)";
}

def Torch_AtenCopysignOutOp : Torch_Op<"aten.copysign.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::copysign.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenCopysignScalarOutOp : Torch_Op<"aten.copysign.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::copysign.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenCudnnConvolutionDeprecatedOp : Torch_Op<"aten.cudnn_convolution.deprecated", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution.deprecated : (Tensor, Tensor, Tensor?, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenCudnnConvolutionDeprecated2Op : Torch_Op<"aten.cudnn_convolution.deprecated2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution.deprecated2 : (Tensor, Tensor, int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenCudnnConvolutionOp : Torch_Op<"aten.cudnn_convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution : (Tensor, Tensor, int[], int[], int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 attr-dict `:` type($self) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `->` type($result)";
}

def Torch_AtenCudnnConvolutionTransposeDeprecatedOp : Torch_Op<"aten.cudnn_convolution_transpose.deprecated", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_transpose.deprecated : (Tensor, Tensor, Tensor?, int[], int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $padding `,` $output_padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($output_padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenCudnnConvolutionTransposeDeprecated2Op : Torch_Op<"aten.cudnn_convolution_transpose.deprecated2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_transpose.deprecated2 : (Tensor, Tensor, int[], int[], int[], int[], int, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $padding `,` $output_padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic attr-dict `:` type($self) `,` type($weight) `,` type($padding) `,` type($output_padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `->` type($result)";
}

def Torch_AtenCudnnConvolutionTransposeOp : Torch_Op<"aten.cudnn_convolution_transpose", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::cudnn_convolution_transpose : (Tensor, Tensor, int[], int[], int[], int[], int, bool, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    Torch_BoolType:$benchmark,
    Torch_BoolType:$deterministic,
    Torch_BoolType:$allow_tf32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $padding `,` $output_padding `,` $stride `,` $dilation `,` $groups `,` $benchmark `,` $deterministic `,` $allow_tf32 attr-dict `:` type($self) `,` type($weight) `,` type($padding) `,` type($output_padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($benchmark) `,` type($deterministic) `,` type($allow_tf32) `->` type($result)";
}

def Torch_Aten_ForeachMinimumListOp : Torch_Op<"aten._foreach_minimum.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_minimum.List : (Tensor[], Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors1,
    AnyTorchTensorListType:$tensors2
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors1 `,` $tensors2 attr-dict `:` type($tensors1) `,` type($tensors2) `->` type($result)";
}

def Torch_AtenThresholdOutOp : Torch_Op<"aten.threshold.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::threshold.out : (Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$threshold,
    AnyTorchScalarType:$value,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $threshold `,` $value `,` $out attr-dict `:` type($self) `,` type($threshold) `,` type($value) `,` type($out) `->` type($result)";
}

def Torch_AtenFftFftOutOp : Torch_Op<"aten.fft_fft.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_fft.out : (Tensor, int?, int, str?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$n,
    Torch_IntType:$dim,
    TorchOptionalStringType:$norm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $dim `,` $norm `,` $out attr-dict `:` type($self) `,` type($n) `,` type($dim) `,` type($norm) `,` type($out) `->` type($result)";
}

def Torch_AtenMatmulOutOp : Torch_Op<"aten.matmul.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::matmul.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenRenormOutOp : Torch_Op<"aten.renorm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::renorm.out : (Tensor, Scalar, int, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$p,
    Torch_IntType:$dim,
    AnyTorchScalarType:$maxnorm,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $maxnorm `,` $out attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($maxnorm) `,` type($out) `->` type($result)";
}

def Torch_AtenChainMatmulOutOp : Torch_Op<"aten.chain_matmul.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::chain_matmul.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$matrices,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$matrices `,` $out attr-dict `:` type($matrices) `,` type($out) `->` type($result)";
}

def Torch_AtenSymeigEOp : Torch_Op<"aten.symeig.e", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::symeig.e : (Tensor, bool, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$eigenvectors,
    Torch_BoolType:$upper,
    AnyTorchTensorType:$e,
    AnyTorchTensorType:$V
  );
  let results = (outs
    AnyTorchTensorType:$eigenvalues,
    AnyTorchTensorType:$res_eigenvectors
  );
  let assemblyFormat = "$self `,` $eigenvectors `,` $upper `,` $e `,` $V attr-dict `:` type($self) `,` type($eigenvectors) `,` type($upper) `,` type($e) `,` type($V) `->` type($eigenvalues) `,` type($res_eigenvectors)";
}

def Torch_Aten_SparseCsrTensorUnsafeOp : Torch_Op<"aten._sparse_csr_tensor_unsafe", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_csr_tensor_unsafe : (Tensor, Tensor, Tensor, int[], int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$crow_indices,
    AnyTorchTensorType:$col_indices,
    AnyTorchTensorType:$values,
    TorchIntListType:$size,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$crow_indices `,` $col_indices `,` $values `,` $size `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($crow_indices) `,` type($col_indices) `,` type($values) `,` type($size) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_Aten_RemoveBatchDimOp : Torch_Op<"aten._remove_batch_dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_remove_batch_dim : (Tensor, int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$level,
    Torch_IntType:$batch_size,
    Torch_IntType:$out_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $level `,` $batch_size `,` $out_dim attr-dict `:` type($self) `,` type($level) `,` type($batch_size) `,` type($out_dim) `->` type($result)";
}

def Torch_Aten_SparseCooTensorWithDimsAndTensorsOp : Torch_Op<"aten._sparse_coo_tensor_with_dims_and_tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sparse_coo_tensor_with_dims_and_tensors : (int, int, int[], Tensor, Tensor, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$sparse_dim,
    Torch_IntType:$dense_dim,
    TorchIntListType:$size,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$values,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$sparse_dim `,` $dense_dim `,` $size `,` $indices `,` $values `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($sparse_dim) `,` type($dense_dim) `,` type($size) `,` type($indices) `,` type($values) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_AtenSoftplusOutOp : Torch_Op<"aten.softplus.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::softplus.out : (Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$threshold,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $beta `,` $threshold `,` $out attr-dict `:` type($self) `,` type($beta) `,` type($threshold) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgMultiDotOutOp : Torch_Op<"aten.linalg_multi_dot.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_multi_dot.out : (Tensor[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $out attr-dict `:` type($tensors) `,` type($out) `->` type($result)";
}

def Torch_AtenI0OutOp : Torch_Op<"aten.i0.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::i0.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachCeil_Op : Torch_Op<"aten._foreach_ceil_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_ceil_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenFrobeniusNormOutOp : Torch_Op<"aten.frobenius_norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::frobenius_norm.out : (Tensor, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_Aten_TrilinearOp : Torch_Op<"aten._trilinear", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_trilinear : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$i1,
    AnyTorchTensorType:$i2,
    AnyTorchTensorType:$i3,
    TorchIntListType:$expand1,
    TorchIntListType:$expand2,
    TorchIntListType:$expand3,
    TorchIntListType:$sumdim,
    Torch_IntType:$unroll_dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$i1 `,` $i2 `,` $i3 `,` $expand1 `,` $expand2 `,` $expand3 `,` $sumdim `,` $unroll_dim attr-dict `:` type($i1) `,` type($i2) `,` type($i3) `,` type($expand1) `,` type($expand2) `,` type($expand3) `,` type($sumdim) `,` type($unroll_dim) `->` type($result)";
}

def Torch_AtenDropout_Op : Torch_Op<"aten.dropout_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::dropout_ : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $train attr-dict `:` type($self) `,` type($p) `,` type($train) `->` type($result)";
}

def Torch_AtenNllLossOutOp : Torch_Op<"aten.nll_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nll_loss.out : (Tensor, Tensor, Tensor?, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $out attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachNegOp : Torch_Op<"aten._foreach_neg", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_neg : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenHardswishOutOp : Torch_Op<"aten.hardswish.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardswish.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenNllLoss2dOutOp : Torch_Op<"aten.nll_loss2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nll_loss2d.out : (Tensor, Tensor, Tensor?, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $out attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachNeg_Op : Torch_Op<"aten._foreach_neg_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_neg_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenSmoothL1LossOutOp : Torch_Op<"aten.smooth_l1_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::smooth_l1_loss.out : (Tensor, Tensor, int, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$beta,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $beta `,` $out attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($beta) `,` type($out) `->` type($result)";
}

def Torch_AtenHuberLossOutOp : Torch_Op<"aten.huber_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::huber_loss.out : (Tensor, Tensor, int, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$delta,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $delta `,` $out attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($delta) `,` type($out) `->` type($result)";
}

def Torch_AtenSoftMarginLossOutOp : Torch_Op<"aten.soft_margin_loss.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::soft_margin_loss.out : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $target `,` $reduction `,` $out attr-dict `:` type($self) `,` type($target) `,` type($reduction) `,` type($out) `->` type($result)";
}

def Torch_AtenAddcmul_Op : Torch_Op<"aten.addcmul_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addcmul_ : (Tensor, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor1,
    AnyTorchTensorType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value) `->` type($result)";
}

def Torch_AtenProdDimnameOutOp : Torch_Op<"aten.prod.Dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::prod.Dimname_out : (Tensor, str, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenProdIntOutOp : Torch_Op<"aten.prod.int_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::prod.int_out : (Tensor, int, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_Aten_ConvertIndicesFromCooToCsrOp : Torch_Op<"aten._convert_indices_from_coo_to_csr", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_convert_indices_from_coo_to_csr : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$size,
    Torch_BoolType:$out_int32
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $out_int32 attr-dict `:` type($self) `,` type($size) `,` type($out_int32) `->` type($result)";
}

def Torch_Aten_ConvertIndicesFromCooToCsrOutOp : Torch_Op<"aten._convert_indices_from_coo_to_csr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_convert_indices_from_coo_to_csr.out : (Tensor, int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$size,
    Torch_BoolType:$out_int32,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $size `,` $out_int32 `,` $out attr-dict `:` type($self) `,` type($size) `,` type($out_int32) `,` type($out) `->` type($result)";
}

def Torch_AtenCumprodDimnameOutOp : Torch_Op<"aten.cumprod.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumprod.dimname_out : (Tensor, str, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenCumprodOutOp : Torch_Op<"aten.cumprod.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumprod.out : (Tensor, int, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenCrossOutOp : Torch_Op<"aten.cross.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cross.out : (Tensor, Tensor, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    TorchOptionalIntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $dim `,` $out attr-dict `:` type($self) `,` type($other) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_AtenCumsumDimnameOutOp : Torch_Op<"aten.cumsum.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumsum.dimname_out : (Tensor, str, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenCumsumOutOp : Torch_Op<"aten.cumsum.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumsum.out : (Tensor, int, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenNormDtypeOutOp : Torch_Op<"aten.norm.dtype_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::norm.dtype_out : (Tensor, Scalar?, int[], bool, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    Torch_IntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenNormOutOp : Torch_Op<"aten.norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::norm.out : (Tensor, Scalar?, int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_AtenNormNamesDtypeOutOp : Torch_Op<"aten.norm.names_dtype_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::norm.names_dtype_out : (Tensor, Scalar?, str[], bool, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    Torch_IntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_AtenNormNamesOutOp : Torch_Op<"aten.norm.names_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::norm.names_out : (Tensor, Scalar?, str[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalScalarType:$p,
    TorchStringListType:$dim,
    Torch_BoolType:$keepdim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $keepdim `,` $out attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($keepdim) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachSin_Op : Torch_Op<"aten._foreach_sin_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sin_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenFrexpTensorOutOp : Torch_Op<"aten.frexp.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::frexp.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mantissa,
    AnyTorchTensorType:$exponent
  );
  let results = (outs
    AnyTorchTensorType:$res_mantissa,
    AnyTorchTensorType:$res_exponent
  );
  let assemblyFormat = "$self `,` $mantissa `,` $exponent attr-dict `:` type($self) `,` type($mantissa) `,` type($exponent) `->` type($res_mantissa) `,` type($res_exponent)";
}

def Torch_AtenEluBackwardOp : Torch_Op<"aten.elu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::elu_backward : (Tensor, Scalar, Scalar, Scalar, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchScalarType:$alpha,
    AnyTorchScalarType:$scale,
    AnyTorchScalarType:$input_scale,
    Torch_BoolType:$is_result,
    AnyTorchTensorType:$self_or_result
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $alpha `,` $scale `,` $input_scale `,` $is_result `,` $self_or_result attr-dict `:` type($grad_output) `,` type($alpha) `,` type($scale) `,` type($input_scale) `,` type($is_result) `,` type($self_or_result) `->` type($result)";
}

def Torch_AtenEluBackwardGradInputOp : Torch_Op<"aten.elu_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::elu_backward.grad_input : (Tensor, Scalar, Scalar, Scalar, bool, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchScalarType:$alpha,
    AnyTorchScalarType:$scale,
    AnyTorchScalarType:$input_scale,
    Torch_BoolType:$is_result,
    AnyTorchTensorType:$self_or_result,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $alpha `,` $scale `,` $input_scale `,` $is_result `,` $self_or_result `,` $grad_input attr-dict `:` type($grad_output) `,` type($alpha) `,` type($scale) `,` type($input_scale) `,` type($is_result) `,` type($self_or_result) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenEmbeddingDenseBackwardOp : Torch_Op<"aten.embedding_dense_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::embedding_dense_backward : (Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$indices,
    Torch_IntType:$num_weights,
    Torch_IntType:$padding_idx,
    Torch_BoolType:$scale_grad_by_freq
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $indices `,` $num_weights `,` $padding_idx `,` $scale_grad_by_freq attr-dict `:` type($grad_output) `,` type($indices) `,` type($num_weights) `,` type($padding_idx) `,` type($scale_grad_by_freq) `->` type($result)";
}

def Torch_AtenSpecialEntrOutOp : Torch_Op<"aten.special_entr.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_entr.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenEyeOutOp : Torch_Op<"aten.eye.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eye.out : (int, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $out attr-dict `:` type($n) `,` type($out) `->` type($result)";
}

def Torch_AtenEyeMOutOp : Torch_Op<"aten.eye.m_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::eye.m_out : (int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    Torch_IntType:$m,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $m `,` $out attr-dict `:` type($n) `,` type($m) `,` type($out) `->` type($result)";
}

def Torch_AtenFmod_TensorOp : Torch_Op<"aten.fmod_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fmod_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenFmaxOutOp : Torch_Op<"aten.fmax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fmax.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenFminOutOp : Torch_Op<"aten.fmin.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fmin.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenFractionalMaxPool2dBackwardOp : Torch_Op<"aten.fractional_max_pool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool2d_backward : (Tensor, Tensor, int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $output_size `,` $indices attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($indices) `->` type($result)";
}

def Torch_AtenFractionalMaxPool2dBackwardGradInputOp : Torch_Op<"aten.fractional_max_pool2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fractional_max_pool2d_backward.grad_input : (Tensor, Tensor, int[], int[], Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $output_size `,` $indices `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($output_size) `,` type($indices) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenFullOutOp : Torch_Op<"aten.full.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::full.out : (int[], Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchScalarType:$fill_value,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $fill_value `,` $out attr-dict `:` type($size) `,` type($fill_value) `,` type($out) `->` type($result)";
}

def Torch_AtenGatherOutOp : Torch_Op<"aten.gather.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gather.out : (Tensor, int, Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    Torch_BoolType:$sparse_grad,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $sparse_grad `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($sparse_grad) `,` type($out) `->` type($result)";
}

def Torch_AtenGatherDimnameOutOp : Torch_Op<"aten.gather.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gather.dimname_out : (Tensor, str, Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    Torch_BoolType:$sparse_grad,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $sparse_grad `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($sparse_grad) `,` type($out) `->` type($result)";
}

def Torch_AtenGcdOutOp : Torch_Op<"aten.gcd.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gcd.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenGeluBackwardGradInputOp : Torch_Op<"aten.gelu_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gelu_backward.grad_input : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self `,` $grad_input attr-dict `:` type($grad) `,` type($self) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenGluBackwardOp : Torch_Op<"aten.glu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::glu_backward : (Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $dim attr-dict `:` type($grad_output) `,` type($self) `,` type($dim) `->` type($result)";
}

def Torch_AtenGluBackwardGradInputOp : Torch_Op<"aten.glu_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::glu_backward.grad_input : (Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $dim `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($dim) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenGridSampler2dBackwardOp : Torch_Op<"aten.grid_sampler_2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::grid_sampler_2d_backward : (Tensor, Tensor, Tensor, int, int, bool, bool[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_output `,` $input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners `,` $output_mask attr-dict `:` type($grad_output) `,` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `,` type($output_mask) `->` type($result0) `,` type($result1)";
}

def Torch_AtenGridSampler3dBackwardOp : Torch_Op<"aten.grid_sampler_3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::grid_sampler_3d_backward : (Tensor, Tensor, Tensor, int, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_output `,` $input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners attr-dict `:` type($grad_output) `,` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `->` type($result0) `,` type($result1)";
}

def Torch_AtenHardshrinkBackwardOp : Torch_Op<"aten.hardshrink_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardshrink_backward : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_out `,` $self `,` $lambd attr-dict `:` type($grad_out) `,` type($self) `,` type($lambd) `->` type($result)";
}

def Torch_AtenHardshrinkBackwardGradInputOp : Torch_Op<"aten.hardshrink_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardshrink_backward.grad_input : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_out `,` $self `,` $lambd `,` $grad_input attr-dict `:` type($grad_out) `,` type($self) `,` type($lambd) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenHardsigmoidBackwardOp : Torch_Op<"aten.hardsigmoid_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardsigmoid_backward : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self attr-dict `:` type($grad_output) `,` type($self) `->` type($result)";
}

def Torch_AtenHardsigmoidBackwardGradInputOp : Torch_Op<"aten.hardsigmoid_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardsigmoid_backward.grad_input : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenHardtanhOutOp : Torch_Op<"aten.hardtanh.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardtanh.out : (Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min_val,
    AnyTorchScalarType:$max_val,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min_val `,` $max_val `,` $out attr-dict `:` type($self) `,` type($min_val) `,` type($max_val) `,` type($out) `->` type($result)";
}

def Torch_AtenHardtanhBackwardOp : Torch_Op<"aten.hardtanh_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::hardtanh_backward : (Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min_val,
    AnyTorchScalarType:$max_val
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $min_val `,` $max_val attr-dict `:` type($grad_output) `,` type($self) `,` type($min_val) `,` type($max_val) `->` type($result)";
}

def Torch_AtenHardtanhBackwardGradInputOp : Torch_Op<"aten.hardtanh_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardtanh_backward.grad_input : (Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min_val,
    AnyTorchScalarType:$max_val,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $min_val `,` $max_val `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($min_val) `,` type($max_val) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenHeavisideOutOp : Torch_Op<"aten.heaviside.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::heaviside.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $values `,` $out attr-dict `:` type($self) `,` type($values) `,` type($out) `->` type($result)";
}

def Torch_AtenHistogramBinsTensorOutOp : Torch_Op<"aten.histogram.bins_tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::histogram.bins_tensor_out : (Tensor, Tensor, Tensor?, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$bins,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density,
    AnyTorchTensorType:$hist,
    AnyTorchTensorType:$bin_edges
  );
  let results = (outs
    AnyTorchTensorType:$res_hist,
    AnyTorchTensorType:$res_bin_edges
  );
  let assemblyFormat = "$self `,` $bins `,` $weight `,` $density `,` $hist `,` $bin_edges attr-dict `:` type($self) `,` type($bins) `,` type($weight) `,` type($density) `,` type($hist) `,` type($bin_edges) `->` type($res_hist) `,` type($res_bin_edges)";
}

def Torch_AtenHistogramBinCtOutOp : Torch_Op<"aten.histogram.bin_ct_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::histogram.bin_ct_out : (Tensor, int, float[]?, Tensor?, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$bins,
    TorchOptionalFloatListType:$range,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density,
    AnyTorchTensorType:$hist,
    AnyTorchTensorType:$bin_edges
  );
  let results = (outs
    AnyTorchTensorType:$res_hist,
    AnyTorchTensorType:$res_bin_edges
  );
  let assemblyFormat = "$self `,` $bins `,` $range `,` $weight `,` $density `,` $hist `,` $bin_edges attr-dict `:` type($self) `,` type($bins) `,` type($range) `,` type($weight) `,` type($density) `,` type($hist) `,` type($bin_edges) `->` type($res_hist) `,` type($res_bin_edges)";
}

def Torch_AtenIndexSelectOutOp : Torch_Op<"aten.index_select.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_select.out : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($out) `->` type($result)";
}

def Torch_AtenIndexSelectDimnameOutOp : Torch_Op<"aten.index_select.dimname_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_select.dimname_out : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($out) `->` type($result)";
}

def Torch_Aten_CudnnInitDropoutStateOp : Torch_Op<"aten._cudnn_init_dropout_state", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cudnn_init_dropout_state : (float, bool, int, int?, int?, Device?, bool?) -> (Tensor)`";
  let arguments = (ins
    Torch_FloatType:$dropout,
    Torch_BoolType:$train,
    Torch_IntType:$dropout_seed,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$dropout `,` $train `,` $dropout_seed `,` $dtype `,` $layout `,` $device `,` $pin_memory attr-dict `:` type($dropout) `,` type($train) `,` type($dropout_seed) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `->` type($result)";
}

def Torch_Aten_EmptyPerChannelAffineQuantizedOp : Torch_Op<"aten._empty_per_channel_affine_quantized", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_empty_per_channel_affine_quantized : (int[], Tensor, Tensor, int, int?, int?, Device?, bool?, int?) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchTensorType:$scales,
    AnyTorchTensorType:$zero_points,
    Torch_IntType:$axis,
    TorchOptionalIntType:$dtype,
    TorchOptionalIntType:$layout,
    TorchOptionalDeviceType:$device,
    TorchOptionalBoolType:$pin_memory,
    TorchOptionalIntType:$memory_format
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $scales `,` $zero_points `,` $axis `,` $dtype `,` $layout `,` $device `,` $pin_memory `,` $memory_format attr-dict `:` type($size) `,` type($scales) `,` type($zero_points) `,` type($axis) `,` type($dtype) `,` type($layout) `,` type($device) `,` type($pin_memory) `,` type($memory_format) `->` type($result)";
}

def Torch_AtenIsSetToOp : Torch_Op<"aten.is_set_to", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::is_set_to : (Tensor, Tensor) -> (bool)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$tensor
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = "$self `,` $tensor attr-dict `:` type($self) `,` type($tensor) `->` type($result)";
}

def Torch_Aten_AssertAsyncOp : Torch_Op<"aten._assert_async", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_assert_async : (Tensor) -> ()`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenLinspaceOutOp : Torch_Op<"aten.linspace.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linspace.out : (Scalar, Scalar, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$steps,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $steps `,` $out attr-dict `:` type($start) `,` type($end) `,` type($steps) `,` type($out) `->` type($result)";
}

def Torch_AtenNativeGroupNormBackwardOp : Torch_Op<"aten.native_group_norm_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_group_norm_backward : (Tensor, Tensor, Tensor, Tensor, Tensor?, int, int, int, int, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$rstd,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$N,
    Torch_IntType:$C,
    Torch_IntType:$HxW,
    Torch_IntType:$group,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_out `,` $input `,` $mean `,` $rstd `,` $weight `,` $N `,` $C `,` $HxW `,` $group `,` $output_mask attr-dict `:` type($grad_out) `,` type($input) `,` type($mean) `,` type($rstd) `,` type($weight) `,` type($N) `,` type($C) `,` type($HxW) `,` type($group) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenLogspaceOutOp : Torch_Op<"aten.logspace.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logspace.out : (Scalar, Scalar, int?, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    TorchOptionalIntType:$steps,
    Torch_FloatType:$base,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $steps `,` $base `,` $out attr-dict `:` type($start) `,` type($end) `,` type($steps) `,` type($base) `,` type($out) `->` type($result)";
}

def Torch_Aten_CdistBackwardOp : Torch_Op<"aten._cdist_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cdist_backward : (Tensor, Tensor, Tensor, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$x1,
    AnyTorchTensorType:$x2,
    Torch_FloatType:$p,
    AnyTorchTensorType:$cdist
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $x1 `,` $x2 `,` $p `,` $cdist attr-dict `:` type($grad) `,` type($x1) `,` type($x2) `,` type($p) `,` type($cdist) `->` type($result)";
}

def Torch_AtenOnesOutOp : Torch_Op<"aten.ones.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ones.out : (int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $out attr-dict `:` type($size) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLgammaOp : Torch_Op<"aten._foreach_lgamma", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_lgamma : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenRangeOutOp : Torch_Op<"aten.range.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::range.out : (Scalar, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$start,
    AnyTorchScalarType:$end,
    AnyTorchScalarType:$step,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$start `,` $end `,` $step `,` $out attr-dict `:` type($start) `,` type($end) `,` type($step) `,` type($out) `->` type($result)";
}

def Torch_Aten_DetLuBasedHelperBackwardHelperOp : Torch_Op<"aten._det_lu_based_helper_backward_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_det_lu_based_helper_backward_helper : (Tensor, Tensor, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$det_grad,
    AnyTorchTensorType:$det,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$lu,
    AnyTorchTensorType:$pivs
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$det_grad `,` $det `,` $self `,` $lu `,` $pivs attr-dict `:` type($det_grad) `,` type($det) `,` type($self) `,` type($lu) `,` type($pivs) `->` type($result)";
}

def Torch_AtenZerosOutOp : Torch_Op<"aten.zeros.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::zeros.out : (int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    TorchIntListType:$size,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$size `,` $out attr-dict `:` type($size) `,` type($out) `->` type($result)";
}

def Torch_AtenFftFftfreqOutOp : Torch_Op<"aten.fft_fftfreq.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_fftfreq.out : (int, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    Torch_FloatType:$d,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $d `,` $out attr-dict `:` type($n) `,` type($d) `,` type($out) `->` type($result)";
}

def Torch_AtenFftRfftfreqOutOp : Torch_Op<"aten.fft_rfftfreq.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::fft_rfftfreq.out : (int, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    Torch_IntType:$n,
    Torch_FloatType:$d,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$n `,` $d `,` $out attr-dict `:` type($n) `,` type($d) `,` type($out) `->` type($result)";
}

def Torch_AtenIsposinfOutOp : Torch_Op<"aten.isposinf.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::isposinf.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_PinMemoryOp : Torch_Op<"aten._pin_memory", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_pin_memory : (Tensor, Device?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalDeviceType:$device
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $device attr-dict `:` type($self) `,` type($device) `->` type($result)";
}

def Torch_AtenIsneginfOutOp : Torch_Op<"aten.isneginf.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::isneginf.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSgnOutOp : Torch_Op<"aten.sgn.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sgn.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenCopysign_TensorOp : Torch_Op<"aten.copysign_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::copysign_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenCopysign_ScalarOp : Torch_Op<"aten.copysign_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::copysign_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenKlDivBackwardOp : Torch_Op<"aten.kl_div_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::kl_div_backward : (Tensor, Tensor, Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_BoolType:$log_target
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $log_target attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($log_target) `->` type($result)";
}

def Torch_AtenCumprod_Op : Torch_Op<"aten.cumprod_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumprod_ : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenCumprod_DimnameOp : Torch_Op<"aten.cumprod_.dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumprod_.dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenL1LossBackwardGradInputOp : Torch_Op<"aten.l1_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::l1_loss_backward.grad_input : (Tensor, Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenL1LossBackwardOp : Torch_Op<"aten.l1_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::l1_loss_backward : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenCumsum_Op : Torch_Op<"aten.cumsum_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumsum_ : (Tensor, int, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_AtenCumsum_DimnameOp : Torch_Op<"aten.cumsum_.dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::cumsum_.dimname : (Tensor, str, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $dtype attr-dict `:` type($self) `,` type($dim) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_CtcLossOp : Torch_Op<"aten._ctc_loss", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_ctc_loss : (Tensor, Tensor, int[], int[], int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$log_probs,
    AnyTorchTensorType:$targets,
    TorchIntListType:$input_lengths,
    TorchIntListType:$target_lengths,
    Torch_IntType:$blank,
    Torch_BoolType:$zero_infinity
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$log_probs `,` $targets `,` $input_lengths `,` $target_lengths `,` $blank `,` $zero_infinity attr-dict `:` type($log_probs) `,` type($targets) `,` type($input_lengths) `,` type($target_lengths) `,` type($blank) `,` type($zero_infinity) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_CtcLossBackwardOp : Torch_Op<"aten._ctc_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_ctc_loss_backward : (Tensor, Tensor, Tensor, int[], int[], Tensor, Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$log_probs,
    AnyTorchTensorType:$targets,
    TorchIntListType:$input_lengths,
    TorchIntListType:$target_lengths,
    AnyTorchTensorType:$neg_log_likelihood,
    AnyTorchTensorType:$log_alpha,
    Torch_IntType:$blank,
    Torch_BoolType:$zero_infinity
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $log_probs `,` $targets `,` $input_lengths `,` $target_lengths `,` $neg_log_likelihood `,` $log_alpha `,` $blank `,` $zero_infinity attr-dict `:` type($grad) `,` type($log_probs) `,` type($targets) `,` type($input_lengths) `,` type($target_lengths) `,` type($neg_log_likelihood) `,` type($log_alpha) `,` type($blank) `,` type($zero_infinity) `->` type($result)";
}

def Torch_Aten_EmbeddingBagForwardOnlyOp : Torch_Op<"aten._embedding_bag_forward_only", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_embedding_bag_forward_only : (Tensor, Tensor, Tensor, bool, int, bool, Tensor?, bool, int) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    Torch_BoolType:$sparse,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_BoolType:$include_last_offset,
    Torch_IntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3
  );
  let assemblyFormat = "$weight `,` $indices `,` $offsets `,` $scale_grad_by_freq `,` $mode `,` $sparse `,` $per_sample_weights `,` $include_last_offset `,` $padding_idx attr-dict `:` type($weight) `,` type($indices) `,` type($offsets) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($sparse) `,` type($per_sample_weights) `,` type($include_last_offset) `,` type($padding_idx) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_AtenLcmOutOp : Torch_Op<"aten.lcm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lcm.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_EmbeddingBagOp : Torch_Op<"aten._embedding_bag", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_embedding_bag : (Tensor, Tensor, Tensor, bool, int, bool, Tensor?, bool, int) -> (Tensor, Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    Torch_BoolType:$sparse,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_BoolType:$include_last_offset,
    Torch_IntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2,
    AnyTorchTensorType:$result3
  );
  let assemblyFormat = "$weight `,` $indices `,` $offsets `,` $scale_grad_by_freq `,` $mode `,` $sparse `,` $per_sample_weights `,` $include_last_offset `,` $padding_idx attr-dict `:` type($weight) `,` type($indices) `,` type($offsets) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($sparse) `,` type($per_sample_weights) `,` type($include_last_offset) `,` type($padding_idx) `->` type($result0) `,` type($result1) `,` type($result2) `,` type($result3)";
}

def Torch_Aten_EmbeddingBagDenseBackwardOp : Torch_Op<"aten._embedding_bag_dense_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_embedding_bag_dense_backward : (Tensor, Tensor, Tensor, Tensor, Tensor, int, bool, int, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offset2bag,
    AnyTorchTensorType:$bag_size,
    AnyTorchTensorType:$maximum_indices,
    Torch_IntType:$num_weights,
    Torch_BoolType:$scale_grad_by_freq,
    Torch_IntType:$mode,
    AnyTorchOptionalTensorType:$per_sample_weights,
    Torch_IntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $indices `,` $offset2bag `,` $bag_size `,` $maximum_indices `,` $num_weights `,` $scale_grad_by_freq `,` $mode `,` $per_sample_weights `,` $padding_idx attr-dict `:` type($grad) `,` type($indices) `,` type($offset2bag) `,` type($bag_size) `,` type($maximum_indices) `,` type($num_weights) `,` type($scale_grad_by_freq) `,` type($mode) `,` type($per_sample_weights) `,` type($padding_idx) `->` type($result)";
}

def Torch_Aten_EmbeddingBagPerSampleWeightsBackwardOp : Torch_Op<"aten._embedding_bag_per_sample_weights_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_embedding_bag_per_sample_weights_backward : (Tensor, Tensor, Tensor, Tensor, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$offsets,
    AnyTorchTensorType:$offset2bag,
    Torch_IntType:$mode,
    Torch_IntType:$padding_idx
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $weight `,` $indices `,` $offsets `,` $offset2bag `,` $mode `,` $padding_idx attr-dict `:` type($grad) `,` type($weight) `,` type($indices) `,` type($offsets) `,` type($offset2bag) `,` type($mode) `,` type($padding_idx) `->` type($result)";
}

def Torch_AtenLeakyReluOutOp : Torch_Op<"aten.leaky_relu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::leaky_relu.out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$negative_slope,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $negative_slope `,` $out attr-dict `:` type($self) `,` type($negative_slope) `,` type($out) `->` type($result)";
}

def Torch_AtenExp2OutOp : Torch_Op<"aten.exp2.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::exp2.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenExp2_Op : Torch_Op<"aten.exp2_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::exp2_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenLeakyReluBackwardOp : Torch_Op<"aten.leaky_relu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::leaky_relu_backward : (Tensor, Tensor, Scalar, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$negative_slope,
    Torch_BoolType:$self_is_result
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $negative_slope `,` $self_is_result attr-dict `:` type($grad_output) `,` type($self) `,` type($negative_slope) `,` type($self_is_result) `->` type($result)";
}

def Torch_AtenLeakyReluBackwardGradInputOp : Torch_Op<"aten.leaky_relu_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::leaky_relu_backward.grad_input : (Tensor, Tensor, Scalar, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$negative_slope,
    Torch_BoolType:$self_is_result,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $negative_slope `,` $self_is_result `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($negative_slope) `,` type($self_is_result) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenGcd_Op : Torch_Op<"aten.gcd_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::gcd_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLcm_Op : Torch_Op<"aten.lcm_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lcm_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLerpScalarOutOp : Torch_Op<"aten.lerp.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lerp.Scalar_out : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$end,
    AnyTorchScalarType:$weight,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $end `,` $weight `,` $out attr-dict `:` type($self) `,` type($end) `,` type($weight) `,` type($out) `->` type($result)";
}

def Torch_AtenLerpTensorOutOp : Torch_Op<"aten.lerp.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lerp.Tensor_out : (Tensor, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$end,
    AnyTorchTensorType:$weight,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $end `,` $weight `,` $out attr-dict `:` type($self) `,` type($end) `,` type($weight) `,` type($out) `->` type($result)";
}

def Torch_Aten_IndexPutImpl_Op : Torch_Op<"aten._index_put_impl_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_index_put_impl_ : (Tensor, Tensor?[], Tensor, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchListOptionalTensorType:$indices,
    AnyTorchTensorType:$values,
    Torch_BoolType:$accumulate,
    Torch_BoolType:$unsafe
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $indices `,` $values `,` $accumulate `,` $unsafe attr-dict `:` type($self) `,` type($indices) `,` type($values) `,` type($accumulate) `,` type($unsafe) `->` type($result)";
}

def Torch_AtenIsinTensorTensorOutOp : Torch_Op<"aten.isin.Tensor_Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::isin.Tensor_Tensor_out : (Tensor, Tensor, bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$elements,
    AnyTorchTensorType:$test_elements,
    Torch_BoolType:$assume_unique,
    Torch_BoolType:$invert,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$elements `,` $test_elements `,` $assume_unique `,` $invert `,` $out attr-dict `:` type($elements) `,` type($test_elements) `,` type($assume_unique) `,` type($invert) `,` type($out) `->` type($result)";
}

def Torch_AtenIsinTensorScalarOutOp : Torch_Op<"aten.isin.Tensor_Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::isin.Tensor_Scalar_out : (Tensor, Scalar, bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$elements,
    AnyTorchScalarType:$test_element,
    Torch_BoolType:$assume_unique,
    Torch_BoolType:$invert,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$elements `,` $test_element `,` $assume_unique `,` $invert `,` $out attr-dict `:` type($elements) `,` type($test_element) `,` type($assume_unique) `,` type($invert) `,` type($out) `->` type($result)";
}

def Torch_AtenIsinScalarTensorOutOp : Torch_Op<"aten.isin.Scalar_Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::isin.Scalar_Tensor_out : (Scalar, Tensor, bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$element,
    AnyTorchTensorType:$test_elements,
    Torch_BoolType:$assume_unique,
    Torch_BoolType:$invert,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$element `,` $test_elements `,` $assume_unique `,` $invert `,` $out attr-dict `:` type($element) `,` type($test_elements) `,` type($assume_unique) `,` type($invert) `,` type($out) `->` type($result)";
}

def Torch_AtenLogSigmoidBackwardOp : Torch_Op<"aten.log_sigmoid_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::log_sigmoid_backward : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$buffer
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $buffer attr-dict `:` type($grad_output) `,` type($self) `,` type($buffer) `->` type($result)";
}

def Torch_AtenLogSigmoidBackwardGradInputOp : Torch_Op<"aten.log_sigmoid_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log_sigmoid_backward.grad_input : (Tensor, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$buffer,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $buffer `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($buffer) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenNativeLayerNormBackwardOp : Torch_Op<"aten.native_layer_norm_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_layer_norm_backward : (Tensor, Tensor, int[], Tensor, Tensor, Tensor?, Tensor?, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$input,
    TorchIntListType:$normalized_shape,
    AnyTorchTensorType:$mean,
    AnyTorchTensorType:$rstd,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_out `,` $input `,` $normalized_shape `,` $mean `,` $rstd `,` $weight `,` $bias `,` $output_mask attr-dict `:` type($grad_out) `,` type($input) `,` type($normalized_shape) `,` type($mean) `,` type($rstd) `,` type($weight) `,` type($bias) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_ForeachCosOp : Torch_Op<"aten._foreach_cos", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_cos : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenNanToNumOutOp : Torch_Op<"aten.nan_to_num.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nan_to_num.out : (Tensor, float?, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$nan,
    TorchOptionalFloatType:$posinf,
    TorchOptionalFloatType:$neginf,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $nan `,` $posinf `,` $neginf `,` $out attr-dict `:` type($self) `,` type($nan) `,` type($posinf) `,` type($neginf) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAsinOp : Torch_Op<"aten._foreach_asin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_asin : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenXlogyOutTensorOp : Torch_Op<"aten.xlogy.OutTensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::xlogy.OutTensor : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenXlogyOutScalarSelfOp : Torch_Op<"aten.xlogy.OutScalar_Self", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::xlogy.OutScalar_Self : (Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenXlogyOutScalarOtherOp : Torch_Op<"aten.xlogy.OutScalar_Other", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::xlogy.OutScalar_Other : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenXlogy_TensorOp : Torch_Op<"aten.xlogy_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::xlogy_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenXlogy_ScalarOtherOp : Torch_Op<"aten.xlogy_.Scalar_Other", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::xlogy_.Scalar_Other : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLogSigmoidForwardOutputOp : Torch_Op<"aten.log_sigmoid_forward.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::log_sigmoid_forward.output : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$buffer
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $output `,` $buffer attr-dict `:` type($self) `,` type($output) `,` type($buffer) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_LogSoftmaxOp : Torch_Op<"aten._log_softmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_log_softmax : (Tensor, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$half_to_float
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $half_to_float attr-dict `:` type($self) `,` type($dim) `,` type($half_to_float) `->` type($result)";
}

def Torch_Aten_LogSoftmaxOutOp : Torch_Op<"aten._log_softmax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_log_softmax.out : (Tensor, int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$half_to_float,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $half_to_float `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($half_to_float) `,` type($out) `->` type($result)";
}

def Torch_Aten_LogcumsumexpOp : Torch_Op<"aten._logcumsumexp", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_logcumsumexp : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim attr-dict `:` type($self) `,` type($dim) `->` type($result)";
}

def Torch_Aten_LogcumsumexpOutOp : Torch_Op<"aten._logcumsumexp.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_logcumsumexp.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_Aten_LogSoftmaxBackwardDataOutOp : Torch_Op<"aten._log_softmax_backward_data.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_log_softmax_backward_data.out : (Tensor, Tensor, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    Torch_IntType:$dim,
    Torch_IntType:$input_dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $dim `,` $input_dtype `,` $out attr-dict `:` type($grad_output) `,` type($output) `,` type($dim) `,` type($input_dtype) `,` type($out) `->` type($result)";
}

def Torch_Aten_AminmaxOp : Torch_Op<"aten._aminmax", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_aminmax : (Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_AminmaxDimOp : Torch_Op<"aten._aminmax.dim", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_aminmax.dim : (Tensor, int, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$keepdim
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `->` type($result0) `,` type($result1)";
}

def Torch_AtenMvlgammaOutOp : Torch_Op<"aten.mvlgamma.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mvlgamma.out : (Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$p,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $out attr-dict `:` type($self) `,` type($p) `,` type($out) `->` type($result)";
}

def Torch_AtenNarrowCopyOutOp : Torch_Op<"aten.narrow_copy.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::narrow_copy.out : (Tensor, int, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_IntType:$start,
    Torch_IntType:$length,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $start `,` $length `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($start) `,` type($length) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAtanOp : Torch_Op<"aten._foreach_atan", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_atan : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenNativeBatchNormOp : Torch_Op<"aten.native_batch_norm", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_batch_norm : (Tensor, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, float) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$training,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $training `,` $momentum `,` $eps attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($training) `,` type($momentum) `,` type($eps) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenNativeBatchNormOutOp : Torch_Op<"aten.native_batch_norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::native_batch_norm.out : (Tensor, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, float, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_BoolType:$training,
    Torch_FloatType:$momentum,
    Torch_FloatType:$eps,
    AnyTorchTensorType:$out,
    AnyTorchTensorType:$save_mean,
    AnyTorchTensorType:$save_invstd
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $running_mean `,` $running_var `,` $training `,` $momentum `,` $eps `,` $out `,` $save_mean `,` $save_invstd attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($running_mean) `,` type($running_var) `,` type($training) `,` type($momentum) `,` type($eps) `,` type($out) `,` type($save_mean) `,` type($save_invstd) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_ForeachAtan_Op : Torch_Op<"aten._foreach_atan_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_atan_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenNativeBatchNormBackwardOp : Torch_Op<"aten.native_batch_norm_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::native_batch_norm_backward : (Tensor, Tensor, Tensor?, Tensor?, Tensor?, Tensor?, Tensor?, bool, float, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_out,
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$weight,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    AnyTorchOptionalTensorType:$save_mean,
    AnyTorchOptionalTensorType:$save_invstd,
    Torch_BoolType:$train,
    Torch_FloatType:$eps,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_out `,` $input `,` $weight `,` $running_mean `,` $running_var `,` $save_mean `,` $save_invstd `,` $train `,` $eps `,` $output_mask attr-dict `:` type($grad_out) `,` type($input) `,` type($weight) `,` type($running_mean) `,` type($running_var) `,` type($save_mean) `,` type($save_invstd) `,` type($train) `,` type($eps) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_ForeachCeilOp : Torch_Op<"aten._foreach_ceil", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_ceil : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenBatchNormUpdateStatsOp : Torch_Op<"aten.batch_norm_update_stats", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::batch_norm_update_stats : (Tensor, Tensor?, Tensor?, float) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchOptionalTensorType:$running_mean,
    AnyTorchOptionalTensorType:$running_var,
    Torch_FloatType:$momentum
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $running_mean `,` $running_var `,` $momentum attr-dict `:` type($input) `,` type($running_mean) `,` type($running_var) `,` type($momentum) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_PdistForwardOp : Torch_Op<"aten._pdist_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_pdist_forward : (Tensor, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$p
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p attr-dict `:` type($self) `,` type($p) `->` type($result)";
}

def Torch_Aten_PdistBackwardOp : Torch_Op<"aten._pdist_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_pdist_backward : (Tensor, Tensor, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$self,
    Torch_FloatType:$p,
    AnyTorchTensorType:$pdist
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $self `,` $p `,` $pdist attr-dict `:` type($grad) `,` type($self) `,` type($p) `,` type($pdist) `->` type($result)";
}

def Torch_AtenPreluBackwardOp : Torch_Op<"aten.prelu_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::prelu_backward : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `->` type($result0) `,` type($result1)";
}

def Torch_AtenBucketizeTensorOutOp : Torch_Op<"aten.bucketize.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bucketize.Tensor_out : (Tensor, Tensor, bool, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$boundaries,
    Torch_BoolType:$out_int32,
    Torch_BoolType:$right,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $boundaries `,` $out_int32 `,` $right `,` $out attr-dict `:` type($self) `,` type($boundaries) `,` type($out_int32) `,` type($right) `,` type($out) `->` type($result)";
}

def Torch_AtenSiluOutOp : Torch_Op<"aten.silu.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::silu.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSilu_Op : Torch_Op<"aten.silu_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::silu_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenMishOutOp : Torch_Op<"aten.mish.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mish.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenRenorm_Op : Torch_Op<"aten.renorm_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::renorm_ : (Tensor, Scalar, int, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$p,
    Torch_IntType:$dim,
    AnyTorchScalarType:$maxnorm
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $dim `,` $maxnorm attr-dict `:` type($self) `,` type($p) `,` type($dim) `,` type($maxnorm) `->` type($result)";
}

def Torch_AtenLogitOutOp : Torch_Op<"aten.logit.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logit.out : (Tensor, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $eps `,` $out attr-dict `:` type($self) `,` type($eps) `,` type($out) `->` type($result)";
}

def Torch_AtenLogit_Op : Torch_Op<"aten.logit_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::logit_ : (Tensor, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$eps
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $eps attr-dict `:` type($self) `,` type($eps) `->` type($result)";
}

def Torch_AtenSincOutOp : Torch_Op<"aten.sinc.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sinc.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_SoftmaxOutOp : Torch_Op<"aten._softmax.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_softmax.out : (Tensor, int, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$half_to_float,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $half_to_float `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($half_to_float) `,` type($out) `->` type($result)";
}

def Torch_Aten_SoftmaxBackwardDataOutOp : Torch_Op<"aten._softmax_backward_data.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_softmax_backward_data.out : (Tensor, Tensor, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$output,
    Torch_IntType:$dim,
    Torch_IntType:$input_dtype,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output `,` $dim `,` $input_dtype `,` $grad_input attr-dict `:` type($grad_output) `,` type($output) `,` type($dim) `,` type($input_dtype) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenSspaddmmOutOp : Torch_Op<"aten.sspaddmm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sspaddmm.out : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mat1,
    AnyTorchTensorType:$mat2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mat1 `,` $mat2 `,` $beta `,` $alpha `,` $out attr-dict `:` type($self) `,` type($mat1) `,` type($mat2) `,` type($beta) `,` type($alpha) `,` type($out) `->` type($result)";
}

def Torch_AtenNansumIntListOutOp : Torch_Op<"aten.nansum.IntList_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nansum.IntList_out : (Tensor, int[], bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAcos_Op : Torch_Op<"aten._foreach_acos_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_acos_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_DirichletGradOp : Torch_Op<"aten._dirichlet_grad", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_dirichlet_grad : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x,
    AnyTorchTensorType:$alpha,
    AnyTorchTensorType:$total
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x `,` $alpha `,` $total attr-dict `:` type($x) `,` type($alpha) `,` type($total) `->` type($result)";
}

def Torch_AtenMaxPool2dWithIndicesBackwardOp : Torch_Op<"aten.max_pool2d_with_indices_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool2d_with_indices_backward : (Tensor, Tensor, int[], int[], int[], int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode `,` $indices attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `,` type($indices) `->` type($result)";
}

def Torch_AtenMaxPool2dWithIndicesBackwardGradInputOp : Torch_Op<"aten.max_pool2d_with_indices_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_pool2d_with_indices_backward.grad_input : (Tensor, Tensor, int[], int[], int[], int[], bool, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode `,` $indices `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `,` type($indices) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenHeaviside_Op : Torch_Op<"aten.heaviside_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::heaviside_ : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$values
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $values attr-dict `:` type($self) `,` type($values) `->` type($result)";
}

def Torch_AtenToMkldnnOp : Torch_Op<"aten.to_mkldnn", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::to_mkldnn : (Tensor, int?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dtype attr-dict `:` type($self) `,` type($dtype) `->` type($result)";
}

def Torch_Aten_MakePerTensorQuantizedTensorOp : Torch_Op<"aten._make_per_tensor_quantized_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_make_per_tensor_quantized_tensor : (Tensor, float, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$scale,
    Torch_IntType:$zero_point
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `->` type($result)";
}

def Torch_AtenMaxPool3dWithIndicesBackwardOp : Torch_Op<"aten.max_pool3d_with_indices_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_pool3d_with_indices_backward : (Tensor, Tensor, int[], int[], int[], int[], bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode `,` $indices attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `,` type($indices) `->` type($result)";
}

def Torch_AtenMaxPool3dWithIndicesBackwardGradInputOp : Torch_Op<"aten.max_pool3d_with_indices_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_pool3d_with_indices_backward.grad_input : (Tensor, Tensor, int[], int[], int[], int[], bool, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$ceil_mode,
    AnyTorchTensorType:$indices,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $ceil_mode `,` $indices `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($ceil_mode) `,` type($indices) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_MakePerChannelQuantizedTensorOp : Torch_Op<"aten._make_per_channel_quantized_tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_make_per_channel_quantized_tensor : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$axis
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $axis attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($axis) `->` type($result)";
}

def Torch_Aten_FakeQuantizePerTensorAffineCachemaskTensorQparamsOp : Torch_Op<"aten._fake_quantize_per_tensor_affine_cachemask_tensor_qparams", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fake_quantize_per_tensor_affine_cachemask_tensor_qparams : (Tensor, Tensor, Tensor, Tensor, int, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    AnyTorchTensorType:$fake_quant_enabled,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$mask
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $fake_quant_enabled `,` $quant_min `,` $quant_max attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($fake_quant_enabled) `,` type($quant_min) `,` type($quant_max) `->` type($output) `,` type($mask)";
}

def Torch_AtenMaxUnpool2dBackwardOp : Torch_Op<"aten.max_unpool2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_unpool2d_backward : (Tensor, Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices `,` $output_size attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `,` type($output_size) `->` type($result)";
}

def Torch_AtenMaxUnpool2dBackwardGradInputOp : Torch_Op<"aten.max_unpool2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_unpool2d_backward.grad_input : (Tensor, Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices `,` $output_size `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `,` type($output_size) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_FakeQuantizeLearnablePerTensorAffineOp : Torch_Op<"aten._fake_quantize_learnable_per_tensor_affine", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fake_quantize_learnable_per_tensor_affine : (Tensor, Tensor, Tensor, int, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max,
    Torch_FloatType:$grad_factor
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $quant_min `,` $quant_max `,` $grad_factor attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($quant_min) `,` type($quant_max) `,` type($grad_factor) `->` type($result)";
}

def Torch_Aten_FakeQuantizeLearnablePerChannelAffineOp : Torch_Op<"aten._fake_quantize_learnable_per_channel_affine", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_fake_quantize_learnable_per_channel_affine : (Tensor, Tensor, Tensor, int, int, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_IntType:$axis,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max,
    Torch_FloatType:$grad_factor
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $scale `,` $zero_point `,` $axis `,` $quant_min `,` $quant_max `,` $grad_factor attr-dict `:` type($self) `,` type($scale) `,` type($zero_point) `,` type($axis) `,` type($quant_min) `,` type($quant_max) `,` type($grad_factor) `->` type($result)";
}

def Torch_AtenMaxUnpool3dBackwardOp : Torch_Op<"aten.max_unpool3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::max_unpool3d_backward : (Tensor, Tensor, Tensor, int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices `,` $output_size `,` $stride `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `,` type($output_size) `,` type($stride) `,` type($padding) `->` type($result)";
}

def Torch_AtenMaxUnpool3dBackwardGradInputOp : Torch_Op<"aten.max_unpool3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::max_unpool3d_backward.grad_input : (Tensor, Tensor, Tensor, int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$indices,
    TorchIntListType:$output_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $indices `,` $output_size `,` $stride `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($indices) `,` type($output_size) `,` type($stride) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_FusedMovingAvgObsFqHelperOp : Torch_Op<"aten._fused_moving_avg_obs_fq_helper", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_fused_moving_avg_obs_fq_helper : (Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, Tensor, float, int, int, int, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$observer_on,
    AnyTorchTensorType:$fake_quant_on,
    AnyTorchTensorType:$running_min,
    AnyTorchTensorType:$running_max,
    AnyTorchTensorType:$scale,
    AnyTorchTensorType:$zero_point,
    Torch_FloatType:$averaging_const,
    Torch_IntType:$quant_min,
    Torch_IntType:$quant_max,
    Torch_IntType:$ch_axis,
    Torch_BoolType:$per_row_fake_quant,
    Torch_BoolType:$symmetric_quant
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$mask
  );
  let assemblyFormat = "$self `,` $observer_on `,` $fake_quant_on `,` $running_min `,` $running_max `,` $scale `,` $zero_point `,` $averaging_const `,` $quant_min `,` $quant_max `,` $ch_axis `,` $per_row_fake_quant `,` $symmetric_quant attr-dict `:` type($self) `,` type($observer_on) `,` type($fake_quant_on) `,` type($running_min) `,` type($running_max) `,` type($scale) `,` type($zero_point) `,` type($averaging_const) `,` type($quant_min) `,` type($quant_max) `,` type($ch_axis) `,` type($per_row_fake_quant) `,` type($symmetric_quant) `->` type($output) `,` type($mask)";
}

def Torch_AtenMaskedScatter_Op : Torch_Op<"aten.masked_scatter_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::masked_scatter_ : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$mask,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $mask `,` $source attr-dict `:` type($self) `,` type($mask) `,` type($source) `->` type($result)";
}

def Torch_AtenIndexAdd_AlphaOp : Torch_Op<"aten.index_add_.alpha", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_add_.alpha : (Tensor, int, Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source `,` $alpha attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `,` type($alpha) `->` type($result)";
}

def Torch_AtenIndexAdd_Op : Torch_Op<"aten.index_add_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_add_ : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenScatterSrcOutOp : Torch_Op<"aten.scatter.src_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter.src_out : (Tensor, int, Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `,` type($out) `->` type($result)";
}

def Torch_AtenScatterValueOutOp : Torch_Op<"aten.scatter.value_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter.value_out : (Tensor, int, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `,` type($out) `->` type($result)";
}

def Torch_AtenScatterReduceOutOp : Torch_Op<"aten.scatter.reduce_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter.reduce_out : (Tensor, int, Tensor, Tensor, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$src,
    Torch_StringType:$reduce,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $src `,` $reduce `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($src) `,` type($reduce) `,` type($out) `->` type($result)";
}

def Torch_AtenScatterValueReduceOutOp : Torch_Op<"aten.scatter.value_reduce_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::scatter.value_reduce_out : (Tensor, int, Tensor, Scalar, str, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchScalarType:$value,
    Torch_StringType:$reduce,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $value `,` $reduce `,` $out attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($value) `,` type($reduce) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseAndTensorOutOp : Torch_Op<"aten.bitwise_and.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_and.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseAndScalarOutOp : Torch_Op<"aten.bitwise_and.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_and.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog10_Op : Torch_Op<"aten._foreach_log10_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log10_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenBitwiseOrTensorOutOp : Torch_Op<"aten.bitwise_or.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_or.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseOrScalarOutOp : Torch_Op<"aten.bitwise_or.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_or.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog1p_Op : Torch_Op<"aten._foreach_log1p_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log1p_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenBitwiseOr_TensorOp : Torch_Op<"aten.bitwise_or_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_or_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseOr_ScalarOp : Torch_Op<"aten.bitwise_or_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_or_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseXorTensorOutOp : Torch_Op<"aten.bitwise_xor.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_xor.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseXorScalarOutOp : Torch_Op<"aten.bitwise_xor.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_xor.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog2Op : Torch_Op<"aten._foreach_log2", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log2 : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenBitwiseXor_TensorOp : Torch_Op<"aten.bitwise_xor_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_xor_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseXor_ScalarOp : Torch_Op<"aten.bitwise_xor_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_xor_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Lshift__ScalarOp : Torch_Op<"aten.__lshift__.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__lshift__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Lshift__TensorOp : Torch_Op<"aten.__lshift__.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__lshift__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Ilshift__ScalarOp : Torch_Op<"aten.__ilshift__.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__ilshift__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Ilshift__TensorOp : Torch_Op<"aten.__ilshift__.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__ilshift__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseLeftShiftTensorOutOp : Torch_Op<"aten.bitwise_left_shift.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseLeftShiftTensorScalarOutOp : Torch_Op<"aten.bitwise_left_shift.Tensor_Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift.Tensor_Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseLeftShift_TensorOp : Torch_Op<"aten.bitwise_left_shift_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseLeftShift_TensorScalarOp : Torch_Op<"aten.bitwise_left_shift_.Tensor_Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_left_shift_.Tensor_Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Rshift__ScalarOp : Torch_Op<"aten.__rshift__.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__rshift__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Rshift__TensorOp : Torch_Op<"aten.__rshift__.Tensor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::__rshift__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Irshift__ScalarOp : Torch_Op<"aten.__irshift__.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__irshift__.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_Aten__Irshift__TensorOp : Torch_Op<"aten.__irshift__.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::__irshift__.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseRightShiftTensorOutOp : Torch_Op<"aten.bitwise_right_shift.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseRightShiftTensorScalarOutOp : Torch_Op<"aten.bitwise_right_shift.Tensor_Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift.Tensor_Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenBitwiseRightShift_TensorOp : Torch_Op<"aten.bitwise_right_shift_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenBitwiseRightShift_TensorScalarOp : Torch_Op<"aten.bitwise_right_shift_.Tensor_Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::bitwise_right_shift_.Tensor_Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenTril_Op : Torch_Op<"aten.tril_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::tril_ : (Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$diagonal
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $diagonal attr-dict `:` type($self) `,` type($diagonal) `->` type($result)";
}

def Torch_AtenLerp_ScalarOp : Torch_Op<"aten.lerp_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::lerp_.Scalar : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$end,
    AnyTorchScalarType:$weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $end `,` $weight attr-dict `:` type($self) `,` type($end) `,` type($weight) `->` type($result)";
}

def Torch_AtenAddbmm_Op : Torch_Op<"aten.addbmm_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addbmm_ : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$batch1,
    AnyTorchTensorType:$batch2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $batch1 `,` $batch2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($batch1) `,` type($batch2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenGe_TensorOp : Torch_Op<"aten.ge_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::ge_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLe_ScalarOp : Torch_Op<"aten.le_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::le_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenLe_TensorOp : Torch_Op<"aten.le_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::le_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenTakeOutOp : Torch_Op<"aten.take.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::take.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $index `,` $out attr-dict `:` type($self) `,` type($index) `,` type($out) `->` type($result)";
}

def Torch_AtenNonzeroOutOp : Torch_Op<"aten.nonzero.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nonzero.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_SymeigHelperOp : Torch_Op<"aten._symeig_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_symeig_helper : (Tensor, bool, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$eigenvectors,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $eigenvectors `,` $upper attr-dict `:` type($self) `,` type($eigenvectors) `,` type($upper) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_SvdHelperOp : Torch_Op<"aten._svd_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_svd_helper : (Tensor, bool, bool) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$some,
    Torch_BoolType:$compute_uv
  );
  let results = (outs
    AnyTorchTensorType:$U,
    AnyTorchTensorType:$S,
    AnyTorchTensorType:$V
  );
  let assemblyFormat = "$self `,` $some `,` $compute_uv attr-dict `:` type($self) `,` type($some) `,` type($compute_uv) `->` type($U) `,` type($S) `,` type($V)";
}

def Torch_Aten_CholeskySolveHelperOp : Torch_Op<"aten._cholesky_solve_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cholesky_solve_helper : (Tensor, Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A,
    Torch_BoolType:$upper
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $A `,` $upper attr-dict `:` type($self) `,` type($A) `,` type($upper) `->` type($result)";
}

def Torch_Aten_SolveHelperOp : Torch_Op<"aten._solve_helper", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_solve_helper : (Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$A
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $A attr-dict `:` type($self) `,` type($A) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_HistogramddBinEdgesOp : Torch_Op<"aten._histogramdd_bin_edges", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_histogramdd_bin_edges : (Tensor, int[], float[]?, Tensor?, bool) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$bins,
    TorchOptionalFloatListType:$range,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$self `,` $bins `,` $range `,` $weight `,` $density attr-dict `:` type($self) `,` type($bins) `,` type($range) `,` type($weight) `,` type($density) `->` type($result)";
}

def Torch_Aten_HistogramddFromBinCtsOp : Torch_Op<"aten._histogramdd_from_bin_cts", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_histogramdd_from_bin_cts : (Tensor, int[], float[]?, Tensor?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$bins,
    TorchOptionalFloatListType:$range,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $bins `,` $range `,` $weight `,` $density attr-dict `:` type($self) `,` type($bins) `,` type($range) `,` type($weight) `,` type($density) `->` type($result)";
}

def Torch_Aten_HistogramddFromBinTensorsOp : Torch_Op<"aten._histogramdd_from_bin_tensors", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_histogramdd_from_bin_tensors : (Tensor, Tensor[], Tensor?, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorListType:$bins,
    AnyTorchOptionalTensorType:$weight,
    Torch_BoolType:$density
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $bins `,` $weight `,` $density attr-dict `:` type($self) `,` type($bins) `,` type($weight) `,` type($density) `->` type($result)";
}

def Torch_AtenRemainderTensorOutOp : Torch_Op<"aten.remainder.Tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::remainder.Tensor_out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenRemainderScalarOutOp : Torch_Op<"aten.remainder.Scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::remainder.Scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_Aten_NnpackSpatialConvolutionOp : Torch_Op<"aten._nnpack_spatial_convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_nnpack_spatial_convolution : (Tensor, Tensor, Tensor?, int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$stride
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $padding `,` $stride attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($stride) `->` type($result)";
}

def Torch_AtenRemainder_TensorOp : Torch_Op<"aten.remainder_.Tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::remainder_.Tensor : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenRemainder_ScalarOp : Torch_Op<"aten.remainder_.Scalar", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::remainder_.Scalar : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other) `->` type($result)";
}

def Torch_AtenMaximumOutOp : Torch_Op<"aten.maximum.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::maximum.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenMinimumOutOp : Torch_Op<"aten.minimum.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::minimum.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSortValuesOp : Torch_Op<"aten.sort.values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sort.values : (Tensor, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    Torch_BoolType:$descending,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $descending `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($descending) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenSortValuesStableOp : Torch_Op<"aten.sort.values_stable", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sort.values_stable : (Tensor, bool?, int, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalBoolType:$stable,
    Torch_IntType:$dim,
    Torch_BoolType:$descending,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $stable `,` $dim `,` $descending `,` $values `,` $indices attr-dict `:` type($self) `,` type($stable) `,` type($dim) `,` type($descending) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenSortDimnameValuesOp : Torch_Op<"aten.sort.dimname_values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sort.dimname_values : (Tensor, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    Torch_BoolType:$descending,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $dim `,` $descending `,` $values `,` $indices attr-dict `:` type($self) `,` type($dim) `,` type($descending) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenSortDimnameValuesStableOp : Torch_Op<"aten.sort.dimname_values_stable", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::sort.dimname_values_stable : (Tensor, bool?, str, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalBoolType:$stable,
    Torch_StringType:$dim,
    Torch_BoolType:$descending,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $stable `,` $dim `,` $descending `,` $values `,` $indices attr-dict `:` type($self) `,` type($stable) `,` type($dim) `,` type($descending) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenTopkValuesOp : Torch_Op<"aten.topk.values", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::topk.values : (Tensor, int, int, bool, bool, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$k,
    Torch_IntType:$dim,
    Torch_BoolType:$largest,
    Torch_BoolType:$sorted,
    AnyTorchTensorType:$values,
    AnyTorchTensorType:$indices
  );
  let results = (outs
    AnyTorchTensorType:$res_values,
    AnyTorchTensorType:$res_indices
  );
  let assemblyFormat = "$self `,` $k `,` $dim `,` $largest `,` $sorted `,` $values `,` $indices attr-dict `:` type($self) `,` type($k) `,` type($dim) `,` type($largest) `,` type($sorted) `,` type($values) `,` type($indices) `->` type($res_values) `,` type($res_indices)";
}

def Torch_AtenUnfoldBackwardOp : Torch_Op<"aten.unfold_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::unfold_backward : (Tensor, int[], int, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_in,
    TorchIntListType:$input_sizes,
    Torch_IntType:$dim,
    Torch_IntType:$size,
    Torch_IntType:$step
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_in `,` $input_sizes `,` $dim `,` $size `,` $step attr-dict `:` type($grad_in) `,` type($input_sizes) `,` type($dim) `,` type($size) `,` type($step) `->` type($result)";
}

def Torch_AtenMkldnnConvolutionOp : Torch_Op<"aten.mkldnn_convolution", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_convolution : (Tensor, Tensor, Tensor?, int[], int[], int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $bias `,` $padding `,` $stride `,` $dilation `,` $groups attr-dict `:` type($self) `,` type($weight) `,` type($bias) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `->` type($result)";
}

def Torch_Aten_IndexCopy_Op : Torch_Op<"aten._index_copy_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_index_copy_ : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenMkldnnConvolutionBackwardOp : Torch_Op<"aten.mkldnn_convolution_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mkldnn_convolution_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$weight,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    TorchIntListType:$dilation,
    Torch_IntType:$groups,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $grad_output `,` $weight `,` $padding `,` $stride `,` $dilation `,` $groups `,` $output_mask attr-dict `:` type($self) `,` type($grad_output) `,` type($weight) `,` type($padding) `,` type($stride) `,` type($dilation) `,` type($groups) `,` type($output_mask) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_CatOp : Torch_Op<"aten._cat", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cat : (Tensor[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim attr-dict `:` type($tensors) `,` type($dim) `->` type($result)";
}

def Torch_Aten_CatOutOp : Torch_Op<"aten._cat.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_cat.out : (Tensor[], int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    Torch_IntType:$dim,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$tensors `,` $dim `,` $out attr-dict `:` type($tensors) `,` type($dim) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachAddScalarOp : Torch_Op<"aten._foreach_add.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_add.Scalar : (Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalar attr-dict `:` type($tensors) `,` type($scalar) `->` type($result)";
}

def Torch_Aten_ForeachAddListOp : Torch_Op<"aten._foreach_add.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_add.List : (Tensor[], Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors1,
    AnyTorchTensorListType:$tensors2,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors1 `,` $tensors2 `,` $alpha attr-dict `:` type($tensors1) `,` type($tensors2) `,` type($alpha) `->` type($result)";
}

def Torch_Aten_ForeachAddScalarListOp : Torch_Op<"aten._foreach_add.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_add.ScalarList : (Tensor[], Scalar[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalars attr-dict `:` type($tensors) `,` type($scalars) `->` type($result)";
}

def Torch_Aten_ForeachAdd_ScalarOp : Torch_Op<"aten._foreach_add_.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_add_.Scalar : (Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalar attr-dict `:` type($self) `,` type($scalar)";
}

def Torch_Aten_ForeachAdd_ListOp : Torch_Op<"aten._foreach_add_.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_add_.List : (Tensor[], Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$other,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $other `,` $alpha attr-dict `:` type($self) `,` type($other) `,` type($alpha)";
}

def Torch_Aten_ForeachAdd_ScalarListOp : Torch_Op<"aten._foreach_add_.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_add_.ScalarList : (Tensor[], Scalar[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalars attr-dict `:` type($self) `,` type($scalars)";
}

def Torch_Aten_ForeachMul_ScalarOp : Torch_Op<"aten._foreach_mul_.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_mul_.Scalar : (Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalar attr-dict `:` type($self) `,` type($scalar)";
}

def Torch_Aten_ForeachMul_ListOp : Torch_Op<"aten._foreach_mul_.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_mul_.List : (Tensor[], Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$other
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other)";
}

def Torch_Aten_ForeachMul_ScalarListOp : Torch_Op<"aten._foreach_mul_.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_mul_.ScalarList : (Tensor[], Scalar[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalars attr-dict `:` type($self) `,` type($scalars)";
}

def Torch_AtenMseLossBackwardOp : Torch_Op<"aten.mse_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::mse_loss_backward : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenMseLossBackwardGradInputOp : Torch_Op<"aten.mse_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::mse_loss_backward.grad_input : (Tensor, Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_ForeachDivScalarOp : Torch_Op<"aten._foreach_div.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_div.Scalar : (Tensor[], Scalar) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalar attr-dict `:` type($tensors) `,` type($scalar) `->` type($result)";
}

def Torch_Aten_ForeachDivListOp : Torch_Op<"aten._foreach_div.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_div.List : (Tensor[], Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors1,
    AnyTorchTensorListType:$tensors2
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors1 `,` $tensors2 attr-dict `:` type($tensors1) `,` type($tensors2) `->` type($result)";
}

def Torch_Aten_ForeachDivScalarListOp : Torch_Op<"aten._foreach_div.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_div.ScalarList : (Tensor[], Scalar[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors `,` $scalars attr-dict `:` type($tensors) `,` type($scalars) `->` type($result)";
}

def Torch_Aten_ForeachDiv_ScalarOp : Torch_Op<"aten._foreach_div_.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_div_.Scalar : (Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarType:$scalar
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalar attr-dict `:` type($self) `,` type($scalar)";
}

def Torch_Aten_ForeachDiv_ListOp : Torch_Op<"aten._foreach_div_.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_div_.List : (Tensor[], Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$other
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $other attr-dict `:` type($self) `,` type($other)";
}

def Torch_Aten_ForeachDiv_ScalarListOp : Torch_Op<"aten._foreach_div_.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_div_.ScalarList : (Tensor[], Scalar[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $scalars attr-dict `:` type($self) `,` type($scalars)";
}

def Torch_Aten_ForeachZero_Op : Torch_Op<"aten._foreach_zero_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_zero_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenMultiMarginLossBackwardOp : Torch_Op<"aten.multi_margin_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multi_margin_loss_backward : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchScalarType:$p,
    AnyTorchScalarType:$margin,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $p `,` $margin `,` $weight `,` $reduction attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($p) `,` type($margin) `,` type($weight) `,` type($reduction) `->` type($result)";
}

def Torch_AtenMultiMarginLossBackwardGradInputOp : Torch_Op<"aten.multi_margin_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multi_margin_loss_backward.grad_input : (Tensor, Tensor, Tensor, Scalar, Scalar, Tensor?, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchScalarType:$p,
    AnyTorchScalarType:$margin,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $p `,` $margin `,` $weight `,` $reduction `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($p) `,` type($margin) `,` type($weight) `,` type($reduction) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_ForeachExp_Op : Torch_Op<"aten._foreach_exp_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_exp_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachSqrt_Op : Torch_Op<"aten._foreach_sqrt_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sqrt_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenMultilabelMarginLossBackwardOp : Torch_Op<"aten.multilabel_margin_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::multilabel_margin_loss_backward : (Tensor, Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$is_target
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $is_target attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($is_target) `->` type($result)";
}

def Torch_AtenMultilabelMarginLossBackwardGradInputOp : Torch_Op<"aten.multilabel_margin_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::multilabel_margin_loss_backward.grad_input : (Tensor, Tensor, Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$is_target,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $is_target `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($is_target) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_ForeachCos_Op : Torch_Op<"aten._foreach_cos_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_cos_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachCoshOp : Torch_Op<"aten._foreach_cosh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_cosh : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachCosh_Op : Torch_Op<"aten._foreach_cosh_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_cosh_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachErfOp : Torch_Op<"aten._foreach_erf", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_erf : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachErf_Op : Torch_Op<"aten._foreach_erf_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_erf_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachErfcOp : Torch_Op<"aten._foreach_erfc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_erfc : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachErfc_Op : Torch_Op<"aten._foreach_erfc_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_erfc_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachExpm1Op : Torch_Op<"aten._foreach_expm1", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_expm1 : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachFloorOp : Torch_Op<"aten._foreach_floor", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_floor : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenSpecialNdtriOutOp : Torch_Op<"aten.special_ndtri.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_ndtri.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_Aten_ForeachLog2_Op : Torch_Op<"aten._foreach_log2_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_log2_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachTanOp : Torch_Op<"aten._foreach_tan", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_tan : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenNllLoss2dBackwardOp : Torch_Op<"aten.nll_loss2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss2d_backward : (Tensor, Tensor, Tensor, Tensor?, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$total_weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $total_weight attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($total_weight) `->` type($result)";
}

def Torch_AtenNllLoss2dBackwardGradInputOp : Torch_Op<"aten.nll_loss2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nll_loss2d_backward.grad_input : (Tensor, Tensor, Tensor, Tensor?, int, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$total_weight,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $total_weight `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($total_weight) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_ForeachTan_Op : Torch_Op<"aten._foreach_tan_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_tan_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenNllLoss2dForwardOutputOp : Torch_Op<"aten.nll_loss2d_forward.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nll_loss2d_forward.output : (Tensor, Tensor, Tensor?, int, int, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$total_weight
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $output `,` $total_weight attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($output) `,` type($total_weight) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_ForeachTanhOp : Torch_Op<"aten._foreach_tanh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_tanh : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_AtenNllLossBackwardOp : Torch_Op<"aten.nll_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::nll_loss_backward : (Tensor, Tensor, Tensor, Tensor?, int, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$total_weight
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $total_weight attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($total_weight) `->` type($result)";
}

def Torch_AtenNllLossBackwardGradInputOp : Torch_Op<"aten.nll_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nll_loss_backward.grad_input : (Tensor, Tensor, Tensor, Tensor?, int, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$total_weight,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $total_weight `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($total_weight) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_ForeachTanh_Op : Torch_Op<"aten._foreach_tanh_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_tanh_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_AtenNllLossForwardOutputOp : Torch_Op<"aten.nll_loss_forward.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nll_loss_forward.output : (Tensor, Tensor, Tensor?, int, int, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    AnyTorchOptionalTensorType:$weight,
    Torch_IntType:$reduction,
    Torch_IntType:$ignore_index,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$total_weight
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $target `,` $weight `,` $reduction `,` $ignore_index `,` $output `,` $total_weight attr-dict `:` type($self) `,` type($target) `,` type($weight) `,` type($reduction) `,` type($ignore_index) `,` type($output) `,` type($total_weight) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_ForeachSinOp : Torch_Op<"aten._foreach_sin", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sin : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachSinhOp : Torch_Op<"aten._foreach_sinh", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_sinh : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachRound_Op : Torch_Op<"aten._foreach_round_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_round_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachFrac_Op : Torch_Op<"aten._foreach_frac_", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_frac_ : (Tensor[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self
  );
  let results = (outs
  );
  let assemblyFormat = "$self attr-dict `:` type($self)";
}

def Torch_Aten_ForeachReciprocalOp : Torch_Op<"aten._foreach_reciprocal", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_reciprocal : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_EuclideanDistOp : Torch_Op<"aten._euclidean_dist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_euclidean_dist : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$x1,
    AnyTorchTensorType:$x2
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$x1 `,` $x2 attr-dict `:` type($x1) `,` type($x2) `->` type($result)";
}

def Torch_Aten_ForeachTruncOp : Torch_Op<"aten._foreach_trunc", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_trunc : (Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors attr-dict `:` type($tensors) `->` type($result)";
}

def Torch_Aten_ForeachAddcdiv_ScalarOp : Torch_Op<"aten._foreach_addcdiv_.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcdiv_.Scalar : (Tensor[], Tensor[], Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value)";
}

def Torch_Aten_ForeachAddcdiv_ScalarListOp : Torch_Op<"aten._foreach_addcdiv_.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcdiv_.ScalarList : (Tensor[], Tensor[], Tensor[], Scalar[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $scalars attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($scalars)";
}

def Torch_Aten_ForeachAddcmul_ScalarOp : Torch_Op<"aten._foreach_addcmul_.Scalar", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcmul_.Scalar : (Tensor[], Tensor[], Tensor[], Scalar) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarType:$value
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $value attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($value)";
}

def Torch_Aten_ForeachAddcmul_ScalarListOp : Torch_Op<"aten._foreach_addcmul_.ScalarList", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_addcmul_.ScalarList : (Tensor[], Tensor[], Tensor[], Scalar[]) -> ()`";
  let arguments = (ins
    AnyTorchTensorListType:$self,
    AnyTorchTensorListType:$tensor1,
    AnyTorchTensorListType:$tensor2,
    AnyTorchScalarListType:$scalars
  );
  let results = (outs
  );
  let assemblyFormat = "$self `,` $tensor1 `,` $tensor2 `,` $scalars attr-dict `:` type($self) `,` type($tensor1) `,` type($tensor2) `,` type($scalars)";
}

def Torch_Aten_ForeachMaximumListOp : Torch_Op<"aten._foreach_maximum.List", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_foreach_maximum.List : (Tensor[], Tensor[]) -> (Tensor[])`";
  let arguments = (ins
    AnyTorchTensorListType:$tensors1,
    AnyTorchTensorListType:$tensors2
  );
  let results = (outs
    AnyTorchTensorListType:$result
  );
  let assemblyFormat = "$tensors1 `,` $tensors2 attr-dict `:` type($tensors1) `,` type($tensors2) `->` type($result)";
}

def Torch_AtenSmoothL1LossBackwardGradInputOp : Torch_Op<"aten.smooth_l1_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::smooth_l1_loss_backward.grad_input : (Tensor, Tensor, Tensor, int, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$beta,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $beta `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($beta) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenSmoothL1LossBackwardOp : Torch_Op<"aten.smooth_l1_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::smooth_l1_loss_backward : (Tensor, Tensor, Tensor, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$beta
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $beta attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($beta) `->` type($result)";
}

def Torch_AtenHuberLossBackwardOutOp : Torch_Op<"aten.huber_loss_backward.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::huber_loss_backward.out : (Tensor, Tensor, Tensor, int, float, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$delta,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $delta `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($delta) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenHuberLossBackwardOp : Torch_Op<"aten.huber_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::huber_loss_backward : (Tensor, Tensor, Tensor, int, float) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    Torch_FloatType:$delta
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $delta attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($delta) `->` type($result)";
}

def Torch_AtenElu_Op : Torch_Op<"aten.elu_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::elu_ : (Tensor, Scalar, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$alpha,
    AnyTorchScalarType:$scale,
    AnyTorchScalarType:$input_scale
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $alpha `,` $scale `,` $input_scale attr-dict `:` type($self) `,` type($alpha) `,` type($scale) `,` type($input_scale) `->` type($result)";
}

def Torch_AtenHardsigmoid_Op : Torch_Op<"aten.hardsigmoid_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardsigmoid_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenHardtanh_Op : Torch_Op<"aten.hardtanh_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardtanh_ : (Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$min_val,
    AnyTorchScalarType:$max_val
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $min_val `,` $max_val attr-dict `:` type($self) `,` type($min_val) `,` type($max_val) `->` type($result)";
}

def Torch_AtenHardswish_Op : Torch_Op<"aten.hardswish_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::hardswish_ : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenSoftplusBackwardOp : Torch_Op<"aten.softplus_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::softplus_backward : (Tensor, Tensor, Scalar, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$threshold,
    AnyTorchTensorType:$output
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $beta `,` $threshold `,` $output attr-dict `:` type($grad_output) `,` type($self) `,` type($beta) `,` type($threshold) `,` type($output) `->` type($result)";
}

def Torch_AtenSoftplusBackwardGradInputOp : Torch_Op<"aten.softplus_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::softplus_backward.grad_input : (Tensor, Tensor, Scalar, Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$threshold,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $beta `,` $threshold `,` $output `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($beta) `,` type($threshold) `,` type($output) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenSoftshrinkBackwardOp : Torch_Op<"aten.softshrink_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::softshrink_backward : (Tensor, Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $lambd attr-dict `:` type($grad_output) `,` type($self) `,` type($lambd) `->` type($result)";
}

def Torch_AtenSoftshrinkBackwardGradInputOp : Torch_Op<"aten.softshrink_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::softshrink_backward.grad_input : (Tensor, Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$lambd,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $lambd `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($lambd) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenReflectionPad1dBackwardOp : Torch_Op<"aten.reflection_pad1d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reflection_pad1d_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReflectionPad1dBackwardGradInputOp : Torch_Op<"aten.reflection_pad1d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reflection_pad1d_backward.grad_input : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_TestOptionalIntlistOp : Torch_Op<"aten._test_optional_intlist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_optional_intlist : (Tensor, int[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$values,
    TorchOptionalIntListType:$addends
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$values `,` $addends attr-dict `:` type($values) `,` type($addends) `->` type($result)";
}

def Torch_AtenReflectionPad2dBackwardOp : Torch_Op<"aten.reflection_pad2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reflection_pad2d_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReflectionPad2dBackwardGradInputOp : Torch_Op<"aten.reflection_pad2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reflection_pad2d_backward.grad_input : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_SegmentReduceBackwardOp : Torch_Op<"aten._segment_reduce_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_segment_reduce_backward : (Tensor, Tensor, Tensor, str, Tensor?, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$data,
    Torch_StringType:$reduce,
    AnyTorchOptionalTensorType:$lengths,
    Torch_IntType:$axis
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad `,` $output `,` $data `,` $reduce `,` $lengths `,` $axis attr-dict `:` type($grad) `,` type($output) `,` type($data) `,` type($reduce) `,` type($lengths) `,` type($axis) `->` type($result)";
}

def Torch_AtenReflectionPad3dOutOp : Torch_Op<"aten.reflection_pad3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reflection_pad3d.out : (Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $padding `,` $out attr-dict `:` type($self) `,` type($padding) `,` type($out) `->` type($result)";
}

def Torch_Aten_GridSampler2dCpuFallbackOp : Torch_Op<"aten._grid_sampler_2d_cpu_fallback", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_grid_sampler_2d_cpu_fallback : (Tensor, Tensor, int, int, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$grid,
    Torch_IntType:$interpolation_mode,
    Torch_IntType:$padding_mode,
    Torch_BoolType:$align_corners
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $grid `,` $interpolation_mode `,` $padding_mode `,` $align_corners attr-dict `:` type($input) `,` type($grid) `,` type($interpolation_mode) `,` type($padding_mode) `,` type($align_corners) `->` type($result)";
}

def Torch_AtenReflectionPad3dBackwardOp : Torch_Op<"aten.reflection_pad3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::reflection_pad3d_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReflectionPad3dBackwardGradInputOp : Torch_Op<"aten.reflection_pad3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::reflection_pad3d_backward.grad_input : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenIndexCopy_Op : Torch_Op<"aten.index_copy_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_copy_ : (Tensor, int, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenIndexCopy_DimnameOp : Torch_Op<"aten.index_copy_.dimname", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::index_copy_.dimname : (Tensor, str, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_StringType:$dim,
    AnyTorchTensorType:$index,
    AnyTorchTensorType:$source
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $dim `,` $index `,` $source attr-dict `:` type($self) `,` type($dim) `,` type($index) `,` type($source) `->` type($result)";
}

def Torch_AtenReplicationPad1dBackwardOp : Torch_Op<"aten.replication_pad1d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::replication_pad1d_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReplicationPad1dBackwardGradInputOp : Torch_Op<"aten.replication_pad1d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::replication_pad1d_backward.grad_input : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenLinalgPinvAtolRtolTensorOutOp : Torch_Op<"aten.linalg_pinv.atol_rtol_tensor_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.atol_rtol_tensor_out : (Tensor, Tensor?, Tensor?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchOptionalTensorType:$atol,
    AnyTorchOptionalTensorType:$rtol,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $atol `,` $rtol `,` $hermitian `,` $out attr-dict `:` type($self) `,` type($atol) `,` type($rtol) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgPinvAtolRtolFloatOutOp : Torch_Op<"aten.linalg_pinv.atol_rtol_float_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.atol_rtol_float_out : (Tensor, float?, float?, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$atol,
    TorchOptionalFloatType:$rtol,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $atol `,` $rtol `,` $hermitian `,` $out attr-dict `:` type($self) `,` type($atol) `,` type($rtol) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgPinvOutOp : Torch_Op<"aten.linalg_pinv.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.out : (Tensor, float, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$rcond,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $rcond `,` $hermitian `,` $out attr-dict `:` type($self) `,` type($rcond) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgPinvOutRcondTensorOp : Torch_Op<"aten.linalg_pinv.out_rcond_tensor", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_pinv.out_rcond_tensor : (Tensor, Tensor, bool, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$rcond,
    Torch_BoolType:$hermitian,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $rcond `,` $hermitian `,` $out attr-dict `:` type($self) `,` type($rcond) `,` type($hermitian) `,` type($out) `->` type($result)";
}

def Torch_AtenReplicationPad2dBackwardOp : Torch_Op<"aten.replication_pad2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::replication_pad2d_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReplicationPad2dBackwardGradInputOp : Torch_Op<"aten.replication_pad2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::replication_pad2d_backward.grad_input : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_UnpackDualOp : Torch_Op<"aten._unpack_dual", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_unpack_dual : (Tensor, int) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$dual,
    Torch_IntType:$level
  );
  let results = (outs
    AnyTorchTensorType:$primal,
    AnyTorchTensorType:$tangent
  );
  let assemblyFormat = "$dual `,` $level attr-dict `:` type($dual) `,` type($level) `->` type($primal) `,` type($tangent)";
}

def Torch_AtenReplicationPad3dBackwardOp : Torch_Op<"aten.replication_pad3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::replication_pad3d_backward : (Tensor, Tensor, int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `->` type($result)";
}

def Torch_AtenReplicationPad3dBackwardGradInputOp : Torch_Op<"aten.replication_pad3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::replication_pad3d_backward.grad_input : (Tensor, Tensor, int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    TorchIntListType:$padding,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $padding `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($padding) `,` type($grad_input) `->` type($result)";
}

def Torch_Aten_SobolEngineDrawOp : Torch_Op<"aten._sobol_engine_draw", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_sobol_engine_draw : (Tensor, int, Tensor, int, int, int?) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$quasi,
    Torch_IntType:$n,
    AnyTorchTensorType:$sobolstate,
    Torch_IntType:$dimension,
    Torch_IntType:$num_generated,
    TorchOptionalIntType:$dtype
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$quasi `,` $n `,` $sobolstate `,` $dimension `,` $num_generated `,` $dtype attr-dict `:` type($quasi) `,` type($n) `,` type($sobolstate) `,` type($dimension) `,` type($num_generated) `,` type($dtype) `->` type($result0) `,` type($result1)";
}

def Torch_AtenUpsampleLinear1dBackwardOp : Torch_Op<"aten.upsample_linear1d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_linear1d_backward : (Tensor, int[], int[], bool, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales) `->` type($result)";
}

def Torch_AtenUpsampleLinear1dBackwardGradInputOp : Torch_Op<"aten.upsample_linear1d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_linear1d_backward.grad_input : (Tensor, int[], int[], bool, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleLinear1dBackwardVecOp : Torch_Op<"aten.upsample_linear1d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_linear1d_backward.vec : (Tensor, int[]?, int[], bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenUpsampleBilinear2dBackwardOp : Torch_Op<"aten.upsample_bilinear2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bilinear2d_backward : (Tensor, int[], int[], bool, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales_h `,` $scales_w attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleBilinear2dBackwardGradInputOp : Torch_Op<"aten.upsample_bilinear2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_bilinear2d_backward.grad_input : (Tensor, int[], int[], bool, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales_h `,` $scales_w `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleBilinear2dBackwardVecOp : Torch_Op<"aten.upsample_bilinear2d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bilinear2d_backward.vec : (Tensor, int[]?, int[], bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenUpsampleBicubic2dOutOp : Torch_Op<"aten.upsample_bicubic2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_bicubic2d.out : (Tensor, int[], bool, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchIntListType:$output_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $output_size `,` $align_corners `,` $scales_h `,` $scales_w `,` $out attr-dict `:` type($self) `,` type($output_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `,` type($out) `->` type($result)";
}

def Torch_AtenUpsampleBicubic2dBackwardOp : Torch_Op<"aten.upsample_bicubic2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bicubic2d_backward : (Tensor, int[], int[], bool, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales_h `,` $scales_w attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleBicubic2dBackwardGradInputOp : Torch_Op<"aten.upsample_bicubic2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_bicubic2d_backward.grad_input : (Tensor, int[], int[], bool, float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scales_h `,` $scales_w `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scales_h) `,` type($scales_w) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleBicubic2dBackwardVecOp : Torch_Op<"aten.upsample_bicubic2d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_bicubic2d_backward.vec : (Tensor, int[]?, int[], bool, float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    Torch_BoolType:$align_corners,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $align_corners `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($align_corners) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenUpsampleNearest1dBackwardOp : Torch_Op<"aten.upsample_nearest1d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest1d_backward : (Tensor, int[], int[], float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatType:$scales
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scales attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scales) `->` type($result)";
}

def Torch_AtenUpsampleNearest1dBackwardGradInputOp : Torch_Op<"aten.upsample_nearest1d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_nearest1d_backward.grad_input : (Tensor, int[], int[], float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatType:$scales,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scales `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scales) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleNearest1dBackwardVecOp : Torch_Op<"aten.upsample_nearest1d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest1d_backward.vec : (Tensor, int[]?, int[], float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenUpsampleNearest2dBackwardOp : Torch_Op<"aten.upsample_nearest2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest2d_backward : (Tensor, int[], int[], float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scales_h `,` $scales_w attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scales_h) `,` type($scales_w) `->` type($result)";
}

def Torch_AtenUpsampleNearest2dBackwardGradInputOp : Torch_Op<"aten.upsample_nearest2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::upsample_nearest2d_backward.grad_input : (Tensor, int[], int[], float?, float?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatType:$scales_h,
    TorchOptionalFloatType:$scales_w,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scales_h `,` $scales_w `,` $grad_input attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scales_h) `,` type($scales_w) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenUpsampleNearest2dBackwardVecOp : Torch_Op<"aten.upsample_nearest2d_backward.vec", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::upsample_nearest2d_backward.vec : (Tensor, int[]?, int[], float[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchOptionalIntListType:$output_size,
    TorchIntListType:$input_size,
    TorchOptionalFloatListType:$scale_factors
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $output_size `,` $input_size `,` $scale_factors attr-dict `:` type($grad_output) `,` type($output_size) `,` type($input_size) `,` type($scale_factors) `->` type($result)";
}

def Torch_AtenSlowConvTranspose2dOp : Torch_Op<"aten.slow_conv_transpose2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose2d : (Tensor, Tensor, int[], Tensor?, int[], int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $dilation attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `->` type($result)";
}

def Torch_AtenSlowConvTranspose2dOutOp : Torch_Op<"aten.slow_conv_transpose2d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose2d.out : (Tensor, Tensor, int[], Tensor?, int[], int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $dilation `,` $out attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `,` type($out) `->` type($result)";
}

def Torch_AtenSlowConvTranspose2dBackwardGradOutputOp : Torch_Op<"aten.slow_conv_transpose2d_backward.grad_output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose2d_backward.grad_output : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int[], Tensor, Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$columns,
    AnyTorchTensorType:$ones,
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $output_padding `,` $dilation `,` $columns `,` $ones `,` $grad_input `,` $grad_weight `,` $grad_bias attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `,` type($columns) `,` type($ones) `,` type($grad_input) `,` type($grad_weight) `,` type($grad_bias) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenSlowConvTranspose2dBackwardOutputMaskOp : Torch_Op<"aten.slow_conv_transpose2d_backward.output_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose2d_backward.output_mask : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int[], Tensor, Tensor, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$columns,
    AnyTorchTensorType:$ones,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $output_padding `,` $dilation `,` $columns `,` $ones `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `,` type($columns) `,` type($ones) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_AtenSlowConvTranspose3dOp : Torch_Op<"aten.slow_conv_transpose3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose3d : (Tensor, Tensor, int[], Tensor?, int[], int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $dilation attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `->` type($result)";
}

def Torch_AtenSlowConvTranspose3dOutOp : Torch_Op<"aten.slow_conv_transpose3d.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose3d.out : (Tensor, Tensor, int[], Tensor?, int[], int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $output_padding `,` $dilation `,` $out attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `,` type($out) `->` type($result)";
}

def Torch_AtenSlowConvTranspose3dBackwardGradOutputOp : Torch_Op<"aten.slow_conv_transpose3d_backward.grad_output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose3d_backward.grad_output : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int[], Tensor, Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$fgrad_input,
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $output_padding `,` $dilation `,` $finput `,` $fgrad_input `,` $grad_input `,` $grad_weight `,` $grad_bias attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `,` type($finput) `,` type($fgrad_input) `,` type($grad_input) `,` type($grad_weight) `,` type($grad_bias) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenSlowConvTranspose3dBackwardOutputMaskOp : Torch_Op<"aten.slow_conv_transpose3d_backward.output_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_transpose3d_backward.output_mask : (Tensor, Tensor, Tensor, int[], int[], int[], int[], int[], Tensor, Tensor, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$output_padding,
    TorchIntListType:$dilation,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$fgrad_input,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $output_padding `,` $dilation `,` $finput `,` $fgrad_input `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($output_padding) `,` type($dilation) `,` type($finput) `,` type($fgrad_input) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_Aten_SlowConv2dForwardOp : Torch_Op<"aten._slow_conv2d_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_slow_conv2d_forward : (Tensor, Tensor, int[], Tensor?, int[], int[]) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$finput
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `->` type($output) `,` type($finput)";
}

def Torch_Aten_SlowConv2dForwardOutputOp : Torch_Op<"aten._slow_conv2d_forward.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_slow_conv2d_forward.output : (Tensor, Tensor, int[], Tensor?, int[], int[], Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$finput
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $output `,` $finput attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output) `,` type($finput) `->` type($result0) `,` type($result1)";
}

def Torch_Aten_SlowConv2dBackwardGradInputOp : Torch_Op<"aten._slow_conv2d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_slow_conv2d_backward.grad_input : (Tensor, Tensor, Tensor, int[], int[], int[], Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $finput `,` $grad_input `,` $grad_weight `,` $grad_bias attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($finput) `,` type($grad_input) `,` type($grad_weight) `,` type($grad_bias) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_Aten_SlowConv2dBackwardOutputMaskOp : Torch_Op<"aten._slow_conv2d_backward.output_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_slow_conv2d_backward.output_mask : (Tensor, Tensor, Tensor, int[], int[], int[], Tensor, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$finput,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $finput `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($finput) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_AtenSlowConv3dForwardOp : Torch_Op<"aten.slow_conv3d_forward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv3d_forward : (Tensor, Tensor, int[], Tensor?, int[], int[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding
  );
  let results = (outs
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$fgrad_input
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `->` type($output) `,` type($finput) `,` type($fgrad_input)";
}

def Torch_AtenSlowConv3dForwardOutputOp : Torch_Op<"aten.slow_conv3d_forward.output", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv3d_forward.output : (Tensor, Tensor, int[], Tensor?, int[], int[], Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$output,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$fgrad_input
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $output `,` $finput `,` $fgrad_input attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($output) `,` type($finput) `,` type($fgrad_input) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenSlowConv3dBackwardGradInputOp : Torch_Op<"aten.slow_conv3d_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::slow_conv3d_backward.grad_input : (Tensor, Tensor, Tensor, int[], int[], int[], Tensor, Tensor, Tensor, Tensor, Tensor) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$fgrad_input,
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1,
    AnyTorchTensorType:$result2
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $finput `,` $fgrad_input `,` $grad_input `,` $grad_weight `,` $grad_bias attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($finput) `,` type($fgrad_input) `,` type($grad_input) `,` type($grad_weight) `,` type($grad_bias) `->` type($result0) `,` type($result1) `,` type($result2)";
}

def Torch_AtenSlowConv3dBackwardOutputMaskOp : Torch_Op<"aten.slow_conv3d_backward.output_mask", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv3d_backward.output_mask : (Tensor, Tensor, Tensor, int[], int[], int[], Tensor, Tensor, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    AnyTorchTensorType:$finput,
    AnyTorchTensorType:$fgrad_input,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $finput `,` $fgrad_input `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($finput) `,` type($fgrad_input) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_AtenSlowConvDilated2dOp : Torch_Op<"aten.slow_conv_dilated2d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_dilated2d : (Tensor, Tensor, int[], Tensor?, int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $dilation attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `->` type($result)";
}

def Torch_AtenSlowConvDilated2dBackwardOp : Torch_Op<"aten.slow_conv_dilated2d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_dilated2d_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int[], bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_AtenSlowConvDilated3dOp : Torch_Op<"aten.slow_conv_dilated3d", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_dilated3d : (Tensor, Tensor, int[], Tensor?, int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $weight `,` $kernel_size `,` $bias `,` $stride `,` $padding `,` $dilation attr-dict `:` type($self) `,` type($weight) `,` type($kernel_size) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `->` type($result)";
}

def Torch_AtenSlowConvDilated3dBackwardOp : Torch_Op<"aten.slow_conv_dilated3d_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::slow_conv_dilated3d_backward : (Tensor, Tensor, Tensor, int[], int[], int[], int[], bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$weight,
    TorchIntListType:$kernel_size,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $self `,` $weight `,` $kernel_size `,` $stride `,` $padding `,` $dilation `,` $output_mask attr-dict `:` type($grad_output) `,` type($self) `,` type($weight) `,` type($kernel_size) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_AtenIm2colBackwardOp : Torch_Op<"aten.im2col_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::im2col_backward : (Tensor, int[], int[], int[], int[], int[]) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$input_size,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $input_size `,` $kernel_size `,` $dilation `,` $padding `,` $stride attr-dict `:` type($grad_output) `,` type($input_size) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `->` type($result)";
}

def Torch_AtenIm2colBackwardGradInputOp : Torch_Op<"aten.im2col_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::im2col_backward.grad_input : (Tensor, int[], int[], int[], int[], int[], Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    TorchIntListType:$input_size,
    TorchIntListType:$kernel_size,
    TorchIntListType:$dilation,
    TorchIntListType:$padding,
    TorchIntListType:$stride,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $input_size `,` $kernel_size `,` $dilation `,` $padding `,` $stride `,` $grad_input attr-dict `:` type($grad_output) `,` type($input_size) `,` type($kernel_size) `,` type($dilation) `,` type($padding) `,` type($stride) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenSpecialErfcxOutOp : Torch_Op<"aten.special_erfcx.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_erfcx.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialXlog1pyOutOp : Torch_Op<"aten.special_xlog1py.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_xlog1py.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialXlog1pySelfScalarOutOp : Torch_Op<"aten.special_xlog1py.self_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_xlog1py.self_scalar_out : (Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialXlog1pyOtherScalarOutOp : Torch_Op<"aten.special_xlog1py.other_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_xlog1py.other_scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialZetaOutOp : Torch_Op<"aten.special_zeta.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_zeta.out : (Tensor, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialZetaSelfScalarOutOp : Torch_Op<"aten.special_zeta.self_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_zeta.self_scalar_out : (Scalar, Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchScalarType:$self,
    AnyTorchTensorType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialZetaOtherScalarOutOp : Torch_Op<"aten.special_zeta.other_scalar_out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_zeta.other_scalar_out : (Tensor, Scalar, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$other,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $other `,` $out attr-dict `:` type($self) `,` type($other) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialI0eOutOp : Torch_Op<"aten.special_i0e.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_i0e.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialI1OutOp : Torch_Op<"aten.special_i1.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_i1.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenSpecialI1eOutOp : Torch_Op<"aten.special_i1e.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::special_i1e.out : (Tensor, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $out attr-dict `:` type($self) `,` type($out) `->` type($result)";
}

def Torch_AtenLinalgSlogdetOutOp : Torch_Op<"aten.linalg_slogdet.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_slogdet.out : (Tensor, Tensor, Tensor) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$sign,
    AnyTorchTensorType:$logabsdet
  );
  let results = (outs
    AnyTorchTensorType:$res_sign,
    AnyTorchTensorType:$res_logabsdet
  );
  let assemblyFormat = "$self `,` $sign `,` $logabsdet attr-dict `:` type($self) `,` type($sign) `,` type($logabsdet) `->` type($res_sign) `,` type($res_logabsdet)";
}

def Torch_AtenLinalgVectorNormOutOp : Torch_Op<"aten.linalg_vector_norm.out", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::linalg_vector_norm.out : (Tensor, Scalar, int[]?, bool, int?, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$ord,
    TorchOptionalIntListType:$dim,
    Torch_BoolType:$keepdim,
    TorchOptionalIntType:$dtype,
    AnyTorchTensorType:$out
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $ord `,` $dim `,` $keepdim `,` $dtype `,` $out attr-dict `:` type($self) `,` type($ord) `,` type($dim) `,` type($keepdim) `,` type($dtype) `,` type($out) `->` type($result)";
}

def Torch_Aten_TestOptionalFilledIntlistOp : Torch_Op<"aten._test_optional_filled_intlist", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_optional_filled_intlist : (Tensor, int[]?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$values,
    TorchOptionalIntListType:$addends
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$values `,` $addends attr-dict `:` type($values) `,` type($addends) `->` type($result)";
}

def Torch_Aten_NegViewOp : Torch_Op<"aten._neg_view", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_neg_view : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_AtenAddr_Op : Torch_Op<"aten.addr_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::addr_ : (Tensor, Tensor, Tensor, Scalar, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$vec1,
    AnyTorchTensorType:$vec2,
    AnyTorchScalarType:$beta,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $vec1 `,` $vec2 `,` $beta `,` $alpha attr-dict `:` type($self) `,` type($vec1) `,` type($vec2) `,` type($beta) `,` type($alpha) `->` type($result)";
}

def Torch_AtenConvolutionOverrideableOp : Torch_Op<"aten.convolution_overrideable", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::convolution_overrideable : (Tensor, Tensor, Tensor?, int[], int[], int[], bool, int[], int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    AnyTorchOptionalTensorType:$bias,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$input `,` $weight `,` $bias `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding `,` $groups attr-dict `:` type($input) `,` type($weight) `,` type($bias) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `,` type($groups) `->` type($result)";
}

def Torch_AtenConvolutionBackwardOverrideableOp : Torch_Op<"aten.convolution_backward_overrideable", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::convolution_backward_overrideable : (Tensor, Tensor, Tensor, int[], int[], int[], bool, int[], int, bool[]) -> (Tensor, Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$weight,
    TorchIntListType:$stride,
    TorchIntListType:$padding,
    TorchIntListType:$dilation,
    Torch_BoolType:$transposed,
    TorchIntListType:$output_padding,
    Torch_IntType:$groups,
    TorchBoolListType:$output_mask
  );
  let results = (outs
    AnyTorchTensorType:$grad_input,
    AnyTorchTensorType:$grad_weight,
    AnyTorchTensorType:$grad_bias
  );
  let assemblyFormat = "$grad_output `,` $input `,` $weight `,` $stride `,` $padding `,` $dilation `,` $transposed `,` $output_padding `,` $groups `,` $output_mask attr-dict `:` type($grad_output) `,` type($input) `,` type($weight) `,` type($stride) `,` type($padding) `,` type($dilation) `,` type($transposed) `,` type($output_padding) `,` type($groups) `,` type($output_mask) `->` type($grad_input) `,` type($grad_weight) `,` type($grad_bias)";
}

def Torch_AtenNanToNum_Op : Torch_Op<"aten.nan_to_num_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::nan_to_num_ : (Tensor, float?, float?, float?) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    TorchOptionalFloatType:$nan,
    TorchOptionalFloatType:$posinf,
    TorchOptionalFloatType:$neginf
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $nan `,` $posinf `,` $neginf attr-dict `:` type($self) `,` type($nan) `,` type($posinf) `,` type($neginf) `->` type($result)";
}

def Torch_AtenCelu_Op : Torch_Op<"aten.celu_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::celu_ : (Tensor, Scalar) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    AnyTorchScalarType:$alpha
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $alpha attr-dict `:` type($self) `,` type($alpha) `->` type($result)";
}

def Torch_Aten_PackPaddedSequenceOp : Torch_Op<"aten._pack_padded_sequence", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_pack_padded_sequence : (Tensor, Tensor, bool) -> (Tensor, Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$input,
    AnyTorchTensorType:$lengths,
    Torch_BoolType:$batch_first
  );
  let results = (outs
    AnyTorchTensorType:$result0,
    AnyTorchTensorType:$result1
  );
  let assemblyFormat = "$input `,` $lengths `,` $batch_first attr-dict `:` type($input) `,` type($lengths) `,` type($batch_first) `->` type($result0) `,` type($result1)";
}

def Torch_AtenSoftMarginLossBackwardOp : Torch_Op<"aten.soft_margin_loss_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::soft_margin_loss_backward : (Tensor, Tensor, Tensor, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `->` type($result)";
}

def Torch_AtenSoftMarginLossBackwardGradInputOp : Torch_Op<"aten.soft_margin_loss_backward.grad_input", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::soft_margin_loss_backward.grad_input : (Tensor, Tensor, Tensor, int, Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$target,
    Torch_IntType:$reduction,
    AnyTorchTensorType:$grad_input
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $target `,` $reduction `,` $grad_input attr-dict `:` type($grad_output) `,` type($self) `,` type($target) `,` type($reduction) `,` type($grad_input) `->` type($result)";
}

def Torch_AtenRreluWithNoiseBackwardOp : Torch_Op<"aten.rrelu_with_noise_backward", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::rrelu_with_noise_backward : (Tensor, Tensor, Tensor, Scalar, Scalar, bool, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$grad_output,
    AnyTorchTensorType:$self,
    AnyTorchTensorType:$noise,
    AnyTorchScalarType:$lower,
    AnyTorchScalarType:$upper,
    Torch_BoolType:$training,
    Torch_BoolType:$self_is_result
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$grad_output `,` $self `,` $noise `,` $lower `,` $upper `,` $training `,` $self_is_result attr-dict `:` type($grad_output) `,` type($self) `,` type($noise) `,` type($lower) `,` type($upper) `,` type($training) `,` type($self_is_result) `->` type($result)";
}

def Torch_Aten_TestWarnInAutogradOp : Torch_Op<"aten._test_warn_in_autograd", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_test_warn_in_autograd : (Tensor) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self attr-dict `:` type($self) `->` type($result)";
}

def Torch_Aten_CastByteOp : Torch_Op<"aten._cast_Byte", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Byte : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastCharOp : Torch_Op<"aten._cast_Char", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Char : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastDoubleOp : Torch_Op<"aten._cast_Double", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Double : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastFloatOp : Torch_Op<"aten._cast_Float", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Float : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastIntOp : Torch_Op<"aten._cast_Int", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Int : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastLongOp : Torch_Op<"aten._cast_Long", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Long : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastShortOp : Torch_Op<"aten._cast_Short", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Short : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_CastHalfOp : Torch_Op<"aten._cast_Half", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_cast_Half : (Tensor, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_BoolType:$non_blocking
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $non_blocking attr-dict `:` type($self) `,` type($non_blocking) `->` type($result)";
}

def Torch_Aten_UseCudnnRnnFlattenWeightOp : Torch_Op<"aten._use_cudnn_rnn_flatten_weight", [
    AllowsTypeRefinement,
    HasValueSemantics
  ]> {
  let summary = "Generated op for `aten::_use_cudnn_rnn_flatten_weight : () -> (bool)`";
  let arguments = (ins
  );
  let results = (outs
    Torch_BoolType:$result
  );
  let assemblyFormat = " attr-dict `:` type($result)";
}

def Torch_Aten_SobolEngineFf_Op : Torch_Op<"aten._sobol_engine_ff_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::_sobol_engine_ff_ : (Tensor, int, Tensor, int, int) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_IntType:$n,
    AnyTorchTensorType:$sobolstate,
    Torch_IntType:$dimension,
    Torch_IntType:$num_generated
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $n `,` $sobolstate `,` $dimension `,` $num_generated attr-dict `:` type($self) `,` type($n) `,` type($sobolstate) `,` type($dimension) `,` type($num_generated) `->` type($result)";
}

def Torch_AtenFeatureDropout_Op : Torch_Op<"aten.feature_dropout_", [
    AllowsTypeRefinement
  ]> {
  let summary = "Generated op for `aten::feature_dropout_ : (Tensor, float, bool) -> (Tensor)`";
  let arguments = (ins
    AnyTorchTensorType:$self,
    Torch_FloatType:$p,
    Torch_BoolType:$train
  );
  let results = (outs
    AnyTorchTensorType:$result
  );
  let assemblyFormat = "$self `,` $p `,` $train attr-dict `:` type($self) `,` type($p) `,` type($train) `->` type($result)";
}

